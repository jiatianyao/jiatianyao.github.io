<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>张洪铭的个人博客</title>
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2018-09-01T14:15:55.889Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>张洪铭</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>机器学习-神经网络</title>
    <link href="http://yoursite.com/2018/08/25/Machine%20learning%20Artificial%20Neural%20Network/"/>
    <id>http://yoursite.com/2018/08/25/Machine learning Artificial Neural Network/</id>
    <published>2018-08-25T07:36:00.000Z</published>
    <updated>2018-09-01T14:15:55.889Z</updated>
    
    <content type="html"><![CDATA[<p>什么是人工神经网络模型<br>人工神经网络(Artificial Neural Network, ANN)没有一个严格的正式定义。它的基本特点，是试图模仿大脑的神经元之间传递，处理信息的模式。</p>
<p>一个计算模型，要被称为为神经网络，通常需要大量彼此连接的节点 （也称 ‘神经元’），并且具备两个特性：<br>每个神经元，通过某种特定的输出函数 （也叫激励函数 activation function），计算处理来自其它相邻神经元的加权输入值<br>神经元之间的信息传递的强度，用所谓加权值来定义，算法会不断自我学习，调整这个加权值<br>总结：神经网络算法的核心就是：计算、连接、评估、纠错、学习</p>
<h4 id="神经网络模型可以分为："><a href="#神经网络模型可以分为：" class="headerlink" title="神经网络模型可以分为："></a><strong>神经网络模型可以分为：</strong></h4><h6 id="前向网络"><a href="#前向网络" class="headerlink" title="前向网络"></a><strong>前向网络</strong></h6><p>网络中各个神经元接受前一级的输入，并输出到下一级，网络中没有反馈，可以用一个有向无环路图表示。这种网络实现信号从输入空间到输出空间的变换，它的信息处理能力来自于简单非线性函数的多次复合。网络结构简单，易于实现。反传网络是一种典型的前向网络。</p>
<h6 id="反馈网络"><a href="#反馈网络" class="headerlink" title="反馈网络"></a><strong>反馈网络</strong></h6><p>网络内神经元间有反馈，可以用一个无向的完备图表示。这种神经网络的信息处理是状态的变换，可以用动力学系统理论处理。系统的稳定性与联想记忆功能有密切关系。Hopfield网络、波耳兹曼机均属于这种类型。</p>
<h4 id="激活函数"><a href="#激活函数" class="headerlink" title="激活函数"></a><strong>激活函数</strong></h4><p>用于处理复杂的非线性分类情况。比线性回归、logistic回归灵活。训练的时候注意过拟合。<br>非线性激活函数<br>Sigmoid<br>𝑓(𝑥)=1/(1+exp⁡(−𝑥))<br>特点：<br>当x趋近负无穷时，y趋近于0；趋近于正无穷时，y趋近于1；<br>x超出[-6,6]的范围后，函数值基本上没有变化，值非常接近0或者1<br>该函数的值域范围限制在(0,1)之间，这样sigmoid函数就能与一个概率分布联系起来了。<br>𝑓^′ (𝑥)=𝑓(𝑥)(1−𝑓(𝑥))</p>
<h4 id="双曲正切"><a href="#双曲正切" class="headerlink" title="双曲正切"></a><strong>双曲正切</strong></h4><p>tanh⁡(𝑥)=(𝑒^𝑥−𝑒^(−𝑥))/(𝑒^𝑥+𝑒^(−𝑥) )<br>特点：<br>当x趋近负无穷时，y趋近于-1；趋近于正无穷时，y趋近于1；<br>x超出[-3,3]的范围后，函数值基本上没有变化，值非常接近-1或者1<br>该函数的值域范围限制在(-1,1)之间<br>tanh^′ (𝑥)=1−tanh(x)^2</p>
<h4 id="修正线性单元Rectifier-Linear-Units（ReLU）"><a href="#修正线性单元Rectifier-Linear-Units（ReLU）" class="headerlink" title="修正线性单元Rectifier Linear Units（ReLU）"></a><strong>修正线性单元Rectifier Linear Units（ReLU）</strong></h4><p>𝑓(𝑥)=max⁡(0,𝑥)<br>特点：<br>只有有一半隐含层是处于激活状态，其余都是输出为0<br>不会出现梯度消失的问题（即在sigmoid接近饱和区时，导数趋于0，这种情况会造成信息丢失）<br>只需比较、乘加运算，因此计算方便，计算速度快，加速了网络的训练<br>ReLU比sigmoid更接近生物学的激活模型<br>还有一些改进或的变体</p>
<h4 id="Softplus"><a href="#Softplus" class="headerlink" title="Softplus"></a><strong>Softplus</strong></h4><p>𝑓(𝑥)=log⁡(1+𝑒^𝑥 )<br>特点：<br>x趋于负无穷时，softplus趋于0；x趋于正无穷时， softplus趋于x<br>它是ReLU的平滑版<br>它是sigmoid的原函数</p>
<h3 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a><strong>损失函数</strong></h3><p>用于回归中的均方损失：<br>𝐸=1/2 (𝑦−𝑦 ̂ )^2<br>用于分类中的交叉熵损失函数：<br>𝐸=−∑▒〖𝑦<em>𝑘 𝑙𝑜𝑔((𝑦</em>𝑘 ) ̂ )” “ 〗<br>k=1,2,…,m表示m种类别。在违约预测中m=2</p>
<p>基于 Anaconda 的安装<br>安装tensorflow<br>建立一个 conda 计算环境名字叫tensorflow:</p>
<h1 id="Python-2-7"><a href="#Python-2-7" class="headerlink" title="Python 2.7"></a>Python 2.7</h1><p>$ conda create -n tensorflow python=2.7</p>
<h1 id="Python-3-4"><a href="#Python-3-4" class="headerlink" title="Python 3.4"></a>Python 3.4</h1><p>$ conda create -n tensorflow python=3.4</p>
<p>activate tensorflow</p>
<p>安装tensorflow<br>conda install –channel <a href="https://conda.anaconda.org/conda-forge" target="_blank" rel="external">https://conda.anaconda.org/conda-forge</a> tensorflow</p>
<p>import tensorflow as tf<br>退出python3环境或当你不用 TensorFlow 的时候,关闭环境:<br>(tensorflow)$  deactivate<br>$  # Your prompt should change back</p>
<p>windows下安装<br>升级pip<br>python -m pip install –upgrade pip<br>安装tensorflow<br>pip3 install –upgrade <a href="https://storage.googleapis.com/tensorflow/windows/cpu/tensorflow-0.12.0-cp35-cp35m-win_amd64.whl" target="_blank" rel="external">https://storage.googleapis.com/tensorflow/windows/cpu/tensorflow-0.12.0-cp35-cp35m-win_amd64.whl</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;什么是人工神经网络模型&lt;br&gt;人工神经网络(Artificial Neural Network, ANN)没有一个严格的正式定义。它的基本特点，是试图模仿大脑的神经元之间传递，处理信息的模式。&lt;/p&gt;
&lt;p&gt;一个计算模型，要被称为为神经网络，通常需要大量彼此连接的节点 （也
    
    </summary>
    
      <category term="机器学习" scheme="http://yoursite.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="机器学习" scheme="http://yoursite.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>TensorFlow 安装使用</title>
    <link href="http://yoursite.com/2018/08/18/Install%20TensorFlow/"/>
    <id>http://yoursite.com/2018/08/18/Install TensorFlow/</id>
    <published>2018-08-18T03:30:00.000Z</published>
    <updated>2018-09-01T14:15:41.490Z</updated>
    
    <content type="html"><![CDATA[<h2 id="基于Anaconda的Tensorflow"><a href="#基于Anaconda的Tensorflow" class="headerlink" title="基于Anaconda的Tensorflow"></a>基于Anaconda的Tensorflow</h2><h3 id="安装Anaconda"><a href="#安装Anaconda" class="headerlink" title="安装Anaconda"></a>安装Anaconda</h3><p>根据官网选择基于不同的python版本安装：<br><a href="https://www.anaconda.com/download/#windows" target="_blank" rel="external">https://www.anaconda.com/download/#windows</a></p>
<p>博主选择Python 3.6 version，windows 64bit</p>
<p>安装完成后需要配置环境变量，根目录和Scripts目录加入到Path下面<br>G:\ProgramData\Anaconda3;G:\ProgramData\Anaconda3\Scripts</p>
<p>1.检测anaconda环境是否安装成功：conda –version<br>2.检测目前安装了哪些环境变量：conda info –envs</p>
<p>3.安装python版本（博主选择3.5）：conda create –name tensorflow python=3.5<br>安装后是3.5.6<br>4.激活tensflow的环境：activate tensorflow<br>5.检测tensflow的环境添加到了Anaconda里面：conda info –envs<br><img src="http://oh6ybr0jg.bkt.clouddn.com/TENSORFLOW_ENV.png" alt="此处输入图片的描述"><br>6.安装tensorflow gru版本<br>pip install –ignore-installed –upgrade tensorflow-gpu</p>
<p>安装其他组件：<br>pip install pandas<br>conda install scikit-learn<br>conda install matplotlib</p>
<p>IDE想要使用tensorflow 需要制定tensorflow的python版本<br><img src="http://oh6ybr0jg.bkt.clouddn.com/QQ%E6%88%AA%E5%9B%BE20180901134100.png" alt="此处输入图片的描述"></p>
]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;基于Anaconda的Tensorflow&quot;&gt;&lt;a href=&quot;#基于Anaconda的Tensorflow&quot; class=&quot;headerlink&quot; title=&quot;基于Anaconda的Tensorflow&quot;&gt;&lt;/a&gt;基于Anaconda的Tensorflow&lt;/
    
    </summary>
    
      <category term="机器学习" scheme="http://yoursite.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="机器学习" scheme="http://yoursite.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>机器学习-随机森林</title>
    <link href="http://yoursite.com/2018/08/16/Mathematical%20%20Random%20Forest/"/>
    <id>http://yoursite.com/2018/08/16/Mathematical  Random Forest/</id>
    <published>2018-08-16T01:30:00.000Z</published>
    <updated>2018-09-01T14:13:49.214Z</updated>
    
    <content type="html"><![CDATA[<p>sklearn.ensemble.RandomForestClassifier</p>
<ul>
<li><strong>n_estimators</strong> : integer, optional (default=10)<br> 森林里（决策）树的数目</li>
<li><strong>criterion</strong> : string, optional (default=”gini”)<br> 衡量分裂质量的性能（函数）。 受支持的标准是基尼不纯度的”gini”,和信息增益的”entropy”（熵）。<br>注意：这个参数是特定树的</li>
<li><p><strong>max_features</strong> : int, float, string or None, optional (default=”auto”)<br> 选择最适属性时划分的特征不能超过此值:</p>
<pre><code>如果是int，就要考虑每一次分割处的max_feature特征
如果是float，那么max_features就是一个百分比，那么（max_feature*n_features）特征整数值是在每个分割处考虑的。
如果是auto，那么max_features=sqrt(n_features)，即n_features的平方根值。
如果是log2，那么max_features=log2(n_features)
如果是None,那么max_features=n_features
</code></pre><p>注意：寻找分割点不会停止，直到找到最少一个有效的节点划分区，即使它需要有效检查超过max_features的特征。</p>
</li>
<li><p><strong>max_depth</strong> : integer or None, optional (default=None)<br>（决策）树的最大深度。如果值为None，那么会扩展节点，直到所有的叶子是纯净的，或者直到所有叶子包含少于min_sample_split的样本。</p>
</li>
<li><p><strong>min_samples_split</strong> : int, float, optional (default=2)<br> 根据属性划分节点时，每个划分最少的样本数。</p>
<pre><code>如果为int，那么考虑min_samples_split作为最小的数字。
如果为float，那么min_samples_split是一个百分比，并且把ceil(min_samples_split*n_samples)是每一个分割最小的样本数量。
</code></pre><p> 在版本0.18中更改：为百分比添加浮点值。<br> 叶子节点最少的样本数。</p>
<pre><code>如果为int，那么考虑min_samples_leaf作为最小的数字。
如果为float，那么min_samples_leaf为一个百分比，并且ceil(min_samples_leaf*n_samples)是每一个节点的最小样本数量。
</code></pre><p> 在版本0.18中更改：为百分比添加浮点值。</p>
</li>
<li><strong>min_weight_fraction_leaf</strong> : float, optional (default=0.)<br> 一个叶子节点所需要的权重总和（所有的输入样本）的最小加权分数。当sample_weight没有提供时，样本具有相同的权重</li>
<li><strong>max_leaf_nodes</strong> : int or None, optional (default=None)<br> 叶子树的最大样本数。<br> 以最优的方法使用max_leaf_nodes来生长树。最好的节点被定义为不纯度上的相对减少。如果为None,那么不限制叶子节点的数量。</li>
<li><strong>min_impurity_split</strong> : float,<br> 树早期生长的阈值。如果一个节点的不纯度超过阈值那么这个节点将会分裂，否则它还是一片叶子。<br> 自0.19版以后不推荐使用：min_impurity_split已被弃用，取而代之的是0.19中的min_impurity_decrease。min_impurity_split将在0.21中被删除。 使用min_impurity_decrease</li>
<li><strong>min_impurity_decrease</strong> : float, optional (default=0.)<br> 如果节点的分裂导致的不纯度的下降程度大于或者等于这个节点的值，那么这个节点将会被分裂。<br> 不纯度加权减少方程式如下：<br> N_t / N <em> (impurity - N_t_R / N_t </em> right_impurity<pre><code>- N_t_L / N_t * left_impurity)
</code></pre> N是样本总的数量，N_t是当前节点处的样本数量，N_t_L是左孩子节点样本的数量,还有N_t_R是右孩子节点的样本数量。<br> N，N_t，N_t_R和N_t_L全部是指加权总和，如果sample_weight通过的话。<br> 0.19版本新加的参数。</li>
<li><strong>bootstrap</strong> : boolean, optional (default=True)<br> 建立决策树时，是否使用有放回抽样。</li>
<li><strong>oob_score</strong> : bool (default=False)<br> 是否使用袋外样本来估计泛化精度。</li>
<li><strong>n_jobs</strong> : integer, optional (default=1)<br> 用于拟合和预测的并行运行的工作（作业）数量。如果值为-1，那么工作数量被设置为核的数量。</li>
<li><strong>random_state</strong> : int, RandomState instance or None, optional (default=None)<br> RandomStateIf int，random_state是随机数生成器使用的种子;<br> 如果是RandomState实例，random_state就是随机数生成器;<br> 如果为None，则随机数生成器是np.random使用的RandomState实例。</li>
<li><strong>verbose</strong> : int, optional (default=0)<br> 控制决策树建立过程的冗余度。</li>
<li><strong>warm_start</strong> : bool, optional (default=False)<br> 当被设置为True时，重新使用之前呼叫的解决方案，用来给全体拟合和添加更多的估计器，反之，仅仅只是为了拟合一个全新的森林。</li>
<li>class_weight : dict, list of dicts, “balanced”,<br> “balanced_subsample” 或者None,（默认值为None）,与格式{class_label: weight}相关联的类的可选的权值。如果没有给值，所有的类到都应该有一个权值。对于多输出问题，一个字典序    列可以按照y的列的顺利被提供。<br> 请注意，对于多输出（包括多标签），其权值应该被定义为它自己字典的每一列的每一个类。例如，对于四类多标签分类，权值应该如[{0: 1, 1: 1}, {0: 1, 1: 5}, {0: 1, 1: 1}, {0: 1, 1: 1}] 这样，而不是[{1:1}, {2:5}, {3:1}, {4:1}].这样。<br> “balanced”模式使用y的值来自动的调整权值，与输入数据中类别频率成反比，如：<pre><code>n_samples / (n_classes * np.bincount(y))
</code></pre> “balanced_subsample”模式和”balanced”相同，除了权值是基于每棵成长树有放回抽样计算的。<br> 对于多输出，y的每列权值将相乘。<br> 请注意，如果指定了sample_weight,这些权值将会和sample_weight相乘（通过拟合方法传递）。</li>
</ul>
<p>Attributes:    属性</p>
<ul>
<li><strong>estimators_</strong> :  决策树分类器的序列<br> 拟合的子估计器的集合。</li>
<li><strong>classes_</strong> :  数组维度=[n_classes]的数组或者一个这样数组的序列。<br> 类别标签（单一输出问题），或者类别标签的数组序列（多输出问题）。</li>
<li><strong>n<em>classes</em></strong> : int or list<br> 类别的数量（单输出问题），或者一个序列，包含每一个输出的类别数量（多输出问题）</li>
<li><strong>n<em>features</em></strong> : int<br> 执行拟合时的特征数量。</li>
<li><strong>n<em>outputs</em></strong> : int<br> 执行拟合时的输出数量。</li>
<li><strong>feature<em>importances</em></strong> : array of shape = [n_features]<br> 特征的重要性（值越高，特征越重要）</li>
<li><strong>oob<em>score</em></strong> : float<br>使用袋外估计获得的训练数据集的得分。</li>
<li><strong>oob_decision<em>function</em></strong> :维度=[n_samples,n_classes]的数组<br> 在训练集上用袋外估计计算的决策函数。如果n_estimators很小的话，那么在有放回抽样中，一个数据点也不会被忽略是可能的。在这种情况下，oob_decision<em>function</em> 可能包括NaN。</li>
</ul>
<p>参数的默认值控制决策树的大小（例如，max_depth，，min_samples_leaf等等），导致完全的生长和在某些数据集上可能非常大的未修剪的树。为了降低内容消耗，决策树的复杂度和大小应该通过设置这些参数值来控制。<br>这些特征总是在每个分割中随机排列。 因此，即使使用相同的训练数据，max_features = n_features和bootstrap = False，如果在搜索最佳分割期间所列举的若干分割的准则的改进是相同的，那么找到的最佳分割点可能会不同。 为了在拟合过程中获得一个确定的行为，random_state将不得不被修正。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;sklearn.ensemble.RandomForestClassifier&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;n_estimators&lt;/strong&gt; : integer, optional (default=10)&lt;br&gt; 森林里（决策）树的数目&lt;/li&gt;

    
    </summary>
    
      <category term="机器学习" scheme="http://yoursite.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="机器学习" scheme="http://yoursite.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>机器学习-梯度下降</title>
    <link href="http://yoursite.com/2018/04/27/Mathematical%20regression%20gradient%20descent/"/>
    <id>http://yoursite.com/2018/04/27/Mathematical regression gradient descent/</id>
    <published>2018-04-27T01:30:00.000Z</published>
    <updated>2018-07-25T16:09:57.310Z</updated>
    
    <content type="html"><![CDATA[<h3 id="梯度下降："><a href="#梯度下降：" class="headerlink" title="梯度下降："></a>梯度下降：</h3><p>批量梯度下降法（Batch Gradient Descent，简称BGD）<br>    优点：全局最优解；易于并行实现；<br>　　缺点：当样本数目很多时，训练过程会很慢。<br>随机梯度下降法（Stochastic Gradient Descent，简称SGD）<br>    优点：训练速度快；迭代次数少<br>    缺点：准确度下降，并不是全局最优；不易于并行实现。<br>小批量梯度下降算法（MBGD）<br>如果损失函数是凸函数，梯度下降法得到的解就一定是全局最优解。</p>
<h4 id="凸凹函数："><a href="#凸凹函数：" class="headerlink" title="凸凹函数："></a>凸凹函数：</h4><p>设f(x)在区间D上连续，如果对D上任意两点a、b恒有<br>f（（a+b）/2）&lt;(f(a)+f(b))/2<br>那么称f(x)在D上的图形是（向上）凹的（或凹弧）；如果恒有<br>f（（a+b）/2）&gt;(f(a)+f(b))/2<br>那么称f(x)在D上的图形是（向上）凸的（或凸弧）</p>
<h3 id="梯度下降相关概念："><a href="#梯度下降相关概念：" class="headerlink" title="梯度下降相关概念："></a>梯度下降相关概念：</h3><ol>
<li>步长（Learning rate）：步长决定了在梯度下降迭代的过程中，每一步沿梯度负方向前进的长度。用上面下山的例子，步长就是在当前这一步所在位置沿着最陡峭最易下山的位置走的那一步的长度。</li>
</ol>
<p>2.特征（feature）：指的是样本中输入部分，比如2个单特征的样本（x(0),y(0)）,（x(1),y(1)）（x(0),y(0)）,（x(1),y(1)）,则第一个样本特征为x(0)x(0)，第一个样本输出为y(0)y(0)。</p>
<ol>
<li><p>假设函数（hypothesis function）：在监督学习中，为了拟合输入样本，而使用的假设函数，记为hθ(x)hθ(x)。比如对于单个特征的m个样本（x(i),y(i)）(i=1,2,…m)（x(i),y(i)）(i=1,2,…m),可以采用拟合函数如下： hθ(x)=θ0+θ1xhθ(x)=θ0+θ1x。</p>
</li>
<li><p>损失函数（loss function）：为了评估模型拟合的好坏，通常用损失函数来度量拟合的程度。损失函数极小化，意味着拟合程度最好，对应的模型参数即为最优参数。在线性回归中，损失函数通常为样本输出和假设函数的差取平方。比如对于m个样本（xi,yi）(i=1,2,…m)（xi,yi）(i=1,2,…m),采用线性回归，损失函数为：</p>
<pre><code>J(θ0,θ1)=∑i=1m(hθ(xi)−yi)2J(θ0,θ1)=∑i=1m(hθ(xi)−yi)2
</code></pre><p>其中xixi表示第i个样本特征，yiyi表示第i个样本对应的输出，hθ(xi)hθ(xi)为假设函数。
　　　　</p>
</li>
</ol>
<h3 id="局部加权回归"><a href="#局部加权回归" class="headerlink" title="局部加权回归"></a>局部加权回归</h3><p>简单来说，这个过程其实是在先拟合出一条曲线，然后再用这个曲线去预测需要预测的点。(源自百度)<br>为什么改进要用加权回归呢？ 很简单，因为非线性拟合出直线误差会很大，这里的局部加权类似于knn算法的权重，即距离中心点越近的权重越大，对拟合曲线的影响也就越大，所以也有了局部加权这一名词</p>
<p>参考文献：<br><a href="https://blog.csdn.net/Gentle_Guan/article/details/76586689?locationNum=8&amp;fps=1" target="_blank" rel="external">https://blog.csdn.net/Gentle_Guan/article/details/76586689?locationNum=8&amp;fps=1</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;梯度下降：&quot;&gt;&lt;a href=&quot;#梯度下降：&quot; class=&quot;headerlink&quot; title=&quot;梯度下降：&quot;&gt;&lt;/a&gt;梯度下降：&lt;/h3&gt;&lt;p&gt;批量梯度下降法（Batch Gradient Descent，简称BGD）&lt;br&gt;    优点：全局最优解；易于并行
    
    </summary>
    
      <category term="机器学习" scheme="http://yoursite.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="机器学习" scheme="http://yoursite.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>机器学习-逻辑回归模型特征处理</title>
    <link href="http://yoursite.com/2018/04/08/Mathematical%20Feature%20processing%20of%20logistic%20regression%20model/"/>
    <id>http://yoursite.com/2018/04/08/Mathematical Feature processing of logistic regression model/</id>
    <published>2018-04-08T01:30:00.000Z</published>
    <updated>2018-07-25T16:10:12.622Z</updated>
    
    <content type="html"><![CDATA[<p>如果有异常值，使用极大-极小归一化或均值-标准差归一化，计算之前需要将极端值排除在外。<br>例如：<br>x’=x−min/ max−min<br>计算max与min时需要用P1与P99来代替。新生成的值如果超过1用1表示，如果小于0 用0表示</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;如果有异常值，使用极大-极小归一化或均值-标准差归一化，计算之前需要将极端值排除在外。&lt;br&gt;例如：&lt;br&gt;x’=x−min/ max−min&lt;br&gt;计算max与min时需要用P1与P99来代替。新生成的值如果超过1用1表示，如果小于0 用0表示&lt;/p&gt;

    
    </summary>
    
      <category term="机器学习" scheme="http://yoursite.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="机器学习" scheme="http://yoursite.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>机器学习-回归算法实例</title>
    <link href="http://yoursite.com/2018/03/27/Mathematical%20regression%20/"/>
    <id>http://yoursite.com/2018/03/27/Mathematical regression /</id>
    <published>2018-03-27T01:30:00.000Z</published>
    <updated>2018-12-21T08:14:28.452Z</updated>
    
    <content type="html"><![CDATA[<h2 id="概念梳理："><a href="#概念梳理：" class="headerlink" title="概念梳理："></a>概念梳理：</h2><p>数学期望：<br>在概率论和统计学中，数学期望(mean)（或均值，亦简称期望）是试验中每次可能结果的概率乘以其结果的总和，是最基本的数学特征之一。它反映随机变量平均取值的大小</p>
<p>方差：<br>（variance)是在概率论和统计方差衡量随机变量或一组数据时离散程度的度量。概率论中方差用来度量随机变量和其数学期望（即均值）之间的偏离程度。统计中的方差（样本方差）是每个样本值与全体样本值的平均数之差的平方值的平均数。在许多实际问题中，研究方差即偏离程度有着重要意义。</p>
<p>概率密度函数：<br>在数学中，连续型随机变量的概率密度函数（在不至于混淆时可以简称为密度函数）是一个描述这个随机变量的输出值，在某个确定的取值点附近的可能性的函数。而随机变量的取值落在某个区域之内的概率则为概率密度函数在这个区域上的积分。当概率密度函数存在的时候，累积分布函数是概率密度函数的积分。概率密度函数一般以小写标记<br>正态分布是重要的概率分布。它的概率密度函数是：<br><img src="http://oh6ybr0jg.bkt.clouddn.com/gailvmidu.jpg" alt="此处输入图片的描述"><br>随着参数μ和σ变化，概率分布也产生变化。<br>期望：μ<br>方差：σ^2<br>中位数：μ<br>众44o6fdeswq    DFGI-数：μ<br>偏度：0<br>峰度：3<br>\]<br><a id="more"></a><br>正态分布：<br>又称为常态分布，高斯分布。<br>若随机变量X服从一个数学期望为μ、方差为σ^2的正态分布，记为N(μ，σ^2)。其概率密度函数为正态分布的期望值μ决定了其位置，其标准差σ决定了分布的幅度。当μ = 0,σ = 1时的正态分布是标准正态分布。</p>
<p>线性回归：<br>线性回归是利用数理统计中回归分析，来确定两种或两种以上变量间相互依赖的定量关系的一种统计分析方法，运用十分广泛。其表达形式为y = w’x+e，e为误差服从均值为0的正态分布。</p>
<p>回归数据：<br><a href="http://archive.ics.uci.edu/ml/datasets/Individual+household+electric+power+consumption" target="_blank" rel="external">http://archive.ics.uci.edu/ml/datasets/Individual+household+electric+power+consumption</a></p>
<p>属性信息：</p>
<p>1.date：格式dd/mm/yyyy日期<br>2.time：格式HH时间：MM：SS<br>3.global_active_power：家用全球分钟平均有功<strong>功率</strong>（千瓦）<br>4.global_reactive_power: 家用全球分钟平均无功<strong>功率</strong>（千瓦）<br>5.voltage：分钟平均<strong>电压</strong>（伏特）<br>6.global_intensity：家用全球分钟平均<strong>电流</strong>强度（安培）<br>7.sub_metering_1：能耗分项计量1号（中有功电能电能）。它与<strong>厨房</strong>相对应，主要包括洗碗机、烤箱和微波炉（热板不是电动的，而是燃气驱动的）。<br>8.sub_metering_2：能耗分项计量2号（中有功电能电能）。它对应<strong>洗衣</strong>房，包括洗衣机、滚筒烘干机、冰箱和灯。<br>9.sub_metering_3：能耗分项计量3号（中有功电能电能）。它相当于一个<strong>电热水器</strong>和一个空调。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</div><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"><span class="keyword">import</span> time</div><div class="line"><span class="keyword">import</span> sklearn</div><div class="line"><span class="keyword">import</span> matplotlib <span class="keyword">as</span> mpl</div><div class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</div><div class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LinearRegression</div><div class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</div><div class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</div><div class="line"></div><div class="line"></div><div class="line">path=<span class="string">'C:/Users/zhanghongming/Documents/data/100.txt'</span></div><div class="line">names = [<span class="string">'Date'</span>,<span class="string">'Time'</span>,<span class="string">'Global_active_power'</span>,<span class="string">'Global_reactive_power'</span>,<span class="string">'Voltage'</span>,<span class="string">'Global_intensity'</span>,<span class="string">'Sub_metering_1'</span>,<span class="string">'Sub_metering_2'</span>,<span class="string">'Sub_metering_3'</span>]</div><div class="line"></div><div class="line"></div><div class="line">df=pd.read_csv(path,sep=<span class="string">';'</span>)</div><div class="line">print(df.head())</div></pre></td></tr></table></figure>
<pre><code>Date      Time  Global_active_power  Global_reactive_power  Voltage  \
</code></pre><p>0  16/12/2006  17:24:00                4.216                  0.418   234.84<br>1  16/12/2006  17:25:00                5.360                  0.436   233.63<br>2  16/12/2006  17:26:00                5.374                  0.498   233.29<br>3  16/12/2006  17:27:00                5.388                  0.502   233.74<br>4  16/12/2006  17:28:00                3.666                  0.528   235.68   </p>
<p>   Global_intensity  Sub_metering_1  Sub_metering_2  Sub_metering_3<br>0              18.4             0.0             1.0            17.0<br>1              23.0             0.0             1.0            16.0<br>2              23.0             0.0             2.0            17.0<br>3              23.0             0.0             1.0            17.0<br>4              15.8             0.0             1.0            17.0  </p>
<h4 id="看所有的变量值"><a href="#看所有的变量值" class="headerlink" title="看所有的变量值"></a>看所有的变量值</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"></div><div class="line"><span class="keyword">for</span> i <span class="keyword">in</span> df.columns:</div><div class="line">    print(df[i].value_counts())</div></pre></td></tr></table></figure>
<p>Name: Date, dtype: int64<br>19:01:00    1<br>17:27:00    1<br>18:24:00    1<br>           ..</p>
<p>Name: Time, Length: 99, dtype: int64<br>4.230    2<br>2.912    2<br>4.218    2<br>6.072    1<br>5.412    1<br>           ..</p>
<p>Name: Global_active_power, Length: 96, dtype: int64<br>0.000    33<br>0.090     7<br>0.054     4<br>0.144     3<br>           ..</p>
<p>Name: Global_reactive_power, dtype: int64<br>235.84    3<br>234.20    2<br>235.68    2<br>233.74    2<br>           ..</p>
<p>Name: Voltage, Length: 90, dtype: int64<br>12.4    7<br>13.8    5<br>15.8    5<br>           ..<br>Name: Global_intensity, dtype: int64<br>0.0    99<br>Name: Sub_metering_1, dtype: int64<br>1.0     50<br>0.0     26<br>2.0      8</p>
<p>Name: Sub_metering_2, dtype: int64<br>17.0    77<br>16.0    18<br>18.0     4</p>
<p>Name: Sub_metering_3, dtype: int64</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#空值处理</span></div><div class="line">new_df= df.replace(<span class="string">'?'</span>,np.nan)</div><div class="line"></div><div class="line">datas = new_df.dropna(how=<span class="string">'any'</span>)</div><div class="line"></div><div class="line"><span class="comment">#定义时间格式化</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">datae_format</span><span class="params">(dt)</span>:</span></div><div class="line">    t = time.strptime(<span class="string">' '</span>.join(dt),<span class="string">'%d/%m/%Y %H:%M:%S'</span>)</div><div class="line">    <span class="keyword">return</span> (t.tm_year,t.tm_mon,t.tm_mday,t.tm_hour,t.tm_min,t.tm_sec)</div><div class="line"></div><div class="line"><span class="comment">##分析功率和时间的线性关系。将时间转换为连续的</span></div><div class="line"></div><div class="line">X = datas[names[<span class="number">0</span>:<span class="number">2</span>]]</div><div class="line">X = X.apply(<span class="keyword">lambda</span> x :pd.Series(datae_format(x)),axis=<span class="number">1</span>)</div><div class="line">Y = datas[names[<span class="number">2</span>]]</div><div class="line"></div><div class="line"></div><div class="line">print(X.head(<span class="number">5</span>))</div><div class="line">print(Y.head(<span class="number">5</span>))</div></pre></td></tr></table></figure>
<pre><code>0   1   2   3   4  5
</code></pre><p>0  2006  12  16  17  24  0<br>1  2006  12  16  17  25  0<br>2  2006  12  16  17  26  0<br>3  2006  12  16  17  27  0<br>4  2006  12  16  17  28  0<br>0    4.216<br>1    5.360<br>2    5.374<br>3    5.388<br>4    3.666<br>Name: Global_active_power, dtype: float64</p>
<h6 id="函数讲解"><a href="#函数讲解" class="headerlink" title="函数讲解"></a>函数讲解</h6><p>sklearn.model_selection.train_test_split随机划分训练集和测试集<br>一般形式：<br>train_test_split是交叉验证中常用的函数，功能是从样本中随机的按比例选取train data和testdata，形式为：<br>X_train,X_test, y_train, y_test =<br>cross_validation.train_test_split(train_data,train_target,test_size=0.4, random_state=0)<br>参数解释：<br>train_data：所要划分的样本特征集<br>train_target：所要划分的样本结果<br>test_size：样本占比，如果是整数的话就是样本的数量<br>random_state：是随机数的种子。<br>随机数种子：其实就是该组随机数的编号，在需要重复试验的时候，保证得到一组一样的随机数。比如你每次都填1，其他参数一样的情况下你得到的随机数组是一样的。但填0或不填，每次都会不一样。<br>随机数的产生取决于种子，随机数和种子之间的关系遵从以下两个规则：<br>种子不同，产生不同的随机数；种子相同，即使实例不同也产生相同的随机数。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line">X_train,X_test,Y_train,Y_test = train_test_split( X, Y, test_size=<span class="number">0.2</span>, random_state=<span class="number">42</span>)</div><div class="line"></div><div class="line"></div><div class="line"><span class="comment">## 数据标准换行</span></div><div class="line">ss = StandardScaler()</div><div class="line">X_train = ss.fit_transform(X_train)</div><div class="line">X_test = ss.fit_transform(X_test)</div><div class="line"></div><div class="line"></div><div class="line"><span class="comment">##训练数据</span></div><div class="line">lr = LinearRegression()</div><div class="line">lr.fit(X_train,Y_train)</div><div class="line"></div><div class="line"><span class="comment">##预测Y值</span></div><div class="line">y_predict = lr.predict(X_test)</div><div class="line"></div><div class="line">print(<span class="string">"准确率:"</span>,lr.score(X_test,Y_test))</div></pre></td></tr></table></figure>
<p>样本数据100条：<br>准确率: 0.0226499044921<br>样本数据1000条：<br>0.103073016594</p>
<p>模型保存及加载：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> sklearn.externals <span class="keyword">import</span> joblib</div><div class="line"><span class="comment">## 模型保存：</span></div><div class="line">joblib.dump(ss,<span class="string">"data_ss.model"</span>)</div><div class="line">joblib.dump(lr,<span class="string">"data_lr.model"</span>)</div><div class="line"></div><div class="line"><span class="comment">## 加载模型</span></div><div class="line">joblib,load(<span class="string">"data_ss.model"</span>)</div><div class="line">joblib,load(<span class="string">"data_lr.model"</span>)</div></pre></td></tr></table></figure></p>
<p>plot文档：<br><a href="https://matplotlib.org/api/pyplot_api.html#matplotlib.pyplot.plot" target="_blank" rel="external">https://matplotlib.org/api/pyplot_api.html#matplotlib.pyplot.plot</a></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line"><span class="comment">## 解决中文问题</span></div><div class="line">mpl.rcParams[<span class="string">'font.sans-serif'</span>] = [<span class="string">u'SimHei'</span>];</div><div class="line">mpl.rcParams[<span class="string">'axes.unicode_minus'</span>] = <span class="keyword">False</span></div><div class="line"></div><div class="line">t=np.arange(len(X_test))</div><div class="line">plt.figure(facecolor=<span class="string">'w'</span>)</div><div class="line">plt.plot(t,Y_test,<span class="string">'r--'</span>,linewidth=<span class="number">2</span>,label=<span class="string">u'真实值'</span>)</div><div class="line">plt.plot(t,y_predict,<span class="string">'g--'</span>,linewidth=<span class="number">2</span>,label=<span class="string">u'预测值'</span>)</div><div class="line">plt.legend(loc =<span class="string">'lower right'</span>)</div><div class="line">plt.title(<span class="string">u'线性回归时间与电压的关系'</span>,fontsize=<span class="number">20</span> )</div><div class="line">plt.grid(b=<span class="keyword">True</span>)</div><div class="line">plt.show()</div></pre></td></tr></table></figure>
<p>100条数据：<br><img src="http://oh6ybr0jg.bkt.clouddn.com/linear_regression_100.png" alt="此处输入图片的描述"></p>
<p>1000条数据：<br><img src="http://oh6ybr0jg.bkt.clouddn.com/linear_regression_1000.png" alt="此处输入图片的描述"></p>
<h3 id="linear多项式"><a href="#linear多项式" class="headerlink" title="linear多项式"></a>linear多项式</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> sklearn.pipeline <span class="keyword">import</span> Pipeline</div><div class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> PolynomialFeatures</div><div class="line"><span class="keyword">from</span> sklearn.grid_search <span class="keyword">import</span> GridSearchCV</div><div class="line">models = [Pipeline([(<span class="string">'Poly'</span>,PolynomialFeatures()),(<span class="string">'Linear'</span>,LinearRegression())])]</div><div class="line">model = models[<span class="number">0</span>]</div><div class="line"></div><div class="line"></div><div class="line"><span class="comment">##获取X，Y变量，并将时间变量转换为数值型连续的</span></div><div class="line">X = datas[names[<span class="number">0</span>:<span class="number">2</span>]]</div><div class="line">X = X.apply(<span class="keyword">lambda</span> x :pd.Series(datae_format(x)),axis=<span class="number">1</span>)</div><div class="line">Y = datas[names[<span class="number">4</span>]]</div><div class="line"></div><div class="line"><span class="comment">## 对数据集进行划分</span></div><div class="line">X_train,X_test,Y_train,Y_test = train_test_split( X, Y, test_size=<span class="number">0.2</span>, random_state=<span class="number">0</span>)</div><div class="line"></div><div class="line"><span class="comment">## 数据标准化</span></div><div class="line">ss = StandardScaler()</div><div class="line">X_train = ss.fit_transform(X_train)</div><div class="line">X_test = ss.fit_transform(X_test)</div><div class="line"></div><div class="line"><span class="comment">## 模型训练</span></div><div class="line">t=np.arange(len(X_test))</div><div class="line">N =<span class="number">5</span></div><div class="line">d_pool= np.arange(<span class="number">1</span>,N,<span class="number">1</span>)</div><div class="line">m=d_pool.size</div><div class="line">clrs = []  <span class="comment"># 颜色</span></div><div class="line"><span class="keyword">for</span> c <span class="keyword">in</span> np.linspace(<span class="number">16711680</span>, <span class="number">255</span>, m,dtype=<span class="string">'int64'</span>):</div><div class="line">    clrs.append(<span class="string">'#%06x'</span> % c)</div><div class="line">line_width = <span class="number">3</span></div><div class="line"></div><div class="line">plt.figure(figsize=(<span class="number">12</span>,<span class="number">6</span>),facecolor=<span class="string">'w'</span>)</div><div class="line"><span class="keyword">for</span> i,d <span class="keyword">in</span> enumerate(d_pool):</div><div class="line">    plt.subplot(N<span class="number">-1</span>,<span class="number">1</span>,i+<span class="number">1</span>)</div><div class="line">    plt.plot(t,Y_test,<span class="string">'r--'</span>,label=<span class="string">u'真实值'</span>,ms=<span class="number">10</span>,zorder=N)</div><div class="line">    model.set_params(Poly__degree=d) <span class="comment"># 设置多项式的阶</span></div><div class="line">    model.fit(X_train,Y_train)</div><div class="line">    lin = model.get_params(<span class="string">'Linear'</span>)[<span class="string">'Linear'</span>]</div><div class="line">    output =<span class="string">u'%d阶，系数为：'</span>%d</div><div class="line">    print( output,lin.coef_.ravel())</div><div class="line"></div><div class="line">    y_hat = model.predict(X_test)</div><div class="line">    s = model.score(X_test,Y_test)</div><div class="line"></div><div class="line">    z=N<span class="number">-1</span> <span class="keyword">if</span> (d==<span class="number">2</span>) <span class="keyword">else</span> <span class="number">0</span></div><div class="line">    label=<span class="string">u'%d阶,准确率=%.3f'</span>%(d,s)</div><div class="line"></div><div class="line"></div><div class="line">    plt.plot(t,y_hat,color=clrs[i],lw=line_width,alpha = <span class="number">0.75</span>,label=label,zorder=z)</div><div class="line">    plt.legend(loc = <span class="string">'upper left'</span>)</div><div class="line">    plt.grid(<span class="keyword">True</span>)</div><div class="line">    plt.ylabel(<span class="string">u'%d阶结果'</span>%d,fontsize=<span class="number">12</span>)</div><div class="line"></div><div class="line"><span class="comment"># 预测值和真实值画图比较</span></div><div class="line">plt.legend(loc = <span class="string">'lower right'</span>)</div><div class="line">plt.suptitle(<span class="string">u'线性回归时间与电压之间多项式关系'</span>)</div><div class="line">plt.grid(b=<span class="keyword">True</span>)</div><div class="line">plt.show()</div></pre></td></tr></table></figure>
<p>1阶，系数为： [  0.00000000e+00   5.55111512e-17   0.00000000e+00   0.00000000e+00<br>  -4.22939297e-01  -4.34494704e-01   0.00000000e+00]<br>2阶，系数为： [  2.47983335e-17   1.11022302e-16  -2.22044605e-16  -1.11022302e-16<br>  -5.05820937e-01  -3.46571423e-01   0.00000000e+00   0.00000000e+00<br>   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00<br>   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00<br>   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00<br>   0.00000000e+00   0.00000000e+00  -8.58357173e-01  -7.57689882e-01<br>   0.00000000e+00  -1.60364055e-01   0.00000000e+00   0.00000000e+00]<br>3阶，系数为： [ -1.69309011e-15  -2.99760217e-15   3.33066907e-16   5.55111512e-16<br>  -4.41970713e-02  -3.57278153e-01   0.00000000e+00   2.22044605e-16<br>   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00<br>   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00<br>   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00<br>   0.00000000e+00   0.00000000e+00   3.43644538e-01   4.86208530e-01<br>   0.00000000e+00   3.26242425e-02   0.00000000e+00   0.00000000e+00<br>   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00<br>   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00<br>   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00<br>   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00<br>   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00<br>   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00<br>   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00<br>   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00<br>   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00<br>   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00<br>   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00<br>   0.00000000e+00   0.00000000e+00   4.48140740e-01   6.37890832e-01<br>   0.00000000e+00  -7.45035081e-01   0.00000000e+00   0.00000000e+00<br>  -5.02511111e-01   0.00000000e+00   0.00000000e+00   0.00000000e+00]<br>4阶，系数为： [  2.22002972e-013  -8.01497757e-013   5.37209166e-014  -4.53519167e-013<br>   7.19933381e-003   2.05441337e-001   3.86510268e-013  -5.94066463e-013<br>   6.66133815e-015   6.66133815e-016  -1.88737914e-015   6.27276009e-015<br>  -5.30131494e-015  -1.01585407e-014   3.35287353e-014   8.21565038e-015<br>  -2.55351296e-015  -2.22044605e-016  -6.31088724e-030   3.02922588e-028<br>   1.00974196e-028  -5.04870979e-029  -4.89052469e-002   3.28220946e-001<br>   0.00000000e+000   6.15440583e-003   0.00000000e+000   0.00000000e+000<br>   1.26217745e-029   0.00000000e+000  -5.60519386e-044  -8.40779079e-045<br>  -7.00649232e-045  -2.24207754e-044  -5.60519386e-045   2.80259693e-045<br>   1.40129846e-045   0.00000000e+000   0.00000000e+000   4.97841222e-060<br>   1.55575382e-061  -1.24460306e-060  -2.48920611e-060   0.00000000e+000<br>  -3.11150764e-061  -1.16681536e-061  -3.11150764e-061  -4.66726146e-061<br>   2.21085915e-075  -5.52714788e-076  -1.38178697e-076   2.76357394e-076<br>  -1.38178697e-076  -3.45446742e-077   0.00000000e+000   1.34940134e-079<br>   0.00000000e+000   1.91761463e-093   1.49813643e-095  -5.99254573e-095<br>   4.49440930e-095   1.12360233e-095   0.00000000e+000   7.49068217e-096<br>  -2.34083818e-097   0.00000000e+000   0.00000000e+000   0.00000000e+000<br>   0.00000000e+000   0.00000000e+000  -1.66326556e-111   4.15816391e-112<br>  -2.07908195e-112   0.00000000e+000  -6.13741990e-002  -8.70197287e-001<br>   8.39734513e-140  -1.48604949e+000   0.00000000e+000   0.00000000e+000<br>  -4.67097255e-001   0.00000000e+000   0.00000000e+000   0.00000000e+000<br>   0.00000000e+000   0.00000000e+000   0.00000000e+000   0.00000000e+000<br>   0.00000000e+000   0.00000000e+000   0.00000000e+000   0.00000000e+000<br>   0.00000000e+000   0.00000000e+000   0.00000000e+000   0.00000000e+000<br>   0.00000000e+000   0.00000000e+000   0.00000000e+000   0.00000000e+000<br>   0.00000000e+000   0.00000000e+000   0.00000000e+000   0.00000000e+000<br>   0.00000000e+000   0.00000000e+000   0.00000000e+000   0.00000000e+000<br>   0.00000000e+000   0.00000000e+000   0.00000000e+000   0.00000000e+000<br>   0.00000000e+000   0.00000000e+000   0.00000000e+000   0.00000000e+000<br>   0.00000000e+000   0.00000000e+000   0.00000000e+000   0.00000000e+000<br>   0.00000000e+000   0.00000000e+000   0.00000000e+000   0.00000000e+000<br>   0.00000000e+000   0.00000000e+000   0.00000000e+000   0.00000000e+000<br>   0.00000000e+000   0.00000000e+000   0.00000000e+000   0.00000000e+000<br>   0.00000000e+000   0.00000000e+000   0.00000000e+000   0.00000000e+000<br>   0.00000000e+000   0.00000000e+000   0.00000000e+000   0.00000000e+000<br>   0.00000000e+000   0.00000000e+000   0.00000000e+000   0.00000000e+000<br>   0.00000000e+000   0.00000000e+000   0.00000000e+000   0.00000000e+000<br>   0.00000000e+000   0.00000000e+000   0.00000000e+000   0.00000000e+000<br>   0.00000000e+000   0.00000000e+000   0.00000000e+000   0.00000000e+000<br>   0.00000000e+000   0.00000000e+000   0.00000000e+000   0.00000000e+000<br>   0.00000000e+000   0.00000000e+000   0.00000000e+000   0.00000000e+000<br>   0.00000000e+000   0.00000000e+000   0.00000000e+000   0.00000000e+000<br>   0.00000000e+000   0.00000000e+000   0.00000000e+000   0.00000000e+000<br>   0.00000000e+000   0.00000000e+000   0.00000000e+000   0.00000000e+000<br>   0.00000000e+000   0.00000000e+000   0.00000000e+000   0.00000000e+000<br>   0.00000000e+000   0.00000000e+000   0.00000000e+000   0.00000000e+000<br>   0.00000000e+000   0.00000000e+000   0.00000000e+000   0.00000000e+000<br>   0.00000000e+000   0.00000000e+000   0.00000000e+000   0.00000000e+000<br>   0.00000000e+000   0.00000000e+000   0.00000000e+000  -2.42848401e-001<br>  -9.28403263e-001   0.00000000e+000  -8.91115491e-001   0.00000000e+000<br>   0.00000000e+000   1.33924630e-001   0.00000000e+000   0.00000000e+000<br>   0.00000000e+000   2.81909059e-001   0.00000000e+000   0.00000000e+000<br>   0.00000000e+000   0.00000000e+000]</p>
<p>   <img src="http://oh6ybr0jg.bkt.clouddn.com/linear_regression_polynomial.png" alt="此处输入图片的描述"></p>
]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;概念梳理：&quot;&gt;&lt;a href=&quot;#概念梳理：&quot; class=&quot;headerlink&quot; title=&quot;概念梳理：&quot;&gt;&lt;/a&gt;概念梳理：&lt;/h2&gt;&lt;p&gt;数学期望：&lt;br&gt;在概率论和统计学中，数学期望(mean)（或均值，亦简称期望）是试验中每次可能结果的概率乘以其结果的总和，是最基本的数学特征之一。它反映随机变量平均取值的大小&lt;/p&gt;
&lt;p&gt;方差：&lt;br&gt;（variance)是在概率论和统计方差衡量随机变量或一组数据时离散程度的度量。概率论中方差用来度量随机变量和其数学期望（即均值）之间的偏离程度。统计中的方差（样本方差）是每个样本值与全体样本值的平均数之差的平方值的平均数。在许多实际问题中，研究方差即偏离程度有着重要意义。&lt;/p&gt;
&lt;p&gt;概率密度函数：&lt;br&gt;在数学中，连续型随机变量的概率密度函数（在不至于混淆时可以简称为密度函数）是一个描述这个随机变量的输出值，在某个确定的取值点附近的可能性的函数。而随机变量的取值落在某个区域之内的概率则为概率密度函数在这个区域上的积分。当概率密度函数存在的时候，累积分布函数是概率密度函数的积分。概率密度函数一般以小写标记&lt;br&gt;正态分布是重要的概率分布。它的概率密度函数是：&lt;br&gt;&lt;img src=&quot;http://oh6ybr0jg.bkt.clouddn.com/gailvmidu.jpg&quot; alt=&quot;此处输入图片的描述&quot;&gt;&lt;br&gt;随着参数μ和σ变化，概率分布也产生变化。&lt;br&gt;期望：μ&lt;br&gt;方差：σ^2&lt;br&gt;中位数：μ&lt;br&gt;众44o6fdeswq    DFGI-数：μ&lt;br&gt;偏度：0&lt;br&gt;峰度：3&lt;br&gt;\]&lt;br&gt;
    
    </summary>
    
      <category term="机器学习" scheme="http://yoursite.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="机器学习" scheme="http://yoursite.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>scikit-learn pca</title>
    <link href="http://yoursite.com/2018/03/03/scikit-learn%20pca/"/>
    <id>http://yoursite.com/2018/03/03/scikit-learn pca/</id>
    <published>2018-03-03T03:06:30.000Z</published>
    <updated>2018-12-21T08:14:17.397Z</updated>
    
    <content type="html"><![CDATA[<p>from sklearn import datasets</p>
<p>digits = datasets.load_digits()<br>x = digits.data<br>y = digits.target</p>
<p>from sklearn.model_selection import  train_test_split<br>x_train,x_test,y_train,y_test = train_test_split(x,y,random_state=666)</p>
<p>print(x_train.shape)</p>
<p>#(1347, 64)<br>from sklearn.neighbors import KNeighborsClassifier<br>import time<br>start = time.clock()<br>knn_clf = KNeighborsClassifier()</p>
<p>knn_clf.fit(x_train,y_train)<br>end = time.clock()</p>
<p>print(end-start)</p>
<p>#0.009107513739889835<br>score = knn_clf.score(x_test,y_test)</p>
<p>print(score)</p>
<p>#0.986666666667</p>
<p>from sklearn.decomposition import  PCA</p>
<p>pca = PCA(n_components=2)<br>pca.fit(x_train)<br>X_train_reduction = pca.transform(x_train)<br>X_test_reduction = pca.transform(x_test)</p>
<p>start2 = time.clock()<br>knn_clf = KNeighborsClassifier()<br>knn_clf.fit(X_train_reduction,y_train)<br>end2 = time.clock()</p>
<p>print(end2-start2)</p>
<p>#0.0019209365663966915<br>score = knn_clf.score(X_test_reduction,y_test)<br>print(score)</p>
<p>#0.606666666667</p>
<p>print(pca.explained<em>variance</em>)</p>
<p>pca = PCA(n_components=x_train.shape[1])</p>
<p>pca3 = PCA(0.95)<br>pca3.fit(x_train)<br>print(pca3.n<em>components</em>)</p>
<p>#28</p>
<p>start3 = time.clock()<br>knn_clf3 = KNeighborsClassifier()<br>X_train_reduction = pca3.transform(x_train)<br>X_test_reduction = pca3.transform(x_test)<br>knn_clf3.fit(X_train_reduction,y_train)<br>end3 = time.clock()</p>
<p>print(end3-start3)</p>
<p>#0.006395458395239972<br>score = knn_clf3.score(X_test_reduction,y_test)<br>print(score)</p>
<p>#0.98</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;from sklearn import datasets&lt;/p&gt;
&lt;p&gt;digits = datasets.load_digits()&lt;br&gt;x = digits.data&lt;br&gt;y = digits.target&lt;/p&gt;
&lt;p&gt;from sklearn.model_sel
    
    </summary>
    
    
      <category term="机器学习" scheme="http://yoursite.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>scikit-learn KNN</title>
    <link href="http://yoursite.com/2018/03/02/scikit-learn%20KNN/"/>
    <id>http://yoursite.com/2018/03/02/scikit-learn KNN/</id>
    <published>2018-03-02T02:06:30.000Z</published>
    <updated>2018-12-21T08:14:37.220Z</updated>
    
    <content type="html"><![CDATA[<p>地址：<br><a href="http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#sklearn.neighbors.KNeighborsClassifier" target="_blank" rel="external">http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#sklearn.neighbors.KNeighborsClassifier</a></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> KNeighborsClassifier</div><div class="line"></div><div class="line">X = [[<span class="number">0</span>], [<span class="number">1</span>], [<span class="number">2</span>], [<span class="number">3</span>]]</div><div class="line">y = [<span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">1</span>]</div><div class="line">neigh = KNeighborsClassifier(n_neighbors=<span class="number">3</span>)</div><div class="line">neigh.fit(X, y)</div><div class="line"></div><div class="line">print(neigh.predict([[<span class="number">1.1</span>]]))</div><div class="line"><span class="comment"># [0]</span></div><div class="line">print(neigh.predict_proba([[<span class="number">0.9</span>]]))</div><div class="line"><span class="comment">#[[ 0.66666667  0.33333333]]</span></div></pre></td></tr></table></figure>
<a id="more"></a>
<p>手写数字练习：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets</div><div class="line"></div><div class="line">digits = datasets.load_digits()</div><div class="line">x= digits.data</div><div class="line">y= digits.target</div><div class="line">print(x.shape)</div><div class="line"><span class="comment">#(1797, 64)</span></div><div class="line"></div><div class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span>  train_test_split</div><div class="line">x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=<span class="number">0.2</span>,random_state=<span class="number">666</span>)</div><div class="line"></div><div class="line"></div><div class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> KNeighborsClassifier</div><div class="line"></div><div class="line">knn_clf = KNeighborsClassifier(n_neighbors=<span class="number">3</span>)</div><div class="line">knn_clf.fit(x_train,y_train)</div><div class="line">score= knn_clf.score(x_test,y_test)</div><div class="line">print(score)</div><div class="line"><span class="comment">#0.988888888889</span></div></pre></td></tr></table></figure>
<p>查找最佳超参数<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line">beat_score=<span class="number">0</span></div><div class="line">break_k =<span class="number">-1</span></div><div class="line"><span class="keyword">for</span> k <span class="keyword">in</span> range(<span class="number">1</span>,<span class="number">11</span>):</div><div class="line">    knn_clf2 = KNeighborsClassifier(n_neighbors=k)</div><div class="line">    knn_clf2.fit(x_train,y_train)</div><div class="line">    score= knn_clf2.score(x_test,y_test)</div><div class="line">    <span class="keyword">if</span>(score &gt;beat_score):</div><div class="line">        break_k =k</div><div class="line">        beat_score = score</div><div class="line"></div><div class="line">print(<span class="string">"beat_score"</span>,beat_score)</div><div class="line">print(<span class="string">"break_k"</span>,break_k)</div></pre></td></tr></table></figure></p>
<p>beat_score 0.991666666667<br>break_k 4</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line">beat_score=<span class="number">0</span></div><div class="line">break_k =<span class="number">-1</span></div><div class="line">beat_method=<span class="string">''</span></div><div class="line"><span class="keyword">for</span> method <span class="keyword">in</span> [<span class="string">'uniform'</span>,<span class="string">'distance'</span>]:</div><div class="line">    <span class="keyword">for</span> k <span class="keyword">in</span> range(<span class="number">1</span>,<span class="number">11</span>):</div><div class="line">        knn_clf2 = KNeighborsClassifier(n_neighbors=k,weights=method)</div><div class="line">        knn_clf2.fit(x_train,y_train)</div><div class="line">        score= knn_clf2.score(x_test,y_test)</div><div class="line">        <span class="keyword">if</span>(score &gt;beat_score):</div><div class="line">            beat_method = method</div><div class="line">            break_k =k</div><div class="line">            beat_score = score</div><div class="line"></div><div class="line">print(<span class="string">"beat_score"</span>,beat_score)</div><div class="line">print(<span class="string">"break_k"</span>,break_k)</div></pre></td></tr></table></figure>
<p>网格搜素：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> time</div><div class="line">start = time.clock()</div><div class="line">param_grid=[</div><div class="line">    &#123;</div><div class="line">        <span class="string">'weights'</span>:[<span class="string">'uniform'</span>],</div><div class="line">        <span class="string">'n_neighbors'</span>:[i  <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>,<span class="number">11</span>)]</div><div class="line">    &#125;,</div><div class="line">    &#123;</div><div class="line">        <span class="string">'weights'</span>:[<span class="string">'distance'</span>],</div><div class="line">        <span class="string">'n_neighbors'</span>:[i  <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>,<span class="number">11</span>)],</div><div class="line">        <span class="string">'p'</span>:[i  <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>,<span class="number">6</span>)]</div><div class="line">    &#125;</div><div class="line">]</div><div class="line"></div><div class="line">knn_clf = KNeighborsClassifier()</div><div class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span>  GridSearchCV</div><div class="line">grid_search = GridSearchCV(knn_clf,param_grid)</div><div class="line">grid_search.fit(x_train,y_train)</div><div class="line">print(<span class="string">"grid_search.best_estimator_:"</span>,grid_search.best_estimator_)</div><div class="line">print(<span class="string">"grid_search.best_score_:"</span>,grid_search.best_score_)</div><div class="line">print(<span class="string">"grid_search.best_params_:"</span>,grid_search.best_params_)</div><div class="line"></div><div class="line">knn_clf = grid_search.best_estimator_</div><div class="line">knn_clf_score = knn_clf.score(x_test,y_test)</div><div class="line">print(knn_clf_score)</div><div class="line">end = time.clock()</div><div class="line">print(end-start)</div></pre></td></tr></table></figure></p>
<p>grid_search.best<em>estimator</em>: KNeighborsClassifier(algorithm=’auto’, leaf_size=30, metric=’minkowski’,<br>           metric_params=None, n_jobs=1, n_neighbors=3, p=3,<br>           weights=’distance’)<br>grid_search.best<em>score</em>: 0.985386221294<br>grid_search.best<em>params</em>: {‘n_neighbors’: 3, ‘p’: 3, ‘weights’: ‘distance’}<br>0.983333333333<br>296.18877317471</p>
<p>增加并行化处理：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">grid_search = GridSearchCV(knn_clf,param_grid,n_jobs=<span class="number">2</span>,verbose=<span class="number">2</span>)</div></pre></td></tr></table></figure></p>
<p>速度变为：156.67693082041933</p>
<p>最值归一化：<br>适用于分布有明显边界的情况，受outlier影响较大<br>均值方差归一化：<br>适用于分布没有明显边界的情况，有可能存在极端数值</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;地址：&lt;br&gt;&lt;a href=&quot;http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#sklearn.neighbors.KNeighborsClassifier&quot;&gt;http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#sklearn.neighbors.KNeighborsClassifier&lt;/a&gt;&lt;/p&gt;
&lt;figure class=&quot;highlight python&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;2&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;3&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;4&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;5&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;6&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;7&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;8&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;9&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;10&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;11&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;from&lt;/span&gt; sklearn.neighbors &lt;span class=&quot;keyword&quot;&gt;import&lt;/span&gt; KNeighborsClassifier&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;X = [[&lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;], [&lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;], [&lt;span class=&quot;number&quot;&gt;2&lt;/span&gt;], [&lt;span class=&quot;number&quot;&gt;3&lt;/span&gt;]]&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;y = [&lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;, &lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;, &lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;, &lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;]&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;neigh = KNeighborsClassifier(n_neighbors=&lt;span class=&quot;number&quot;&gt;3&lt;/span&gt;)&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;neigh.fit(X, y)&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;print(neigh.predict([[&lt;span class=&quot;number&quot;&gt;1.1&lt;/span&gt;]]))&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# [0]&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;print(neigh.predict_proba([[&lt;span class=&quot;number&quot;&gt;0.9&lt;/span&gt;]]))&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;#[[ 0.66666667  0.33333333]]&lt;/span&gt;&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
    
    </summary>
    
    
      <category term="机器学习" scheme="http://yoursite.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>scikit-learn regression</title>
    <link href="http://yoursite.com/2018/03/01/scikit-learn%20regression/"/>
    <id>http://yoursite.com/2018/03/01/scikit-learn regression/</id>
    <published>2018-03-01T03:06:30.000Z</published>
    <updated>2018-12-21T08:14:24.851Z</updated>
    
    <content type="html"><![CDATA[<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets</div><div class="line"></div><div class="line">boston = datasets.load_boston()</div><div class="line">x= boston.data</div><div class="line">y= boston.targe</div><div class="line"></div><div class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span>  train_test_split</div><div class="line">x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=<span class="number">0.2</span>,random_state=<span class="number">666</span>)</div><div class="line"></div><div class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> linear_model</div><div class="line">clf = linear_model.LinearRegression()</div><div class="line"></div><div class="line">clf.fit(x_train,y_train)</div><div class="line">y_predict = clf.predict(x_test)</div><div class="line"></div><div class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> mean_squared_error</div><div class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> mean_absolute_error</div><div class="line"></div><div class="line">MSE = mean_squared_error(y_test,y_predict)</div><div class="line">print(MSE)</div><div class="line">MAE = mean_absolute_error(y_test,y_predict)</div><div class="line">print(MAE)</div></pre></td></tr></table></figure>
]]></content>
    
    <summary type="html">
    
      &lt;figure class=&quot;highlight python&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;2&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;3&lt;/d
    
    </summary>
    
    
      <category term="机器学习" scheme="http://yoursite.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>机器学习-决策树算法实例</title>
    <link href="http://yoursite.com/2018/02/18/Mathematical%20decision%20tree/"/>
    <id>http://yoursite.com/2018/02/18/Mathematical decision tree/</id>
    <published>2018-02-18T01:30:00.000Z</published>
    <updated>2018-07-25T16:10:05.738Z</updated>
    
    <content type="html"><![CDATA[<h2 id="决策树："><a href="#决策树：" class="headerlink" title="决策树："></a>决策树：</h2><p>有监督学习方法<br>是一种预测模型<br>是在已知各种情况发生概率基础上，通过构建决策树来进行分析的一种方法</p>
<h3 id="树形结构"><a href="#树形结构" class="headerlink" title="树形结构"></a>树形结构</h3><p>从跟节点开始，预测待分类项对应的特征属性，按照值选择输出分支，直到叶子节点，将叶子节点的存放类别作为树的结果</p>
<p>决策树分为两类：<br>分类，回归<br>前者用于分类标签值，后者用于预测连续值<br>常用算法ID3，C4,5，CART</p>
<h3 id="数据标准化："><a href="#数据标准化：" class="headerlink" title="数据标准化："></a>数据标准化：</h3><p>StandardScaler (基于特征矩阵的列，将属性值转换至服从正态分布)<br>标准化是依照特征矩阵的列处理数据，其通过求z-score的方法，将样本的特征值转换到同一量纲下<br>常用与基于正态分布的算法，比如回归<br>数据归一化<br>MinMaxScaler （区间缩放，基于最大最小值，将数据转换到0,1区间上的）<br>提升模型收敛速度，提升模型精度<br>常见用于神经网络<br>Normalizer （基于矩阵的行，将样本向量转换为单位向量）<br>其目的在于样本向量在点乘运算或其他核函数计算相似性时，拥有统一的标准<br>常见用于文本分类和聚类、logistic回归中也会使用，有效防止过拟合</p>
<h3 id="特征选择："><a href="#特征选择：" class="headerlink" title="特征选择："></a>特征选择：</h3><p>从已有的特征中选择出影响目标值最大的特征属性</p>
<h2 id="常用方法：-分类：F统计量、卡方系数，互信息mutual-info-classif"><a href="#常用方法：-分类：F统计量、卡方系数，互信息mutual-info-classif" class="headerlink" title="常用方法：{ 分类：F统计量、卡方系数，互信息mutual_info_classif"></a>常用方法：{ 分类：F统计量、卡方系数，互信息mutual_info_classif</h2><pre><code>{ 连续：皮尔逊相关系数 F统计量 互信息mutual_info_classif
</code></pre><h2 id="SelectKBest（卡方系数）"><a href="#SelectKBest（卡方系数）" class="headerlink" title="SelectKBest（卡方系数）"></a>SelectKBest（卡方系数）</h2>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;决策树：&quot;&gt;&lt;a href=&quot;#决策树：&quot; class=&quot;headerlink&quot; title=&quot;决策树：&quot;&gt;&lt;/a&gt;决策树：&lt;/h2&gt;&lt;p&gt;有监督学习方法&lt;br&gt;是一种预测模型&lt;br&gt;是在已知各种情况发生概率基础上，通过构建决策树来进行分析的一种方法&lt;/p&gt;
&lt;h
    
    </summary>
    
      <category term="机器学习" scheme="http://yoursite.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="机器学习" scheme="http://yoursite.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>设计模式-结构模式</title>
    <link href="http://yoursite.com/2018/02/11/Design%20pattern%20structural/"/>
    <id>http://yoursite.com/2018/02/11/Design pattern structural/</id>
    <published>2018-02-11T01:30:00.000Z</published>
    <updated>2018-07-25T16:17:19.158Z</updated>
    
    <content type="html"><![CDATA[<h3 id="1-适配器"><a href="#1-适配器" class="headerlink" title="1.适配器"></a>1.适配器</h3><p>效果及优缺点：<br>对于类适配器：</p>
<ol>
<li>用一个具体的Adapter类对Adaptee和Taget进行匹配。结果是当我们想要匹配一个类以及所有它的子类时，类Adapter将不能胜任工作。</li>
<li>使得Adapter可以override（重定义） Adaptee的部分行为，因为Adapter是Adaptee的一个子类。<br>对于对象适配器：</li>
<li>允许一个Adapter与多个Adaptee，即Adaptee本身以及它的所有子类（如果有子类的话）同时工作。Adapter也可以一次给所有的Adaptee添加功能。</li>
<li>使得override（重定义）Adaptee的行为比较困难。如果一定要override Adaptee的方法，就只好先做一个Adaptee的子类以override Adaptee的方法，然后再把这个子类当作真正的Adaptee源进行适配。</li>
</ol>
<h3 id="2-桥接"><a href="#2-桥接" class="headerlink" title="2.桥接"></a>2.桥接</h3><p>继承是一种强耦合的结果，父类变，子类就必须要变。可以使用组合/继承来解耦合。将抽象和他的实现分离<br><img src="https://images.cnblogs.com/cnblogs_com/houleixx/Snap1.jpg" alt="此处输入图片的描述"></p>
<h3 id="3-组合"><a href="#3-组合" class="headerlink" title="3.组合"></a>3.组合</h3><p>将对象组合成属性结构以表示‘部分-整体’的层次结构。组合模式使得用户对单个对象和组合对象的使用具有一致性。</p>
<p>组合模式描述了如何使用递归的组合，使客户不用区分这些类</p>
<h3 id="4-装配器"><a href="#4-装配器" class="headerlink" title="4.装配器"></a>4.装配器</h3><h3 id="5-外观"><a href="#5-外观" class="headerlink" title="5.外观"></a>5.外观</h3><h3 id="6-享元模式"><a href="#6-享元模式" class="headerlink" title="6.享元模式"></a>6.享元模式</h3><h3 id="7-代理模式"><a href="#7-代理模式" class="headerlink" title="7.代理模式"></a>7.代理模式</h3><p>Copy-on-writedai代理：即写即复制“快照”虚拟代理的一种，把复制拖延到只有客户端需要时，才真正执行<br>保护代理：允许在访问对象时附加管理任务</p>
<p>1.什么是代理模式：例如我们找房子找中介<br>2.为什么要使用代理：我们不需要自己找房子</p>
]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;1-适配器&quot;&gt;&lt;a href=&quot;#1-适配器&quot; class=&quot;headerlink&quot; title=&quot;1.适配器&quot;&gt;&lt;/a&gt;1.适配器&lt;/h3&gt;&lt;p&gt;效果及优缺点：&lt;br&gt;对于类适配器：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;用一个具体的Adapter类对Adaptee和Tag
    
    </summary>
    
      <category term="设计模式" scheme="http://yoursite.com/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"/>
    
    
      <category term="设计模式" scheme="http://yoursite.com/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"/>
    
  </entry>
  
  <entry>
    <title>设计模式-行为模式</title>
    <link href="http://yoursite.com/2018/02/10/Design%20pattern%20behavior/"/>
    <id>http://yoursite.com/2018/02/10/Design pattern behavior/</id>
    <published>2018-02-10T01:30:00.000Z</published>
    <updated>2018-03-30T15:45:16.730Z</updated>
    
    <content type="html"><![CDATA[<h3 id="责任链模式"><a href="#责任链模式" class="headerlink" title="责任链模式"></a>责任链模式</h3><h4 id="命令模式"><a href="#命令模式" class="headerlink" title="命令模式"></a>命令模式</h4><p>命令Command<br>    ——声明执行操作的接口。<br>具体命令ConcreteCommand<br>    ——定义接收对象和动作之间的绑定关系。<br>    ——通过引起接收者的相应动作来实现执行。<br>客户Client<br>    ——产生一个ConcreteCommand对象，并设置接收者。<br>引发者Invoker<br>    ——要求命令执行请求。<br>接收者Receiver<br>    ——知道如何执行与请求相联系的操作。</p>
<a id="more"></a>
<h3 id="迭代器模式"><a href="#迭代器模式" class="headerlink" title="迭代器模式"></a>迭代器模式</h3><h3 id="模板方法模式"><a href="#模板方法模式" class="headerlink" title="模板方法模式"></a>模板方法模式</h3><p>准备一个抽象类，定义一个算法的大体框架<br>将部分逻辑以具体方法以及具体构造子的形式实现<br>剩余的逻辑通过声明一些抽象方法来描述<br>这些抽象方法要求子类实现，<br>不同的子类可以以不同的方式实现这些抽象方法，从而对剩余的逻辑有不同的实现。<br>子类不改变算法的结构而重定义算法</p>
<h3 id="观察者模式"><a href="#观察者模式" class="headerlink" title="观察者模式"></a>观察者模式</h3><p>同一应用对象不同展示形式，如一组数据映射为表格和柱状图。用户更改表格数据，柱状图要同步修改</p>
<p>关键对象：<br>抽象主题Subject<br>提供一个连接观察者对象和解除连接的接口。<br>知道它的观察者。可有任意数目的观察者对象观察一个主题。<br>可以增加和删除观察者对象，<br>具体主题ConcreteSubject：<br>通常用一个具体子类实现。<br>负责实现对观察者引用的聚集的管理力注。<br>将有关状态存入ConcreteObserver对象。<br>在具体主题内部状态改变时向它的观察者发送通知。</p>
<p>抽象观察者Observer ：<br>一般用一个抽象类或者一个接口实现，<br>为所有的具体观察者定义一个更新接口<br>更新接口包含的方法叫更新方法。<br>具体观察者ConcreteObserver<br>通常用一个具体子类实现，<br>保存一个指向ConcreteSubject对象的引用。<br>存储要与主题一致的状态。<br>实现抽象观察者角色所要求的更新接口，以便使本身的状态与主题的状态相协调。</p>
<h3 id="状态模式"><a href="#状态模式" class="headerlink" title="状态模式"></a>状态模式</h3><h3 id="策略模式"><a href="#策略模式" class="headerlink" title="策略模式"></a>策略模式</h3><h3 id="访问者模式"><a href="#访问者模式" class="headerlink" title="访问者模式"></a>访问者模式</h3><h3 id="解释器模式"><a href="#解释器模式" class="headerlink" title="解释器模式"></a>解释器模式</h3>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;责任链模式&quot;&gt;&lt;a href=&quot;#责任链模式&quot; class=&quot;headerlink&quot; title=&quot;责任链模式&quot;&gt;&lt;/a&gt;责任链模式&lt;/h3&gt;&lt;h4 id=&quot;命令模式&quot;&gt;&lt;a href=&quot;#命令模式&quot; class=&quot;headerlink&quot; title=&quot;命令模式&quot;&gt;&lt;/a&gt;命令模式&lt;/h4&gt;&lt;p&gt;命令Command&lt;br&gt;    ——声明执行操作的接口。&lt;br&gt;具体命令ConcreteCommand&lt;br&gt;    ——定义接收对象和动作之间的绑定关系。&lt;br&gt;    ——通过引起接收者的相应动作来实现执行。&lt;br&gt;客户Client&lt;br&gt;    ——产生一个ConcreteCommand对象，并设置接收者。&lt;br&gt;引发者Invoker&lt;br&gt;    ——要求命令执行请求。&lt;br&gt;接收者Receiver&lt;br&gt;    ——知道如何执行与请求相联系的操作。&lt;/p&gt;
    
    </summary>
    
      <category term="设计模式" scheme="http://yoursite.com/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"/>
    
    
      <category term="设计模式" scheme="http://yoursite.com/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"/>
    
  </entry>
  
  <entry>
    <title>2018学习计划</title>
    <link href="http://yoursite.com/2018/02/07/2018%E5%AD%A6%E4%B9%A0%E8%AE%A1%E5%88%92/"/>
    <id>http://yoursite.com/2018/02/07/2018学习计划/</id>
    <published>2018-02-07T00:00:00.000Z</published>
    <updated>2018-12-21T08:12:32.620Z</updated>
    
    <content type="html"><![CDATA[<h2 id="大数据及机器学习学习计划"><a href="#大数据及机器学习学习计划" class="headerlink" title="大数据及机器学习学习计划"></a>大数据及机器学习学习计划</h2><ol>
<li><p>编程基础：Python<br><a href="https://cn.udacity.com/course/programming-foundations-with-python--ud036" target="_blank" rel="external">https://cn.udacity.com/course/programming-foundations-with-python--ud036</a></p>
</li>
<li><p>计算机科学导论  72小时<br><a href="https://cn.udacity.com/course/intro-to-computer-science--cs101" target="_blank" rel="external">https://cn.udacity.com/course/intro-to-computer-science--cs101</a></p>
</li>
<li>推论统计学  48小时<br><a href="https://cn.udacity.com/course/intro-to-inferential-statistics--ud201" target="_blank" rel="external">https://cn.udacity.com/course/intro-to-inferential-statistics--ud201</a></li>
<li>描述统计学  48小时<br><a href="https://cn.udacity.com/course/intro-to-inferential-statistics--ud201" target="_blank" rel="external">https://cn.udacity.com/course/intro-to-inferential-statistics--ud201</a></li>
<li>机器学习  240小时<br><a href="https://cn.udacity.com/course/machine-learning--ud262" target="_blank" rel="external">https://cn.udacity.com/course/machine-learning--ud262</a></li>
<li>统计学入门<br><a href="https://cn.udacity.com/course/intro-to-statistics--st101" target="_blank" rel="external">https://cn.udacity.com/course/intro-to-statistics--st101</a></li>
<li>基础线性代数<br><a href="https://cn.udacity.com/course/linear-algebra-refresher-course--ud953" target="_blank" rel="external">https://cn.udacity.com/course/linear-algebra-refresher-course--ud953</a></li>
<li><p>机器学习<br><a href="https://cn.udacity.com/course/machine-learning-engineer-nanodegree--nd009" target="_blank" rel="external">https://cn.udacity.com/course/machine-learning-engineer-nanodegree--nd009</a></p>
</li>
<li><p>Apache Storm 进行实时分析  48小时<br><a href="https://cn.udacity.com/course/real-time-analytics-with-apache-storm--ud381" target="_blank" rel="external">https://cn.udacity.com/course/real-time-analytics-with-apache-storm--ud381</a></p>
</li>
<li><p>Bash脚本  40+小时</p>
</li>
</ol>
]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;大数据及机器学习学习计划&quot;&gt;&lt;a href=&quot;#大数据及机器学习学习计划&quot; class=&quot;headerlink&quot; title=&quot;大数据及机器学习学习计划&quot;&gt;&lt;/a&gt;大数据及机器学习学习计划&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;&lt;p&gt;编程基础：Python&lt;br&gt;&lt;a hre
    
    </summary>
    
      <category term="学习计划" scheme="http://yoursite.com/categories/%E5%AD%A6%E4%B9%A0%E8%AE%A1%E5%88%92/"/>
    
    
      <category term="学习" scheme="http://yoursite.com/tags/%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>机器学习-支持向量机</title>
    <link href="http://yoursite.com/2018/02/05/Mathematical%20Support%20Vector%20Machine/"/>
    <id>http://yoursite.com/2018/02/05/Mathematical Support Vector Machine/</id>
    <published>2018-02-05T01:30:00.000Z</published>
    <updated>2018-12-21T08:13:30.038Z</updated>
    
    <content type="html"><![CDATA[<h3 id="支持向量机（Support-Vector-Machine，SVM）的基本概念："><a href="#支持向量机（Support-Vector-Machine，SVM）的基本概念：" class="headerlink" title="支持向量机（Support Vector Machine，SVM）的基本概念："></a>支持向量机（Support Vector Machine，SVM）的基本概念：</h3><h5 id="点到超平面的距离"><a href="#点到超平面的距离" class="headerlink" title="点到超平面的距离"></a>点到超平面的距离</h5><p>在分类任务中，为了获取稳健的线性分类器，一个很自然的想法是，找出一条分割线使得两侧样本与该分割线的平均距离足够的远。在欧式空间中，定义一个点𝒙到直线（或者高维空间中的超平面）𝒘^𝑇 𝒙+𝑏=0的距离公式是：<br>            𝑟(𝑥)=  (|𝒘^𝑇 𝒙+𝑏|)/(||𝒘||)<br>在分类问题中，如果这样的分割线或者分割平面能够准确地将样本分开，对于样本{𝒙<em>𝑖,𝑦</em>𝑖}∈𝐷, 𝑦<em>𝑖=±1 而言，若𝑦</em>𝑖=1，则有𝒘^𝑇 𝒙<em>𝒊+𝑏≥1，反之若𝑦</em>𝑖=-1，则有𝒘^𝑇 𝒙_𝒊+𝑏≤−1.</p>
]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;支持向量机（Support-Vector-Machine，SVM）的基本概念：&quot;&gt;&lt;a href=&quot;#支持向量机（Support-Vector-Machine，SVM）的基本概念：&quot; class=&quot;headerlink&quot; title=&quot;支持向量机（Support 
    
    </summary>
    
      <category term="机器学习" scheme="http://yoursite.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="机器学习" scheme="http://yoursite.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>设计模式目录</title>
    <link href="http://yoursite.com/2018/01/27/Design%20pattern%20catalog/"/>
    <id>http://yoursite.com/2018/01/27/Design pattern catalog/</id>
    <published>2018-01-27T01:30:00.000Z</published>
    <updated>2018-02-06T14:27:35.863Z</updated>
    
    <content type="html"><![CDATA[<h3 id="创建性模式："><a href="#创建性模式：" class="headerlink" title="创建性模式："></a>创建性模式：</h3><p>1.类的创建模式——使用继承关系，把类的创建延迟到子类<br>2.对象的创建模式——把对象的创建过程动态地委派给另一个对象<br>    封装要创建的具体类（类的实例）的信息<br>    隐藏这些类（类的实例）被创建和组合的过程</p>
<p>包含<br>抽象工厂、建造者、工厂方式、原型、单例</p>
<h3 id="结构性模式："><a href="#结构性模式：" class="headerlink" title="结构性模式："></a>结构性模式：</h3><p>考虑如何组合类和对象构成较大的结构。<br>1.结构性类模式：使用继承来组合接口或实现<br>2.结构性对象模式：对象合成实现新功能。<br><a id="more"></a><br>包含：<br>适配器、桥接、组合、装饰着、外观、轻量、代理</p>
<h3 id="行为模式："><a href="#行为模式：" class="headerlink" title="行为模式："></a>行为模式：</h3><p>主要解决算法和对象之间的责任分配问题。<br>对象或类的模式<br>它们之间的通信模式。<br>包含：<br>责任链、命令、解释器、迭代、中介者、备忘录、观察者、状态、策略、模板方法、观察者</p>
<p>工厂方法主要针对一个产品等级结构<br>抽象工厂模式需要面对多个产品等级结构</p>
]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;创建性模式：&quot;&gt;&lt;a href=&quot;#创建性模式：&quot; class=&quot;headerlink&quot; title=&quot;创建性模式：&quot;&gt;&lt;/a&gt;创建性模式：&lt;/h3&gt;&lt;p&gt;1.类的创建模式——使用继承关系，把类的创建延迟到子类&lt;br&gt;2.对象的创建模式——把对象的创建过程动态地委派给另一个对象&lt;br&gt;    封装要创建的具体类（类的实例）的信息&lt;br&gt;    隐藏这些类（类的实例）被创建和组合的过程&lt;/p&gt;
&lt;p&gt;包含&lt;br&gt;抽象工厂、建造者、工厂方式、原型、单例&lt;/p&gt;
&lt;h3 id=&quot;结构性模式：&quot;&gt;&lt;a href=&quot;#结构性模式：&quot; class=&quot;headerlink&quot; title=&quot;结构性模式：&quot;&gt;&lt;/a&gt;结构性模式：&lt;/h3&gt;&lt;p&gt;考虑如何组合类和对象构成较大的结构。&lt;br&gt;1.结构性类模式：使用继承来组合接口或实现&lt;br&gt;2.结构性对象模式：对象合成实现新功能。&lt;br&gt;
    
    </summary>
    
      <category term="设计模式" scheme="http://yoursite.com/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"/>
    
    
      <category term="设计模式" scheme="http://yoursite.com/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"/>
    
  </entry>
  
  <entry>
    <title>设计模式-工厂模式</title>
    <link href="http://yoursite.com/2018/01/27/Design%20pattern%20factory/"/>
    <id>http://yoursite.com/2018/01/27/Design pattern factory/</id>
    <published>2018-01-27T01:30:00.000Z</published>
    <updated>2018-02-08T16:00:47.673Z</updated>
    
    <content type="html"><![CDATA[<p>创建几个套皮肤，所有的UI控件 如按钮，滚动条，窗口 都要创建出来。现在需要红色主题，黑色主题，和蓝色主题3套皮肤。</p>
<p>接口类：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">Button</span> </span>&#123;</div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">display</span><span class="params">()</span></span>;</div><div class="line">&#125;</div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">ScrollBar</span> </span>&#123;</div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">display</span><span class="params">()</span></span>;</div><div class="line">&#125;</div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">Window</span> </span>&#123;</div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">display</span><span class="params">()</span></span>;</div><div class="line">&#125;</div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">SkinFactory</span> </span>&#123;</div><div class="line">    <span class="function"><span class="keyword">public</span> ScrollBar <span class="title">createScrollBar</span><span class="params">()</span></span>;</div><div class="line">    <span class="function"><span class="keyword">public</span> Button <span class="title">createButton</span><span class="params">()</span></span>;</div><div class="line">    <span class="function"><span class="keyword">public</span> Window <span class="title">createWindow</span><span class="params">()</span></span>;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<a id="more"></a>
<p>红色皮肤工厂<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">RedSkinFactory</span> <span class="keyword">implements</span> <span class="title">SkinFactory</span> </span>&#123;</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">public</span> ScrollBar <span class="title">createScrollBar</span><span class="params">()</span> </span>&#123;</div><div class="line">        <span class="keyword">return</span> <span class="keyword">new</span> RedScrollBar();</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">public</span> Button <span class="title">createButton</span><span class="params">()</span> </span>&#123;</div><div class="line">        <span class="keyword">return</span> <span class="keyword">new</span> RedButton();</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">public</span> Window <span class="title">createWindow</span><span class="params">()</span> </span>&#123;</div><div class="line">        <span class="keyword">return</span> <span class="keyword">new</span> RedWindow();</div><div class="line">    &#125;</div><div class="line">&#125;</div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">RedScrollBar</span> <span class="keyword">implements</span> <span class="title">ScrollBar</span> </span>&#123;</div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">display</span><span class="params">()</span> </span>&#123;</div><div class="line">        System.out.println(<span class="string">"创建红色滚动条。"</span>);</div><div class="line">    &#125;</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">RedButton</span> <span class="keyword">implements</span> <span class="title">Button</span> </span>&#123;</div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">display</span><span class="params">()</span> </span>&#123;</div><div class="line">        System.out.println(<span class="string">"创建红色按钮"</span>);</div><div class="line">    &#125;</div><div class="line">&#125;</div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">RedWindow</span> <span class="keyword">implements</span> <span class="title">Window</span> </span>&#123;</div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">display</span><span class="params">()</span> </span>&#123;</div><div class="line">        System.out.println(<span class="string">"创建红色窗口。"</span>);</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>实现类<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">SkinClient</span> </span>&#123;</div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</div><div class="line">        SkinFactory BlackSkinFactory = <span class="keyword">new</span> BlackSkinFactory();</div><div class="line">        BlackSkinFactory.createButton().display();</div><div class="line">        BlackSkinFactory.createScrollBar().display();</div><div class="line">        BlackSkinFactory.createWindow().display();</div><div class="line"></div><div class="line">        SkinFactory RedSkinFactory = <span class="keyword">new</span> RedSkinFactory();</div><div class="line">        RedSkinFactory.createButton().display();</div><div class="line">        RedSkinFactory.createScrollBar().display();</div><div class="line">        RedSkinFactory.createWindow().display();</div><div class="line"></div><div class="line">        SkinFactory BlueSkinFactory = <span class="keyword">new</span> BlueSkinFactory();</div><div class="line">        BlueSkinFactory.createButton().display();</div><div class="line">        BlueSkinFactory.createScrollBar().display();</div><div class="line">        BlueSkinFactory.createWindow().display();</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>sh输出结果<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">创建黑色按钮</div><div class="line">创建黑色滚动条。</div><div class="line">创建黑色窗口。</div><div class="line">创建红色按钮</div><div class="line">创建红色滚动条。</div><div class="line">创建红色窗口。</div><div class="line">创建蓝色按钮</div><div class="line">创建蓝色滚动条。</div><div class="line">创建蓝色窗口。</div></pre></td></tr></table></figure></p>
<p>其他颜色同上<br>代码结构截图：<br><img src="http://oh6ybr0jg.bkt.clouddn.com/daimajiegoutu-gongchang.png" alt="此处输入图片的描述"><br>结果截图：<br><img src="http://oh6ybr0jg.bkt.clouddn.com/jieguojietu-gongchang1.png" alt="此处输入图片的描述"></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;创建几个套皮肤，所有的UI控件 如按钮，滚动条，窗口 都要创建出来。现在需要红色主题，黑色主题，和蓝色主题3套皮肤。&lt;/p&gt;
&lt;p&gt;接口类：&lt;br&gt;&lt;figure class=&quot;highlight java&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;2&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;3&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;4&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;5&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;6&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;7&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;8&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;9&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;10&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;11&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;12&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;13&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;14&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;class&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;interface&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;Button&lt;/span&gt; &lt;/span&gt;&amp;#123;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    &lt;span class=&quot;function&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;display&lt;/span&gt;&lt;span class=&quot;params&quot;&gt;()&lt;/span&gt;&lt;/span&gt;;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&amp;#125;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;class&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;interface&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;ScrollBar&lt;/span&gt; &lt;/span&gt;&amp;#123;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    &lt;span class=&quot;function&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;display&lt;/span&gt;&lt;span class=&quot;params&quot;&gt;()&lt;/span&gt;&lt;/span&gt;;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&amp;#125;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;class&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;interface&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;Window&lt;/span&gt; &lt;/span&gt;&amp;#123;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    &lt;span class=&quot;function&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;display&lt;/span&gt;&lt;span class=&quot;params&quot;&gt;()&lt;/span&gt;&lt;/span&gt;;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&amp;#125;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;class&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;interface&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;SkinFactory&lt;/span&gt; &lt;/span&gt;&amp;#123;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    &lt;span class=&quot;function&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;public&lt;/span&gt; ScrollBar &lt;span class=&quot;title&quot;&gt;createScrollBar&lt;/span&gt;&lt;span class=&quot;params&quot;&gt;()&lt;/span&gt;&lt;/span&gt;;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    &lt;span class=&quot;function&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;public&lt;/span&gt; Button &lt;span class=&quot;title&quot;&gt;createButton&lt;/span&gt;&lt;span class=&quot;params&quot;&gt;()&lt;/span&gt;&lt;/span&gt;;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    &lt;span class=&quot;function&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;public&lt;/span&gt; Window &lt;span class=&quot;title&quot;&gt;createWindow&lt;/span&gt;&lt;span class=&quot;params&quot;&gt;()&lt;/span&gt;&lt;/span&gt;;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&amp;#125;&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="设计模式" scheme="http://yoursite.com/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"/>
    
    
      <category term="设计模式" scheme="http://yoursite.com/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"/>
    
  </entry>
  
  <entry>
    <title>kNN实现手写数字识别</title>
    <link href="http://yoursite.com/2018/01/25/kNN%E5%AE%9E%E7%8E%B0%E6%89%8B%E5%86%99%E6%95%B0%E5%AD%97%E8%AF%86%E5%88%AB/"/>
    <id>http://yoursite.com/2018/01/25/kNN实现手写数字识别/</id>
    <published>2018-01-25T10:42:30.000Z</published>
    <updated>2018-12-21T08:21:57.435Z</updated>
    
    <content type="html"><![CDATA[<p>需求<br>利用一个手写数字“先验数据”集，使用knn算法来实现对手写数字的自动识别；<br>先验数据（训练数据）集：<br>    数据维度比较大，样本数比较多。<br>    数据集包括数字0-9的手写体。<br>    每个数字大约有200个样本。<br>    每个样本保持在一个txt文件中。<br>    手写体图像本身的大小是32x32的二值图，转换到txt文件保存后，内容也是32x32个数字，0或者1，如下：<br><a id="more"></a><br><img src="http://oh6ybr0jg.bkt.clouddn.com/%E6%95%B0%E5%AD%97012.png" alt="此处输入图片的描述"></p>
<p>首先准备测试文件:<br>1934个训练数据<br>946个测试数据</p>
<p>分析：<br>1、手写体因为每个人，甚至每次写的字都不会完全精确一致，所以，识别手写体的关键是“相似度”<br>2、既然是要求样本之间的相似度，那么，首先需要将样本进行抽象，将每个样本变成一系列特征数据（即特征向量）<br>3、手写体在直观上就是一个个的图片，而图片是由上述图示中的像素点来描述的，样本的相似度其实就是像素的位置和颜色之间的组合的相似度<br>4、因此，将图片的像素按照固定顺序读取到一个个的向量中，即可很好地表示手写体样本<br>5、抽象出了样本向量，及相似度计算模型，即可应用KNN来实现</p>
<p>代码：<br>1)    一个用来生成将每个样本的txt文件转换为对应的一个向量，<br>2)    一个用来加载整个数据集，<br>3)    一个实现kNN分类算法。<br>4)    最后就是实现加载、测试的函数。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div><div class="line">118</div><div class="line">119</div><div class="line">120</div><div class="line">121</div><div class="line">122</div><div class="line">123</div><div class="line">124</div><div class="line">125</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#########################################</span></div><div class="line"><span class="comment"># kNN: k Nearest Neighbors</span></div><div class="line"></div><div class="line"><span class="comment"># 参数:        inX: vector to compare to existing dataset (1xN)</span></div><div class="line"><span class="comment">#             dataSet: size m data set of known vectors (NxM)</span></div><div class="line"><span class="comment">#             labels: data set labels (1xM vector)</span></div><div class="line"><span class="comment">#             k: number of neighbors to use for comparison </span></div><div class="line">            </div><div class="line"><span class="comment"># 输出:     多数类</span></div><div class="line"><span class="comment">#########################################</span></div><div class="line"></div><div class="line"><span class="keyword">from</span> numpy <span class="keyword">import</span> *</div><div class="line"><span class="keyword">import</span> operator</div><div class="line"><span class="keyword">import</span> os</div><div class="line"></div><div class="line"></div><div class="line"><span class="comment"># KNN分类核心方法</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">kNNClassify</span><span class="params">(newInput, dataSet, labels, k)</span>:</span></div><div class="line">	numSamples = dataSet.shape[<span class="number">0</span>]  <span class="comment"># shape[0]代表行数</span></div><div class="line"></div><div class="line">	<span class="comment">## step 1: 计算欧式距离</span></div><div class="line">	<span class="comment"># tile(A, reps): 将A重复reps次来构造一个矩阵</span></div><div class="line">	<span class="comment"># the following copy numSamples rows for dataSet</span></div><div class="line">	diff = tile(newInput, (numSamples, <span class="number">1</span>)) - dataSet  <span class="comment"># Subtract element-wise</span></div><div class="line">	squaredDiff = diff ** <span class="number">2</span> <span class="comment"># squared for the subtract</span></div><div class="line">	squaredDist = sum(squaredDiff, axis = <span class="number">1</span>)  <span class="comment"># sum is performed by row</span></div><div class="line">	distance = squaredDist ** <span class="number">0.5</span></div><div class="line"></div><div class="line">	<span class="comment">## step 2: 对距离排序</span></div><div class="line">	<span class="comment"># argsort()返回排序后的索引</span></div><div class="line">	sortedDistIndices = argsort(distance)</div><div class="line"></div><div class="line">	classCount = &#123;&#125;  <span class="comment"># 定义一个空的字典</span></div><div class="line">	<span class="keyword">for</span> i <span class="keyword">in</span> xrange(k):</div><div class="line">		<span class="comment">## step 3: 选择k个最小距离</span></div><div class="line">		voteLabel = labels[sortedDistIndices[i]]</div><div class="line"></div><div class="line">		<span class="comment">## step 4: 计算类别的出现次数</span></div><div class="line">		<span class="comment"># when the key voteLabel is not in dictionary classCount, get()</span></div><div class="line">		<span class="comment"># will return 0</span></div><div class="line">		classCount[voteLabel] = classCount.get(voteLabel, <span class="number">0</span>) + <span class="number">1</span></div><div class="line"></div><div class="line">	<span class="comment">## step 5: 返回出现次数最多的类别作为分类结果</span></div><div class="line">	maxCount = <span class="number">0</span></div><div class="line">	<span class="keyword">for</span> key, value <span class="keyword">in</span> classCount.items():</div><div class="line">		<span class="keyword">if</span> value &gt; maxCount:</div><div class="line">			maxCount = value</div><div class="line">			maxIndex = key</div><div class="line"></div><div class="line">	<span class="keyword">return</span> maxIndex	</div><div class="line"></div><div class="line"><span class="comment"># 将图片转换为向量</span></div><div class="line"><span class="function"><span class="keyword">def</span>  <span class="title">img2vector</span><span class="params">(filename)</span>:</span></div><div class="line"> 	rows = <span class="number">32</span></div><div class="line"> 	cols = <span class="number">32</span></div><div class="line"> 	imgVector = zeros((<span class="number">1</span>, rows * cols)) </div><div class="line"> 	fileIn = open(filename)</div><div class="line"> 	<span class="keyword">for</span> row <span class="keyword">in</span> xrange(rows):</div><div class="line"> 		lineStr = fileIn.readline()</div><div class="line"> 		<span class="keyword">for</span> col <span class="keyword">in</span> xrange(cols):</div><div class="line"> 			imgVector[<span class="number">0</span>, row * <span class="number">32</span> + col] = int(lineStr[col])</div><div class="line"></div><div class="line"> 	<span class="keyword">return</span> imgVector</div><div class="line"></div><div class="line"><span class="comment"># 加载数据集</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">loadDataSet</span><span class="params">()</span>:</span></div><div class="line">	<span class="comment">## step 1: 读取训练数据集</span></div><div class="line">	<span class="keyword">print</span> <span class="string">"---Getting training set..."</span></div><div class="line">	dataSetDir = <span class="string">'E:/Python/ml/knn/'</span></div><div class="line">	trainingFileList = os.listdir(dataSetDir + <span class="string">'trainingDigits'</span>)  <span class="comment"># 加载测试数据</span></div><div class="line">	numSamples = len(trainingFileList)</div><div class="line"></div><div class="line">	train_x = zeros((numSamples, <span class="number">1024</span>))</div><div class="line">	train_y = []</div><div class="line">	<span class="keyword">for</span> i <span class="keyword">in</span> xrange(numSamples):</div><div class="line">		filename = trainingFileList[i]</div><div class="line"></div><div class="line">		<span class="comment"># get train_x</span></div><div class="line">		train_x[i, :] = img2vector(dataSetDir + <span class="string">'trainingDigits/%s'</span> % filename) </div><div class="line"></div><div class="line">		<span class="comment"># get label from file name such as "1_18.txt"</span></div><div class="line">		label = int(filename.split(<span class="string">'_'</span>)[<span class="number">0</span>]) <span class="comment"># return 1</span></div><div class="line">		train_y.append(label)</div><div class="line"></div><div class="line">	<span class="comment">## step 2:读取测试数据集</span></div><div class="line">	<span class="keyword">print</span> <span class="string">"---Getting testing set..."</span></div><div class="line">	testingFileList = os.listdir(dataSetDir + <span class="string">'testDigits'</span>) <span class="comment"># load the testing set</span></div><div class="line">	numSamples = len(testingFileList)</div><div class="line">	test_x = zeros((numSamples, <span class="number">1024</span>))</div><div class="line">	test_y = []</div><div class="line">	<span class="keyword">for</span> i <span class="keyword">in</span> xrange(numSamples):</div><div class="line">		filename = testingFileList[i]</div><div class="line"></div><div class="line">		<span class="comment"># get train_x</span></div><div class="line">		test_x[i, :] = img2vector(dataSetDir + <span class="string">'testDigits/%s'</span> % filename) </div><div class="line"></div><div class="line">		<span class="comment"># get label from file name such as "1_18.txt"</span></div><div class="line">		label = int(filename.split(<span class="string">'_'</span>)[<span class="number">0</span>]) <span class="comment"># return 1</span></div><div class="line">		test_y.append(label)</div><div class="line"></div><div class="line">	<span class="keyword">return</span> train_x, train_y, test_x, test_y</div><div class="line"></div><div class="line"><span class="comment"># 手写识别主流程</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">testHandWritingClass</span><span class="params">()</span>:</span></div><div class="line">	<span class="comment">## step 1: 加载数据</span></div><div class="line">	<span class="keyword">print</span> <span class="string">"step 1: load data..."</span></div><div class="line">	train_x, train_y, test_x, test_y = loadDataSet()</div><div class="line"></div><div class="line">	<span class="comment">## step 2: 模型训练.</span></div><div class="line">	<span class="keyword">print</span> <span class="string">"step 2: training..."</span></div><div class="line">	<span class="keyword">pass</span></div><div class="line"></div><div class="line">	<span class="comment">## step 3: 测试</span></div><div class="line">	<span class="keyword">print</span> <span class="string">"step 3: testing..."</span></div><div class="line">	numTestSamples = test_x.shape[<span class="number">0</span>]</div><div class="line">	matchCount = <span class="number">0</span></div><div class="line">	<span class="keyword">for</span> i <span class="keyword">in</span> xrange(numTestSamples):</div><div class="line">		predict = kNNClassify(test_x[i], train_x, train_y, <span class="number">3</span>)</div><div class="line">		<span class="keyword">if</span> predict == test_y[i]:</div><div class="line">			matchCount += <span class="number">1</span></div><div class="line">	accuracy = float(matchCount) / numTestSamples</div><div class="line"></div><div class="line">	<span class="comment">## step 4: 输出结果</span></div><div class="line">	<span class="keyword">print</span> <span class="string">"step 4: show the result..."</span></div><div class="line">	<span class="keyword">print</span> <span class="string">'The classify accuracy is: %.2f%%'</span> % (accuracy * <span class="number">100</span>)</div></pre></td></tr></table></figure>
<p>测试<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> kNN</div><div class="line">kNN.testHandWritingClass()</div></pre></td></tr></table></figure></p>
<p>执行结果：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">tep <span class="number">1</span>: load data...</div><div class="line">---Getting training set...</div><div class="line">---Getting testing set...</div><div class="line">step <span class="number">2</span>: training...</div><div class="line">step <span class="number">3</span>: testing...</div><div class="line">step <span class="number">4</span>: show the result...</div><div class="line">The classify accuracy <span class="keyword">is</span>: <span class="number">98.84</span>%</div></pre></td></tr></table></figure></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;需求&lt;br&gt;利用一个手写数字“先验数据”集，使用knn算法来实现对手写数字的自动识别；&lt;br&gt;先验数据（训练数据）集：&lt;br&gt;    数据维度比较大，样本数比较多。&lt;br&gt;    数据集包括数字0-9的手写体。&lt;br&gt;    每个数字大约有200个样本。&lt;br&gt;    每个样本保持在一个txt文件中。&lt;br&gt;    手写体图像本身的大小是32x32的二值图，转换到txt文件保存后，内容也是32x32个数字，0或者1，如下：&lt;br&gt;
    
    </summary>
    
      <category term="python" scheme="http://yoursite.com/categories/python/"/>
    
    
      <category term="机器学习" scheme="http://yoursite.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>机器学习之KNN算法推演</title>
    <link href="http://yoursite.com/2018/01/21/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B9%8BKNN%E7%AE%97%E6%B3%95%E6%8E%A8%E6%BC%94/"/>
    <id>http://yoursite.com/2018/01/21/机器学习之KNN算法推演/</id>
    <published>2018-01-21T13:06:30.000Z</published>
    <updated>2018-12-21T08:21:00.169Z</updated>
    
    <content type="html"><![CDATA[<h4 id="从训练集中找到和新数据最接近的k条记录，然后根据多数类来决定新数据类别。"><a href="#从训练集中找到和新数据最接近的k条记录，然后根据多数类来决定新数据类别。" class="headerlink" title="从训练集中找到和新数据最接近的k条记录，然后根据多数类来决定新数据类别。"></a>从训练集中找到和新数据最接近的k条记录，然后根据多数类来决定新数据类别。</h4><h5 id="算法涉及3个主要因素："><a href="#算法涉及3个主要因素：" class="headerlink" title="算法涉及3个主要因素："></a>算法涉及3个主要因素：</h5><p>1)    训练数据集<br>2)    距离或相似度的计算衡量<br>3)    k的大小<br><img src="http://oh6ybr0jg.bkt.clouddn.com/KNN%E7%AE%97%E6%B3%95.jpg" alt="此处输入图片的描述"><br>绿色圆要被决定赋予哪个类，是红色三角形还是蓝色四方形？如果K=3，由于红色三角形所占比例为2/3，绿色圆将被赋予红色三角形那个类，如果K=5，由于蓝色四方形比例为3/5，因此绿色圆被赋予蓝色四方形类。</p>
<h2 id="KNN分类算法Python实战"><a href="#KNN分类算法Python实战" class="headerlink" title="KNN分类算法Python实战"></a>KNN分类算法Python实战</h2><p>有以下先验数据，使用knn算法对未知类别数据分类</p>
<table>
<thead>
<tr>
<th>x轴</th>
<th style="text-align:center">y轴</th>
<th style="text-align:right">类型</th>
</tr>
</thead>
<tbody>
<tr>
<td>1.0</td>
<td style="text-align:center">0.9</td>
<td style="text-align:right">A</td>
</tr>
<tr>
<td>1.0</td>
<td style="text-align:center">1.0</td>
<td style="text-align:right">A</td>
</tr>
<tr>
<td>0.0</td>
<td style="text-align:center">0.1</td>
<td style="text-align:right">B</td>
</tr>
<tr>
<td>0.1</td>
<td style="text-align:center">0.2</td>
<td style="text-align:right">B</td>
</tr>
</tbody>
</table>
<a id="more"></a>
<p>未知类别数据</p>
<table>
<thead>
<tr>
<th>x轴</th>
<th style="text-align:center">y轴</th>
<th style="text-align:right">类型</th>
</tr>
</thead>
<tbody>
<tr>
<td>1.2</td>
<td style="text-align:center">1.0</td>
<td style="text-align:right">？</td>
</tr>
<tr>
<td>0.1</td>
<td style="text-align:center">0.3</td>
<td style="text-align:right">？</td>
</tr>
</tbody>
</table>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#########################################</span></div><div class="line"><span class="comment"># kNN: k Nearest Neighbors</span></div><div class="line"></div><div class="line"><span class="comment"># 输入:      newInput:  (1xN)的待分类向量</span></div><div class="line"><span class="comment">#             dataSet:   (NxM)的训练数据集</span></div><div class="line"><span class="comment">#             labels: 	训练数据集的类别标签向量</span></div><div class="line"><span class="comment">#             k: 		近邻数 </span></div><div class="line">            </div><div class="line"><span class="comment"># 输出:     可能性最大的分类标签</span></div><div class="line"><span class="comment">#########################################</span></div><div class="line"></div><div class="line"><span class="keyword">from</span> numpy <span class="keyword">import</span> *</div><div class="line"><span class="keyword">import</span> operator</div><div class="line"></div><div class="line"><span class="comment">#创建一个数据集，包含2个类别共4个样本</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">createDataSet</span><span class="params">()</span>:</span></div><div class="line">	<span class="comment"># 生成一个矩阵，每行表示一个样本</span></div><div class="line">	group = array([[<span class="number">1.0</span>, <span class="number">0.9</span>], [<span class="number">1.0</span>, <span class="number">1.0</span>], [<span class="number">0.1</span>, <span class="number">0.2</span>], [<span class="number">0.0</span>, <span class="number">0.1</span>]])</div><div class="line">	<span class="comment"># 4个样本分别所属的类别</span></div><div class="line">	labels = [<span class="string">'A'</span>, <span class="string">'A'</span>, <span class="string">'B'</span>, <span class="string">'B'</span>]</div><div class="line">	<span class="keyword">return</span> group, labels</div><div class="line"></div><div class="line"><span class="comment"># KNN分类算法函数定义</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">kNNClassify</span><span class="params">(newInput, dataSet, labels, k)</span>:</span></div><div class="line">	numSamples = dataSet.shape[<span class="number">0</span>]   <span class="comment"># shape[0]表示行数</span></div><div class="line"></div><div class="line">	<span class="comment">## step 1: 计算距离</span></div><div class="line">	<span class="comment"># tile(A, reps): 构造一个矩阵，通过A重复reps次得到(tile(A, （repsX，repsY）)此处在行的方向重复repsX次，在Y的方向重复repsY次)</span></div><div class="line">	<span class="comment"># the following copy numSamples rows for dataSet</span></div><div class="line">	diff = tile(newInput, (numSamples, <span class="number">1</span>)) - dataSet  <span class="comment"># 按元素求差值</span></div><div class="line">	squaredDiff = diff ** <span class="number">2</span>  <span class="comment">#将差值平方</span></div><div class="line">	squaredDist = sum(squaredDiff, axis = <span class="number">1</span>)   <span class="comment"># 按行累加</span></div><div class="line">	distance = squaredDist ** <span class="number">0.5</span>  <span class="comment">#将差值平方和求开方，即得距离</span></div><div class="line"></div><div class="line">	<span class="comment">## step 2: 对距离排序</span></div><div class="line">	<span class="comment">## 此处排序需要注意样本标签的顺序。排序后存的是角标号。后续直接从排序后的标签序列找下标是排序内容的数据</span></div><div class="line">	<span class="comment"># argsort() 返回排序后的索引值</span></div><div class="line">	sortedDistIndices = argsort(distance)  <span class="comment">#或distance.argsort()</span></div><div class="line">	classCount = &#123;&#125; <span class="comment"># define a dictionary (can be append element)</span></div><div class="line">	<span class="keyword">for</span> i <span class="keyword">in</span> xrange(k):</div><div class="line">		<span class="comment">## step 3: 选择k个最近邻</span></div><div class="line">		voteLabel = labels[sortedDistIndices[i]]</div><div class="line"></div><div class="line">		<span class="comment">## step 4: 计算k个最近邻中各类别出现的次数</span></div><div class="line">		<span class="comment"># when the key voteLabel is not in dictionary classCount, get()</span></div><div class="line">		<span class="comment"># will return 0</span></div><div class="line">		classCount[voteLabel] = classCount.get(voteLabel, <span class="number">0</span>) + <span class="number">1</span></div><div class="line"></div><div class="line">	<span class="comment">## step 5: 返回出现次数最多的类别标签</span></div><div class="line">	maxCount = <span class="number">0</span></div><div class="line">	<span class="keyword">for</span> key, value <span class="keyword">in</span> classCount.items():</div><div class="line">		<span class="keyword">if</span> value &gt; maxCount:</div><div class="line">			maxCount = value</div><div class="line">			maxIndex = key</div><div class="line"></div><div class="line">	<span class="keyword">return</span> maxIndex	</div><div class="line">	</div><div class="line">	<span class="comment">##step 5 可以改成：</span></div><div class="line">	<span class="comment"># sortedClassCount = sorted(classCount.iteritems(),key=operator.itemgetter(1),reverse=True)</span></div><div class="line">	<span class="comment">#return sortedClassCount[0][0]</span></div></pre></td></tr></table></figure>
<p>然后调用算法进行测试：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> kNN</div><div class="line"><span class="keyword">from</span> numpy <span class="keyword">import</span> * </div><div class="line"><span class="comment">#生成数据集和类别标签</span></div><div class="line">dataSet, labels = kNN.createDataSet()</div><div class="line"><span class="comment">#定义一个未知类别的数据</span></div><div class="line">testX = array([<span class="number">1.2</span>, <span class="number">1.0</span>])</div><div class="line">k = <span class="number">3</span></div><div class="line"><span class="comment">#调用分类函数对未知数据分类</span></div><div class="line">outputLabel = kNN.kNNClassify(testX, dataSet, labels, <span class="number">3</span>)</div><div class="line"><span class="keyword">print</span> <span class="string">"Your input is:"</span>, testX, <span class="string">"and classified to class: "</span>, outputLabel</div><div class="line"></div><div class="line">testX = array([<span class="number">0.1</span>, <span class="number">0.3</span>])</div><div class="line">outputLabel = kNN.kNNClassify(testX, dataSet, labels, <span class="number">3</span>)</div><div class="line"><span class="keyword">print</span> <span class="string">"Your input is:"</span>, testX, <span class="string">"and classified to class: "</span>, outputLabel</div></pre></td></tr></table></figure></p>
<p>这时候会输出<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">Your input <span class="keyword">is</span>: [ <span class="number">1.2</span>  <span class="number">1.0</span>] <span class="keyword">and</span> classified to <span class="class"><span class="keyword">class</span>:</span>  A</div><div class="line">Your input <span class="keyword">is</span>: [ <span class="number">0.1</span>  <span class="number">0.3</span>] <span class="keyword">and</span> classified to <span class="class"><span class="keyword">class</span>:</span>  B</div></pre></td></tr></table></figure></p>
]]></content>
    
    <summary type="html">
    
      &lt;h4 id=&quot;从训练集中找到和新数据最接近的k条记录，然后根据多数类来决定新数据类别。&quot;&gt;&lt;a href=&quot;#从训练集中找到和新数据最接近的k条记录，然后根据多数类来决定新数据类别。&quot; class=&quot;headerlink&quot; title=&quot;从训练集中找到和新数据最接近的k条记录，然后根据多数类来决定新数据类别。&quot;&gt;&lt;/a&gt;从训练集中找到和新数据最接近的k条记录，然后根据多数类来决定新数据类别。&lt;/h4&gt;&lt;h5 id=&quot;算法涉及3个主要因素：&quot;&gt;&lt;a href=&quot;#算法涉及3个主要因素：&quot; class=&quot;headerlink&quot; title=&quot;算法涉及3个主要因素：&quot;&gt;&lt;/a&gt;算法涉及3个主要因素：&lt;/h5&gt;&lt;p&gt;1)    训练数据集&lt;br&gt;2)    距离或相似度的计算衡量&lt;br&gt;3)    k的大小&lt;br&gt;&lt;img src=&quot;http://oh6ybr0jg.bkt.clouddn.com/KNN%E7%AE%97%E6%B3%95.jpg&quot; alt=&quot;此处输入图片的描述&quot;&gt;&lt;br&gt;绿色圆要被决定赋予哪个类，是红色三角形还是蓝色四方形？如果K=3，由于红色三角形所占比例为2/3，绿色圆将被赋予红色三角形那个类，如果K=5，由于蓝色四方形比例为3/5，因此绿色圆被赋予蓝色四方形类。&lt;/p&gt;
&lt;h2 id=&quot;KNN分类算法Python实战&quot;&gt;&lt;a href=&quot;#KNN分类算法Python实战&quot; class=&quot;headerlink&quot; title=&quot;KNN分类算法Python实战&quot;&gt;&lt;/a&gt;KNN分类算法Python实战&lt;/h2&gt;&lt;p&gt;有以下先验数据，使用knn算法对未知类别数据分类&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;x轴&lt;/th&gt;
&lt;th style=&quot;text-align:center&quot;&gt;y轴&lt;/th&gt;
&lt;th style=&quot;text-align:right&quot;&gt;类型&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;1.0&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;0.9&lt;/td&gt;
&lt;td style=&quot;text-align:right&quot;&gt;A&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1.0&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;1.0&lt;/td&gt;
&lt;td style=&quot;text-align:right&quot;&gt;A&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;0.0&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;0.1&lt;/td&gt;
&lt;td style=&quot;text-align:right&quot;&gt;B&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;0.1&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;0.2&lt;/td&gt;
&lt;td style=&quot;text-align:right&quot;&gt;B&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
    
    </summary>
    
      <category term="机器学习" scheme="http://yoursite.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="机器学习" scheme="http://yoursite.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>机器学习-概念</title>
    <link href="http://yoursite.com/2018/01/12/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E6%A6%82%E5%BF%B5/"/>
    <id>http://yoursite.com/2018/01/12/机器学习-概念/</id>
    <published>2018-01-12T15:55:30.000Z</published>
    <updated>2018-12-21T08:21:32.463Z</updated>
    
    <content type="html"><![CDATA[<h2 id="监督学习："><a href="#监督学习：" class="headerlink" title="监督学习："></a>监督学习：</h2><p>我们向系统输入我们所称的“已标记样本”<br>已标记样本指我们给系统一些信息，让它用于理解我们向它输入的数据。<br>例如我们创建一个系统来识别我的脸，我们将给他一些我的面部照片，一些别人的面部照片，我们会告诉系统 这些照片是David的，那些照片是别人的。随时间推移，它会利用这些信息提升它的理解程度。<br>”监督“表示你有很多样本，你了解这些样本的正确答案</p>
<h2 id="非监督学习"><a href="#非监督学习" class="headerlink" title="非监督学习"></a>非监督学习</h2><p>比如在医疗保健方面，如果我们已经了解某种疾病，监督学习可用以帮助系统，识别哪些人有患该病的风险，而非监督学习实际上可以根据常见症状的模式帮助我们发现甚至我们还不知道的疾病。</p>
<h2 id="聚类："><a href="#聚类：" class="headerlink" title="聚类："></a>聚类：</h2><p>K-MEANS<br><a id="more"></a></p>
<h2 id="朴素贝叶斯："><a href="#朴素贝叶斯：" class="headerlink" title="朴素贝叶斯："></a>朴素贝叶斯：</h2><p>推导过程和用法：<br><a href="http://scikit-learn.org/stable/modules/naive_bayes.html" target="_blank" rel="external">http://scikit-learn.org/stable/modules/naive_bayes.html</a><br><img src="http://scikit-learn.org/stable/_images/math/47537fc301bbf8971084f2ecbaa76658ad088235.png" alt="此处输入图片的描述"><br><img src="http://scikit-learn.org/stable/_images/math/4a2f8ee56238deb56e9e970a749bbe26d96465f7.png" alt="此处输入图片的描述"><br><img src="http://scikit-learn.org/stable/_images/math/7d90ebd2dc0cc2e1136a22625a489c3326d30ec7.png" alt="此处输入图片的描述"><br><img src="http://scikit-learn.org/stable/_images/math/201f076a3330f2928c26978c4eac59cc8ba4a440.png" alt="此处输入图片的描述"></p>
<p>还有高斯朴素贝叶斯<br><img src="http://scikit-learn.org/stable/_images/math/ed0c1181c1696f72e1be266187e4694919047d9e.png" alt="此处输入图片的描述"></p>
<p>python有一个库叫sklearn</p>
]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;监督学习：&quot;&gt;&lt;a href=&quot;#监督学习：&quot; class=&quot;headerlink&quot; title=&quot;监督学习：&quot;&gt;&lt;/a&gt;监督学习：&lt;/h2&gt;&lt;p&gt;我们向系统输入我们所称的“已标记样本”&lt;br&gt;已标记样本指我们给系统一些信息，让它用于理解我们向它输入的数据。&lt;br&gt;例如我们创建一个系统来识别我的脸，我们将给他一些我的面部照片，一些别人的面部照片，我们会告诉系统 这些照片是David的，那些照片是别人的。随时间推移，它会利用这些信息提升它的理解程度。&lt;br&gt;”监督“表示你有很多样本，你了解这些样本的正确答案&lt;/p&gt;
&lt;h2 id=&quot;非监督学习&quot;&gt;&lt;a href=&quot;#非监督学习&quot; class=&quot;headerlink&quot; title=&quot;非监督学习&quot;&gt;&lt;/a&gt;非监督学习&lt;/h2&gt;&lt;p&gt;比如在医疗保健方面，如果我们已经了解某种疾病，监督学习可用以帮助系统，识别哪些人有患该病的风险，而非监督学习实际上可以根据常见症状的模式帮助我们发现甚至我们还不知道的疾病。&lt;/p&gt;
&lt;h2 id=&quot;聚类：&quot;&gt;&lt;a href=&quot;#聚类：&quot; class=&quot;headerlink&quot; title=&quot;聚类：&quot;&gt;&lt;/a&gt;聚类：&lt;/h2&gt;&lt;p&gt;K-MEANS&lt;br&gt;
    
    </summary>
    
      <category term="机器学习" scheme="http://yoursite.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="机器学习" scheme="http://yoursite.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>机器学习-预测泰坦尼克号乘客生还率</title>
    <link href="http://yoursite.com/2018/01/11/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E9%A2%84%E6%B5%8B%E6%B3%B0%E5%9D%A6%E5%B0%BC%E5%85%8B%E5%8F%B7%E4%B9%98%E5%AE%A2%E7%94%9F%E8%BF%98%E7%8E%87/"/>
    <id>http://yoursite.com/2018/01/11/机器学习-预测泰坦尼克号乘客生还率/</id>
    <published>2018-01-11T08:02:30.000Z</published>
    <updated>2018-12-21T08:21:17.674Z</updated>
    
    <content type="html"><![CDATA[<h1 id="机器学习"><a href="#机器学习" class="headerlink" title="机器学习"></a>机器学习</h1><h2 id="项目-0-预测泰坦尼克号乘客生还率"><a href="#项目-0-预测泰坦尼克号乘客生还率" class="headerlink" title="项目 0: 预测泰坦尼克号乘客生还率"></a>项目 0: 预测泰坦尼克号乘客生还率</h2><p>1912年，泰坦尼克号在第一次航行中就与冰山相撞沉没，导致了大部分乘客和船员身亡。在这个入门项目中，我们将探索部分泰坦尼克号旅客名单，来确定哪些特征可以最好地预测一个人是否会生还。为了完成这个项目，你将需要实现几个基于条件的预测并回答下面的问题。我们将根据代码的完成度和对问题的解答来对你提交的项目的进行评估。 </p>
<h1 id="开始"><a href="#开始" class="headerlink" title="开始"></a>开始</h1><p>当我们开始处理泰坦尼克号乘客数据时，会先导入我们需要的功能模块以及将数据加载到 <code>pandas</code> DataFrame。运行下面区域中的代码加载数据，并使用 <code>.head()</code> 函数显示前几项乘客数据。 </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</div><div class="line"></div><div class="line"><span class="comment"># RMS Titanic data visualization code </span></div><div class="line"><span class="comment"># 数据可视化代码</span></div><div class="line"><span class="keyword">from</span> titanic_visualizations <span class="keyword">import</span> survival_stats</div><div class="line"><span class="keyword">from</span> IPython.display <span class="keyword">import</span> display</div><div class="line">%matplotlib inline</div><div class="line"></div><div class="line"><span class="comment"># Load the dataset </span></div><div class="line"><span class="comment"># 加载数据集</span></div><div class="line">in_file = <span class="string">'titanic_data.csv'</span></div><div class="line">full_data = pd.read_csv(in_file)</div><div class="line"></div><div class="line"><span class="comment"># Print the first few entries of the RMS Titanic data </span></div><div class="line"><span class="comment"># 显示数据列表中的前几项乘客数据</span></div><div class="line">display(full_data.head())</div></pre></td></tr></table></figure>
<a id="more"></a>
<table>
<thead>
<tr>
<th>序号</th>
<th>PassengerId</th>
<th>Survived</th>
<th>Pclass</th>
<th>Name</th>
<th>Sex</th>
<th>Age</th>
<th>SibSp</th>
<th>Parch</th>
<th>Ticket</th>
<th>Fare</th>
<th>Cabin</th>
<th>Embarked</th>
</tr>
</thead>
<tbody>
<tr>
<td>0</td>
<td>1</td>
<td>0</td>
<td>3</td>
<td>Braund, Mr. Owen Harris</td>
<td>male</td>
<td>22.0</td>
<td>1</td>
<td>0</td>
<td>A/5 21171</td>
<td>7.2500</td>
<td>NaN</td>
<td>S</td>
</tr>
<tr>
<td>1</td>
<td>2</td>
<td>1</td>
<td>1</td>
<td>Cumings, Mrs. John Bradley (Florence Briggs Th…</td>
<td>female</td>
<td>38.0</td>
<td>1</td>
<td>0</td>
<td>PC 17599</td>
<td>71.2833</td>
<td>C85</td>
<td>C</td>
</tr>
<tr>
<td>2</td>
<td>3</td>
<td>1</td>
<td>3</td>
<td>Heikkinen, Miss. Laina</td>
<td>female</td>
<td>26.0</td>
<td>0</td>
<td>0</td>
<td>STON/O2. 3101282</td>
<td>7.9250</td>
<td>NaN</td>
<td>S</td>
</tr>
<tr>
<td>3</td>
<td>4</td>
<td>1</td>
<td>1</td>
<td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>
<td>female</td>
<td>35.0</td>
<td>1</td>
<td>0</td>
<td>113803</td>
<td>53.1000</td>
<td>C123</td>
<td>S</td>
</tr>
<tr>
<td>4</td>
<td>5</td>
<td>0</td>
<td>3</td>
<td>Allen, Mr. William Henry</td>
<td>male</td>
<td>35.0</td>
<td>0</td>
<td>0</td>
<td>373450</td>
<td>8.0500</td>
<td>NaN</td>
<td>S</td>
</tr>
</tbody>
</table>
<p>从泰坦尼克号的数据样本中，我们可以看到船上每位旅客的特征</p>
<ul>
<li><strong>Survived</strong>：是否存活（0代表否，1代表是）</li>
<li><strong>Pclass</strong>：社会阶级（1代表上层阶级，2代表中层阶级，3代表底层阶级）</li>
<li><strong>Name</strong>：船上乘客的名字</li>
<li><strong>Sex</strong>：船上乘客的性别</li>
<li><strong>Age</strong>:船上乘客的年龄（可能存在 <code>NaN</code>）</li>
<li><strong>SibSp</strong>：乘客在船上的兄弟姐妹和配偶的数量</li>
<li><strong>Parch</strong>：乘客在船上的父母以及小孩的数量</li>
<li><strong>Ticket</strong>：乘客船票的编号</li>
<li><strong>Fare</strong>：乘客为船票支付的费用</li>
<li><strong>Cabin</strong>：乘客所在船舱的编号（可能存在 <code>NaN</code>）</li>
<li><strong>Embarked</strong>：乘客上船的港口（C 代表从 Cherbourg 登船，Q 代表从 Queenstown 登船，S 代表从 Southampton 登船）</li>
</ul>
<p>因为我们感兴趣的是每个乘客或船员是否在事故中活了下来。可以将 <strong>Survived</strong> 这一特征从这个数据集移除，并且用一个单独的变量 <code>outcomes</code> 来存储。它也做为我们要预测的目标。</p>
<p>运行该代码，从数据集中移除 <strong>Survived</strong> 这个特征，并将它存储在变量 <code>outcomes</code> 中。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># Store the 'Survived' feature in a new variable and remove it from the dataset </span></div><div class="line"><span class="comment"># 从数据集中移除 'Survived' 这个特征，并将它存储在一个新的变量中。</span></div><div class="line">outcomes = full_data[<span class="string">'Survived'</span>]</div><div class="line">data = full_data.drop(<span class="string">'Survived'</span>, axis = <span class="number">1</span>)</div><div class="line"></div><div class="line"><span class="comment"># Show the new dataset with 'Survived' removed</span></div><div class="line"><span class="comment"># 显示已移除 'Survived' 特征的数据集</span></div><div class="line">display(data.head())</div><div class="line"></div><div class="line">display(outcomes[<span class="number">1</span>])</div><div class="line"></div><div class="line">display(data.loc[<span class="number">1</span>])</div></pre></td></tr></table></figure>
<table>
<thead>
<tr>
<th style="text-align:center">序号</th>
<th>PassengerId</th>
<th>Pclass</th>
<th>Name</th>
<th>Sex</th>
<th>Age</th>
<th>SibSp</th>
<th>Parch</th>
<th>Ticket</th>
<th>Fare</th>
<th>Cabin</th>
<th>Embarked</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">0</td>
<td>1</td>
<td>3</td>
<td>Braund, Mr. Owen Harris</td>
<td>male</td>
<td>22.0</td>
<td>1</td>
<td>0</td>
<td>A/5 21171</td>
<td>7.2500</td>
<td>NaN</td>
<td>S</td>
</tr>
<tr>
<td style="text-align:center">1</td>
<td>2</td>
<td>1</td>
<td>Cumings, Mrs. John Bradley (Florence Briggs Th…</td>
<td>female</td>
<td>38.0</td>
<td>1</td>
<td>0</td>
<td>PC 17599</td>
<td>71.2833</td>
<td>C85</td>
<td>C</td>
</tr>
<tr>
<td style="text-align:center">2</td>
<td>3</td>
<td>3</td>
<td>Heikkinen, Miss. Laina</td>
<td>female</td>
<td>26.0</td>
<td>0</td>
<td>0</td>
<td>STON/O2. 3101282</td>
<td>7.9250</td>
<td>NaN</td>
<td>S</td>
</tr>
<tr>
<td style="text-align:center">3</td>
<td>4</td>
<td>1</td>
<td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>
<td>female</td>
<td>35.0</td>
<td>1</td>
<td>0</td>
<td>113803</td>
<td>53.1000</td>
<td>C123</td>
<td>S</td>
</tr>
<tr>
<td style="text-align:center">4</td>
<td>5</td>
<td>3</td>
<td>Allen, Mr. William Henry</td>
<td>male</td>
<td>35.0</td>
<td>0</td>
<td>0</td>
<td>373450</td>
<td>8.0500</td>
<td>NaN</td>
<td>S</td>
</tr>
</tbody>
</table>
<p> 1</p>
<pre><code>PassengerId                                                    2
Pclass                                                         1
Name           Cumings, Mrs. John Bradley (Florence Briggs Th...
Sex                                                       female
Age                                                           38
SibSp                                                          1
Parch                                                          0
Ticket                                                  PC 17599
Fare                                                     71.2833
Cabin                                                        C85
Embarked                                                       C
Name: 1, dtype: object
</code></pre><p>这个例子展示了如何将泰坦尼克号的 <strong>Survived</strong> 数据从 DataFrame 移除。注意到 <code>data</code>（乘客数据）和 <code>outcomes</code> （是否存活）现在已经匹配好。这意味着对于任何乘客的 <code>data.loc[i]</code> 都有对应的存活的结果 <code>outcome[i]</code>。</p>
<p>为了验证我们预测的结果，我们需要一个标准来给我们的预测打分。因为我们最感兴趣的是我们预测的<strong>准确率</strong>，既正确预测乘客存活的比例。运行下面的代码来创建我们的 <code>accuracy_score</code> 函数以对前五名乘客的预测来做测试。</p>
<p><strong>思考题</strong>：从第六个乘客算起，如果我们预测他们全部都存活，你觉得我们预测的准确率是多少？</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">accuracy_score</span><span class="params">(truth, pred)</span>:</span></div><div class="line">    <span class="string">""" Returns accuracy score for input truth and predictions. """</span></div><div class="line">    </div><div class="line">    <span class="comment"># Ensure that the number of predictions matches number of outcomes</span></div><div class="line">    <span class="comment"># 确保预测的数量与结果的数量一致</span></div><div class="line">    <span class="keyword">if</span> len(truth) == len(pred): </div><div class="line"><span class="comment">#         print "kaish1"</span></div><div class="line"><span class="comment">#         print truth</span></div><div class="line"><span class="comment">#         print "kaish2"</span></div><div class="line"><span class="comment">#         print pred</span></div><div class="line"><span class="comment">#         print "end"</span></div><div class="line">        <span class="comment"># Calculate and return the accuracy as a percent</span></div><div class="line">        <span class="comment"># 计算预测准确率（百分比）</span></div><div class="line">        <span class="keyword">return</span> <span class="string">"Predictions have an accuracy of &#123;:.2f&#125;%."</span>.format((truth == pred).mean()*<span class="number">100</span>)</div><div class="line">    </div><div class="line">    <span class="keyword">else</span>:</div><div class="line">        <span class="keyword">return</span> <span class="string">"Number of predictions does not match number of outcomes!"</span></div><div class="line">    </div><div class="line"><span class="comment"># Test the 'accuracy_score' function</span></div><div class="line"><span class="comment"># 测试 'accuracy_score' 函数</span></div><div class="line"><span class="comment"># print np.ones(5, dtype = int)</span></div><div class="line"><span class="comment"># print outcomes[:5]</span></div><div class="line">predictions = pd.Series(np.ones(<span class="number">5</span>, dtype = int))</div><div class="line"><span class="comment"># print accuracy_score(outcomes[:5], predictions)</span></div></pre></td></tr></table></figure>
<blockquote>
<p><strong>提示</strong>：如果你保存 iPython Notebook，代码运行的输出也将被保存。但是，一旦你重新打开项目，你的工作区将会被重置。请确保每次都从上次离开的地方运行代码来重新生成变量和函数。</p>
</blockquote>
<h1 id="预测"><a href="#预测" class="headerlink" title="预测"></a>预测</h1><p>如果我们要预测泰坦尼克号上的乘客是否存活，但是我们又对他们一无所知，那么最好的预测就是船上的人无一幸免。这是因为，我们可以假定当船沉没的时候大多数乘客都遇难了。下面的 <code>predictions_0</code> 函数就预测船上的乘客全部遇难。  </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">predictions_0</span><span class="params">(data)</span>:</span></div><div class="line">    <span class="string">""" Model with no features. Always predicts a passenger did not survive. """</span></div><div class="line"></div><div class="line">    predictions = []</div><div class="line">    <span class="keyword">for</span> _, passenger <span class="keyword">in</span> data.iterrows():</div><div class="line">        </div><div class="line">        <span class="comment"># Predict the survival of 'passenger'</span></div><div class="line">        <span class="comment"># 预测 'passenger' 的生还率</span></div><div class="line">        predictions.append(<span class="number">0</span>)</div><div class="line">    </div><div class="line">    <span class="comment"># Return our predictions</span></div><div class="line">    <span class="comment"># 返回预测结果</span></div><div class="line">    <span class="keyword">return</span> pd.Series(predictions)</div><div class="line"></div><div class="line"><span class="comment"># Make the predictions</span></div><div class="line"><span class="comment"># 进行预测</span></div><div class="line">predictions = predictions_0(data)</div></pre></td></tr></table></figure>
<h3 id="问题1"><a href="#问题1" class="headerlink" title="问题1"></a>问题1</h3><p>对比真实的泰坦尼克号的数据，如果我们做一个所有乘客都没有存活的预测，你认为这个预测的准确率能达到多少？</p>
<p><strong>提示</strong>：运行下面的代码来查看预测的准确率。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">print</span> accuracy_score(outcomes, predictions)</div></pre></td></tr></table></figure>
<pre><code>Predictions have an accuracy of 61.62%.
</code></pre><p><strong>回答:</strong> <em>请用上面出现的预测结果来替换掉这里的文字</em> 61.62%</p>
<hr>
<p>我们可以使用 <code>survival_stats</code> 函数来看看 <strong>Sex</strong> 这一特征对乘客的存活率有多大影响。这个函数定义在名为 <code>titanic_visualizations.py</code> 的 Python 脚本文件中，我们的项目提供了这个文件。传递给函数的前两个参数分别是泰坦尼克号的乘客数据和乘客的 生还结果。第三个参数表明我们会依据哪个特征来绘制图形。</p>
<p>运行下面的代码绘制出依据乘客性别计算存活率的柱形图。 </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">survival_stats(data, outcomes, <span class="string">'Sex'</span>)</div></pre></td></tr></table></figure>
<p><img src="http://oh6ybr0jg.bkt.clouddn.com/output_14_0.png" alt="此处输入图片的描述"></p>
<p>观察泰坦尼克号上乘客存活的数据统计，我们可以发现大部分男性乘客在船沉没的时候都遇难了。相反的，大部分女性乘客都在事故中<strong>生还</strong>。让我们在先前推断的基础上继续创建：如果乘客是男性，那么我们就预测他们遇难；如果乘客是女性，那么我们预测他们在事故中活了下来。</p>
<p>将下面的代码补充完整，让函数可以进行正确预测。  </p>
<p><strong>提示</strong>：您可以用访问 dictionary（字典）的方法来访问船上乘客的每个特征对应的值。例如， <code>passenger[&#39;Sex&#39;]</code> 返回乘客的性别。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">predictions_1</span><span class="params">(data)</span>:</span></div><div class="line">    <span class="string">""" Model with one feature: </span></div><div class="line">            - Predict a passenger survived if they are female. """</div><div class="line">    </div><div class="line">    predictions = []</div><div class="line">    <span class="keyword">for</span> _, passenger <span class="keyword">in</span> data.iterrows():</div><div class="line">        </div><div class="line">        <span class="comment"># Remove the 'pass' statement below </span></div><div class="line">        <span class="comment"># 移除下方的 'pass' 声明</span></div><div class="line">        <span class="comment"># and write your prediction conditions here</span></div><div class="line">        <span class="comment"># 输入你自己的预测条件</span></div><div class="line">        <span class="comment">#  print passenger['Sex']</span></div><div class="line">        </div><div class="line">        <span class="keyword">if</span>(passenger[<span class="string">'Sex'</span>] == <span class="string">"male"</span>) :</div><div class="line">            predictions.append(<span class="number">0</span>)</div><div class="line">        <span class="keyword">else</span> :</div><div class="line">            predictions.append(<span class="number">1</span>)</div><div class="line">    </div><div class="line">    <span class="comment"># Return our predictions</span></div><div class="line">    <span class="comment"># 返回预测结果</span></div><div class="line">    <span class="keyword">return</span> pd.Series(predictions)</div><div class="line"></div><div class="line"><span class="comment"># Make the predictions</span></div><div class="line"><span class="comment"># 进行预测</span></div><div class="line">predictions = predictions_1(data)</div><div class="line"></div><div class="line"><span class="comment"># print predictions</span></div></pre></td></tr></table></figure>
<h3 id="问题2"><a href="#问题2" class="headerlink" title="问题2"></a>问题2</h3><p>当我们预测船上女性乘客全部存活，而剩下的人全部遇难，那么我们预测的准确率会达到多少？</p>
<p><strong>提示</strong>：运行下面的代码来查看我们预测的准确率。 </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#print predictions</span></div><div class="line"><span class="keyword">print</span> accuracy_score(outcomes, predictions)</div></pre></td></tr></table></figure>
<pre><code>Predictions have an accuracy of 78.68%.
</code></pre><p><strong>回答</strong>: <em>用上面出现的预测结果来替换掉这里的文字</em> 78.68%.</p>
<hr>
<p>仅仅使用乘客性别（Sex）这一特征，我们预测的准确性就有了明显的提高。现在再看一下使用额外的特征能否更进一步提升我们的预测准确度。例如，综合考虑所有在泰坦尼克号上的男性乘客：我们是否找到这些乘客中的一个子集，他们的存活概率较高。让我们再次使用 <code>survival_stats</code> 函数来看看每位男性乘客的年龄（Age）。这一次，我们将使用第四个参数来限定柱形图中只有男性乘客。</p>
<p>运行下面这段代码，把男性基于年龄的生存结果绘制出来。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">survival_stats(data, outcomes, <span class="string">'Age'</span>, [<span class="string">"Sex == 'male'"</span>])</div></pre></td></tr></table></figure>
<p><img src="http://oh6ybr0jg.bkt.clouddn.com/output_21_0.png" alt="此处输入图片的描述"></p>
<p>仔细观察泰坦尼克号存活的数据统计，在船沉没的时候，大部分小于10岁的男孩都活着，而大多数10岁以上的男性都随着船的沉没而<strong>遇难</strong>。让我们继续在先前预测的基础上构建：如果乘客是女性，那么我们就预测她们全部存活；如果乘客是男性并且小于10岁，我们也会预测他们全部存活；所有其它我们就预测他们都没有幸存。  </p>
<p>将下面缺失的代码补充完整，让我们的函数可以实现预测。<br><strong>提示</strong>: 您可以用之前 <code>predictions_1</code> 的代码作为开始来修改代码，实现新的预测函数。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">predictions_2</span><span class="params">(data)</span>:</span></div><div class="line">    <span class="string">""" Model with two features: </span></div><div class="line">            - Predict a passenger survived if they are female.</div><div class="line">            - Predict a passenger survived if they are male and younger than 10. """</div><div class="line">    </div><div class="line">    predictions = []</div><div class="line">    <span class="keyword">for</span> _, passenger <span class="keyword">in</span> data.iterrows():</div><div class="line">        </div><div class="line">        <span class="comment"># Remove the 'pass' statement below </span></div><div class="line">        <span class="comment"># 移除下方的 'pass' 声明</span></div><div class="line">        <span class="comment"># and write your prediction conditions here</span></div><div class="line">        <span class="comment"># 输入你自己的预测条件</span></div><div class="line">        <span class="keyword">if</span>(passenger[<span class="string">'Sex'</span>] == <span class="string">"male"</span>) :</div><div class="line">           </div><div class="line">            <span class="keyword">if</span>(passenger[<span class="string">'Age'</span>] &lt; <span class="number">10</span>) :</div><div class="line">                predictions.append(<span class="number">1</span>)</div><div class="line">            <span class="keyword">else</span> :</div><div class="line">                predictions.append(<span class="number">0</span>)</div><div class="line">        <span class="keyword">else</span> :</div><div class="line">             predictions.append(<span class="number">1</span>)</div><div class="line">            </div><div class="line">    </div><div class="line">    <span class="comment"># Return our predictions</span></div><div class="line">    <span class="comment"># 返回预测结果</span></div><div class="line">    <span class="keyword">return</span> pd.Series(predictions)</div><div class="line"></div><div class="line"><span class="comment"># Make the predictions</span></div><div class="line"><span class="comment"># 进行预测</span></div><div class="line">predictions = predictions_2(data)</div><div class="line"></div><div class="line"><span class="comment"># print predictions</span></div></pre></td></tr></table></figure>
<h3 id="问题3"><a href="#问题3" class="headerlink" title="问题3"></a>问题3</h3><p>当预测所有女性以及小于10岁的男性都存活的时候，预测的准确率会达到多少？</p>
<p><strong>提示：</strong>运行下面的代码来查看预测的准确率。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">print</span> accuracy_score(outcomes, predictions)</div></pre></td></tr></table></figure>
<pre><code>Predictions have an accuracy of 79.35%.
</code></pre><p><strong>回答</strong>: <em>用上面出现的预测结果来替换掉这里的文字</em>   79.35%</p>
<hr>
<p>添加年龄（Age）特征与性别（Sex）的结合比单独使用性别（Sex）也提高了不少准确度。现在该你来做预测了：找到一系列的特征和条件来对数据进行划分，使得预测结果提高到80%以上。这可能需要多个特性和多个层次的条件语句才会成功。你可以在不同的条件下多次使用相同的特征。<strong>Pclass</strong>，<strong>Sex</strong>，<strong>Age</strong>，<strong>SibSp</strong> 和 <strong>Parch</strong> 是建议尝试使用的特征。   </p>
<p>使用 <code>survival_stats</code> 函数来观测泰坦尼克号上乘客存活的数据统计。<br><strong>提示:</strong> 要使用多个过滤条件，把每一个条件放在一个列表里作为最后一个参数传递进去。例如: <code>[&quot;Sex == &#39;male&#39;&quot;, &quot;Age &lt; 18&quot;]</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">survival_stats(data, outcomes, <span class="string">'Embarked'</span>, [<span class="string">"Sex == 'female'"</span>,<span class="string">"Pclass == 3"</span>])</div></pre></td></tr></table></figure>
<p><img src="http://oh6ybr0jg.bkt.clouddn.com/output_28_0.png" alt="此处输入图片的描述"></p>
<p>当查看和研究了图形化的泰坦尼克号上乘客的数据统计后，请补全下面这段代码中缺失的部分，使得函数可以返回你的预测。<br>在到达最终的预测模型前请确保记录你尝试过的各种特征和条件。<br><strong>提示:</strong> 您可以用之前 <code>predictions_2</code> 的代码作为开始来修改代码，实现新的预测函数。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">predictions_3</span><span class="params">(data)</span>:</span></div><div class="line">    <span class="string">""" Model with multiple features. Makes a prediction with an accuracy of at least 80%. """</span></div><div class="line">    </div><div class="line">    predictions = []</div><div class="line">    <span class="keyword">for</span> _, passenger <span class="keyword">in</span> data.iterrows():</div><div class="line">        </div><div class="line">        <span class="comment"># Remove the 'pass' statement below </span></div><div class="line">        <span class="comment"># and write your prediction conditions here</span></div><div class="line">        <span class="keyword">if</span>(passenger[<span class="string">'Sex'</span>] == <span class="string">"male"</span>) :</div><div class="line">           </div><div class="line">            <span class="keyword">if</span>(passenger[<span class="string">'Age'</span>] &lt; <span class="number">18</span>) :</div><div class="line">                <span class="keyword">if</span>(passenger[<span class="string">'Pclass'</span>] &lt; <span class="number">3</span> ) :</div><div class="line">                     predictions.append(<span class="number">1</span>)</div><div class="line">                <span class="keyword">else</span> :</div><div class="line">                     predictions.append(<span class="number">0</span>)</div><div class="line">            <span class="keyword">else</span> :</div><div class="line">                </div><div class="line">                    predictions.append(<span class="number">0</span>)      </div><div class="line">               </div><div class="line"><span class="comment">#                 print passenger['Pclass']</span></div><div class="line"><span class="comment">#                if(passenger['Pclass'] &gt; 1 ) :</span></div><div class="line"><span class="comment">#                     predictions.append(0)</span></div><div class="line"><span class="comment">#                else :</span></div><div class="line"><span class="comment">#                     predictions.append(1)</span></div><div class="line">        <span class="keyword">else</span> :</div><div class="line">            </div><div class="line">             <span class="keyword">if</span>(passenger[<span class="string">'Pclass'</span>] == <span class="number">3</span> ) :</div><div class="line">                    <span class="keyword">if</span>(passenger[<span class="string">'Embarked'</span>] == <span class="string">'S'</span> ) :</div><div class="line">                        predictions.append(<span class="number">0</span>)</div><div class="line">                    <span class="keyword">else</span> :</div><div class="line">                        predictions.append(<span class="number">1</span>)</div><div class="line">             <span class="keyword">else</span> :</div><div class="line">                    predictions.append(<span class="number">1</span>)</div><div class="line">    </div><div class="line">    <span class="comment"># Return our predictions</span></div><div class="line">    <span class="keyword">return</span> pd.Series(predictions)</div><div class="line"></div><div class="line"><span class="comment"># Make the predictions</span></div><div class="line">predictions = predictions_3(data)</div></pre></td></tr></table></figure>
<h3 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h3><p>请描述你实现80%准确度的预测模型所经历的步骤。您观察过哪些特征？某些特性是否比其他特征更有帮助？你用了什么条件来预测生还结果？你最终的预测的准确率是多少？<br><strong>提示:</strong>运行下面的代码来查看你的预测准确度。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">print</span> accuracy_score(outcomes, predictions)</div></pre></td></tr></table></figure>
<pre><code>Predictions have an accuracy of 82.38%.
</code></pre><p><strong>回答</strong>: <em>用上面问题的答案来替换掉这里的文字</em></p>
<h1 id="结论-1"><a href="#结论-1" class="headerlink" title="结论"></a>结论</h1><p>经过了数次对数据的探索和分类，你创建了一个预测泰坦尼克号乘客存活率的有用的算法。在这个项目中你手动地实现了一个简单的机器学习模型——决策树（decision tree）。决策树每次按照一个特征把数据分割成越来越小的群组（被称为 <em>nodes</em>）。每次数据的一个子集被分出来，如果分割结果的子集中的数据比之前更同质（包含近似的标签），我们的预测也就更加准确。电脑来帮助我们做这件事会比手动做更彻底，更精确。<a href="http://www.r2d3.us/visual-intro-to-machine-learning-part-1/" target="_blank" rel="external">这个链接</a>提供了另一个使用决策树做机器学习入门的例子。  </p>
<p>决策树是许多<strong>监督学习</strong>算法中的一种。在监督学习中，我们关心的是使用数据的特征并根据数据的结果标签进行预测或建模。也就是说，每一组数据都有一个真正的结果值，不论是像泰坦尼克号生存数据集一样的标签，或者是连续的房价预测。</p>
<h3 id="问题5"><a href="#问题5" class="headerlink" title="问题5"></a>问题5</h3><p>想象一个真实世界中应用监督学习的场景，你期望预测的结果是什么？举出两个在这个场景中能够帮助你进行预测的数据集中的特征。</p>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;机器学习&quot;&gt;&lt;a href=&quot;#机器学习&quot; class=&quot;headerlink&quot; title=&quot;机器学习&quot;&gt;&lt;/a&gt;机器学习&lt;/h1&gt;&lt;h2 id=&quot;项目-0-预测泰坦尼克号乘客生还率&quot;&gt;&lt;a href=&quot;#项目-0-预测泰坦尼克号乘客生还率&quot; class=&quot;headerlink&quot; title=&quot;项目 0: 预测泰坦尼克号乘客生还率&quot;&gt;&lt;/a&gt;项目 0: 预测泰坦尼克号乘客生还率&lt;/h2&gt;&lt;p&gt;1912年，泰坦尼克号在第一次航行中就与冰山相撞沉没，导致了大部分乘客和船员身亡。在这个入门项目中，我们将探索部分泰坦尼克号旅客名单，来确定哪些特征可以最好地预测一个人是否会生还。为了完成这个项目，你将需要实现几个基于条件的预测并回答下面的问题。我们将根据代码的完成度和对问题的解答来对你提交的项目的进行评估。 &lt;/p&gt;
&lt;h1 id=&quot;开始&quot;&gt;&lt;a href=&quot;#开始&quot; class=&quot;headerlink&quot; title=&quot;开始&quot;&gt;&lt;/a&gt;开始&lt;/h1&gt;&lt;p&gt;当我们开始处理泰坦尼克号乘客数据时，会先导入我们需要的功能模块以及将数据加载到 &lt;code&gt;pandas&lt;/code&gt; DataFrame。运行下面区域中的代码加载数据，并使用 &lt;code&gt;.head()&lt;/code&gt; 函数显示前几项乘客数据。 &lt;/p&gt;
&lt;figure class=&quot;highlight python&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;2&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;3&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;4&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;5&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;6&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;7&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;8&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;9&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;10&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;11&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;12&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;13&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;14&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;15&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;16&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;17&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;import&lt;/span&gt; numpy &lt;span class=&quot;keyword&quot;&gt;as&lt;/span&gt; np&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;import&lt;/span&gt; pandas &lt;span class=&quot;keyword&quot;&gt;as&lt;/span&gt; pd&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# RMS Titanic data visualization code &lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# 数据可视化代码&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;from&lt;/span&gt; titanic_visualizations &lt;span class=&quot;keyword&quot;&gt;import&lt;/span&gt; survival_stats&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;from&lt;/span&gt; IPython.display &lt;span class=&quot;keyword&quot;&gt;import&lt;/span&gt; display&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;%matplotlib inline&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# Load the dataset &lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# 加载数据集&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;in_file = &lt;span class=&quot;string&quot;&gt;&#39;titanic_data.csv&#39;&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;full_data = pd.read_csv(in_file)&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# Print the first few entries of the RMS Titanic data &lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# 显示数据列表中的前几项乘客数据&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;display(full_data.head())&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
    
    </summary>
    
      <category term="机器学习" scheme="http://yoursite.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="机器学习" scheme="http://yoursite.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
</feed>
