<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>张洪铭的个人博客</title>
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2019-08-04T15:09:02.531Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>张洪铭</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>flink源码3--StreamGraph-&gt;JobGraph-&gt;ExecutionGraph</title>
    <link href="http://yoursite.com/2019/08/04/flink%E6%BA%90%E7%A0%813--StreamGraph--JobGraph--ExecutionGraph/"/>
    <id>http://yoursite.com/2019/08/04/flink源码3--StreamGraph--JobGraph--ExecutionGraph/</id>
    <published>2019-08-04T11:30:00.000Z</published>
    <updated>2019-08-04T15:09:02.531Z</updated>
    
    <content type="html"><![CDATA[<p><img src="https://upload-images.jianshu.io/upload_images/10507536-19865f27607e82c0.png?imageMogr2/auto-orient/" alt="此处输入图片的描述"></p>
<p>我们接着分析StreamExecutionEnvironment这个类的实现类：<br>即我们在调用env.execute(“Flink StreamingChainingDemo”);<br>此处最新版的flink代码和以前的结构不同。先是调用的StreamExecutionEnvironment的execute代码</p>
<pre><code>public JobExecutionResult execute(String jobName) throws Exception {
    Preconditions.checkNotNull(jobName, &quot;Streaming Job name should not be null.&quot;);

    return execute(getStreamGraph(jobName));
}

@Internal
public StreamGraph getStreamGraph(String jobName) {
    return getStreamGraphGenerator().setJobName(jobName).generate();
}
private StreamGraphGenerator getStreamGraphGenerator() {
    if (transformations.size() &lt;= 0) {
        throw new IllegalStateException(&quot;No operators defined in streaming topology. Cannot execute.&quot;);
    }
    return new StreamGraphGenerator(transformations, config, checkpointCfg)
        .setStateBackend(defaultStateBackend)//null
        .setChaining(isChainingEnabled)//true
        .setUserArtifacts(cacheFile)
        .setTimeCharacteristic(timeCharacteristic)//DEFAULT_TIME_CHARACTERISTIC = TimeCharacteristic.ProcessingTime; //IngestionTime
        .setDefaultBufferTimeout(bufferTimeout);//100
}
</code></pre><p>根据transformations, config, checkpointCfg初始化StreamGraphGenerator</p>
<p>JobGraph:<br>接着会进入到LocalStreamEnvironment 这个实现类里面</p>
<pre><code>public JobExecutionResult execute(StreamGraph streamGraph) throws Exception {
        JobGraph jobGraph = streamGraph.getJobGraph();
        jobGraph.setAllowQueuedScheduling(true);

        Configuration configuration = new Configuration();
        configuration.addAll(jobGraph.getJobConfiguration());
        configuration.setString(TaskManagerOptions.MANAGED_MEMORY_SIZE, &quot;0&quot;);

        // add (and override) the settings with what the user defined
        configuration.addAll(this.configuration);

        if (!configuration.contains(RestOptions.BIND_PORT)) {
            configuration.setString(RestOptions.BIND_PORT, &quot;0&quot;);
        }

        int numSlotsPerTaskManager = configuration.getInteger(TaskManagerOptions.NUM_TASK_SLOTS, jobGraph.getMaximumParallelism());

        MiniClusterConfiguration cfg = new MiniClusterConfiguration.Builder()
            .setConfiguration(configuration)
            .setNumSlotsPerTaskManager(numSlotsPerTaskManager)
            .build();

        if (LOG.isInfoEnabled()) {
            LOG.info(&quot;Running job on local embedded Flink mini cluster&quot;);
        }

        MiniCluster miniCluster = new MiniCluster(cfg);

        try {
            miniCluster.start();
            configuration.setInteger(RestOptions.PORT, miniCluster.getRestAddress().get().getPort());

            return miniCluster.executeJobBlocking(jobGraph);
        }
        finally {
            transformations.clear();
            miniCluster.close();
        }
    }
</code></pre><p>streamGraph.getJobGraph 里</p>
<pre><code>@SuppressWarnings(&quot;deprecation&quot;)
@Override
public JobGraph getJobGraph(@Nullable JobID jobID) {
    // temporarily forbid checkpointing for iterative jobs
    if (isIterative() &amp;&amp; checkpointConfig.isCheckpointingEnabled() &amp;&amp; !checkpointConfig.isForceCheckpointing()) {
            throw new UnsupportedOperationException(
                &quot;Checkpointing is currently not supported by default for iterative jobs, as we cannot guarantee exactly once semantics. &quot;
                    + &quot;State checkpoints happen normally, but records in-transit during the snapshot will be lost upon failure. &quot;
                    + &quot;\nThe user can force enable state checkpoints with the reduced guarantees by calling: env.enableCheckpointing(interval,true)&quot;);
        }

    return StreamingJobGraphGenerator.createJobGraph(this, jobID);
}


public static JobGraph createJobGraph(StreamGraph streamGraph, @Nullable JobID jobID) {
    return new StreamingJobGraphGenerator(streamGraph, jobID).createJobGraph();
}


private JobGraph createJobGraph() {
    // make sure that all vertices start immediately
    jobGraph.setScheduleMode(streamGraph.getScheduleMode());

    // Generate deterministic hashes for the nodes in order to identify them across
    // submission iff they didn&apos;t change.
    Map&lt;Integer, byte[]&gt; hashes = defaultStreamGraphHasher.traverseStreamGraphAndGenerateHashes(streamGraph);

    // Generate legacy version hashes for backwards compatibility
    List&lt;Map&lt;Integer, byte[]&gt;&gt; legacyHashes = new ArrayList&lt;&gt;(legacyStreamGraphHashers.size());
    for (StreamGraphHasher hasher : legacyStreamGraphHashers) {
        legacyHashes.add(hasher.traverseStreamGraphAndGenerateHashes(streamGraph));
    }

    Map&lt;Integer, List&lt;Tuple2&lt;byte[], byte[]&gt;&gt;&gt; chainedOperatorHashes = new HashMap&lt;&gt;();

    setChaining(hashes, legacyHashes, chainedOperatorHashes);

    setPhysicalEdges();

    setSlotSharingAndCoLocation();

    configureCheckpointing();

    JobGraphGenerator.addUserArtifactEntries(streamGraph.getUserArtifacts(), jobGraph);

    // set the ExecutionConfig last when it has been finalized
    try {
        jobGraph.setExecutionConfig(streamGraph.getExecutionConfig());
    }
    catch (IOException e) {
            throw new IllegalConfigurationException(&quot;Could not serialize the ExecutionConfig.&quot; +
                    &quot;This indicates that non-serializable types (like custom serializers) were registered&quot;);
    }

        return jobGraph;
    }
</code></pre><p><strong>上面setChaining(hashes, legacyHashes, chainedOperatorHashes);其核心代码为：</strong><br>createChain的isChainable</p>
<pre><code>public static boolean isChainable(StreamEdge edge, StreamGraph streamGraph) {
    StreamNode upStreamVertex = streamGraph.getSourceVertex(edge);//获取StreamEdge的源和目标StreamNode
    StreamNode downStreamVertex = streamGraph.getTargetVertex(edge);

    StreamOperatorFactory&lt;?&gt; headOperator = upStreamVertex.getOperatorFactory();//获取源和目标StreamNode中的StreamOperator
    StreamOperatorFactory&lt;?&gt; outOperator = downStreamVertex.getOperatorFactory();
    //可以chaining的条件：
    return downStreamVertex.getInEdges().size() == 1//下游节点只有一个输入
            &amp;&amp; outOperator != null//下游节点的操作符不为null
            &amp;&amp; headOperator != null//上游节点的操作符不为null
            &amp;&amp; upStreamVertex.isSameSlotSharingGroup(downStreamVertex)//上下游节点在一个槽位共享组内
            &amp;&amp; outOperator.getChainingStrategy() == ChainingStrategy.ALWAYS//下游节点的连接策略是 ALWAYS
            &amp;&amp; (headOperator.getChainingStrategy() == ChainingStrategy.HEAD ||//上游节点的连接策略是 HEAD 或者 ALWAYS
                headOperator.getChainingStrategy() == ChainingStrategy.ALWAYS)
            &amp;&amp; (edge.getPartitioner() instanceof ForwardPartitioner)//edge 的分区函数是 ForwardPartitioner 的实例
            &amp;&amp; edge.getShuffleMode() != ShuffleMode.BATCH//边的shuffle模式为BATCH
            &amp;&amp; upStreamVertex.getParallelism() == downStreamVertex.getParallelism()//上下游节点的并行度相等
            &amp;&amp; streamGraph.isChainingEnabled();//isChainingEnabled为true，默认为true
}
</code></pre><p>只有上述的10个条件都同时满足时，才能说明两个StreamEdge的源和目标StreamNode是可以链接在一起执行的</p>
<pre><code>private List&lt;StreamEdge&gt; createChain(
            Integer startNodeId,
            Integer currentNodeId,
            Map&lt;Integer, byte[]&gt; hashes,
            List&lt;Map&lt;Integer, byte[]&gt;&gt; legacyHashes,
            int chainIndex,
            Map&lt;Integer, List&lt;Tuple2&lt;byte[], byte[]&gt;&gt;&gt; chainedOperatorHashes) {

        if (!builtVertices.contains(startNodeId)) {

            List&lt;StreamEdge&gt; transitiveOutEdges = new ArrayList&lt;StreamEdge&gt;();

            List&lt;StreamEdge&gt; chainableOutputs = new ArrayList&lt;StreamEdge&gt;();
            List&lt;StreamEdge&gt; nonChainableOutputs = new ArrayList&lt;StreamEdge&gt;();

            StreamNode currentNode = streamGraph.getStreamNode(currentNodeId);

            for (StreamEdge outEdge : currentNode.getOutEdges()) {
                if (isChainable(outEdge, streamGraph)) {
                    chainableOutputs.add(outEdge);
                } else {
                    nonChainableOutputs.add(outEdge);
                }
            }

            for (StreamEdge chainable : chainableOutputs) {
                transitiveOutEdges.addAll(
                        createChain(startNodeId, chainable.getTargetId(), hashes, legacyHashes, chainIndex + 1, chainedOperatorHashes));
            }

            for (StreamEdge nonChainable : nonChainableOutputs) {
                transitiveOutEdges.add(nonChainable);//不可连接的StreamEdge,输出StreamEdge放入transitiveOutEdges
                createChain(nonChainable.getTargetId(), nonChainable.getTargetId(), hashes, legacyHashes, 0, chainedOperatorHashes);//继续遍历可chaining的节点
            }
            //获取头节点散列值，没有初始化为空链表
            List&lt;Tuple2&lt;byte[], byte[]&gt;&gt; operatorHashes =
                chainedOperatorHashes.computeIfAbsent(startNodeId, k -&gt; new ArrayList&lt;&gt;());
            //获取当前节点散列值
            byte[] primaryHashBytes = hashes.get(currentNodeId);
            OperatorID currentOperatorId = new OperatorID(primaryHashBytes);
            //遍历legacyHashes  与primaryHashBytes组成二元数组，添加到链表中
            for (Map&lt;Integer, byte[]&gt; legacyHash : legacyHashes) {
                operatorHashes.add(new Tuple2&lt;&gt;(primaryHashBytes, legacyHash.get(currentNodeId)));
            }
            //通过-&gt; 拼接chaining名称
            chainedNames.put(currentNodeId, createChainedName(currentNodeId, chainableOutputs));
            chainedMinResources.put(currentNodeId, createChainedMinResources(currentNodeId, chainableOutputs));
            chainedPreferredResources.put(currentNodeId, createChainedPreferredResources(currentNodeId, chainableOutputs));

            if (currentNode.getInputFormat() != null) {
                getOrCreateFormatContainer(startNodeId).addInputFormat(currentOperatorId, currentNode.getInputFormat());
            }

            if (currentNode.getOutputFormat() != null) {
                getOrCreateFormatContainer(startNodeId).addOutputFormat(currentOperatorId, currentNode.getOutputFormat());
            }
            //创建jobVertex并设置并行度返回StreamConfig实例
            StreamConfig config = currentNodeId.equals(startNodeId)
                    ? createJobVertex(startNodeId, hashes, legacyHashes, chainedOperatorHashes)
                    : new StreamConfig(new Configuration());
            //设置序列化器，StreamOperator，checkpoint（默认AT_LEAST_ONCE）
            setVertexConfig(currentNodeId, config, chainableOutputs, nonChainableOutputs);

            if (currentNodeId.equals(startNodeId)) {

                config.setChainStart();
                config.setChainIndex(0);
                config.setOperatorName(streamGraph.getStreamNode(currentNodeId).getOperatorName());
                config.setOutEdgesInOrder(transitiveOutEdges);
                config.setOutEdges(streamGraph.getStreamNode(currentNodeId).getOutEdges());

                for (StreamEdge edge : transitiveOutEdges) {
                    connect(startNodeId, edge);//将JobVertex和JobEdge相连
                }
                //将chain中所有子节点的StreamConfig写入到 headOfChain 节点的  chainedTaskConfig_  配置中
                config.setTransitiveChainedTaskConfigs(chainedConfigs.get(startNodeId));

            } else {
                chainedConfigs.computeIfAbsent(startNodeId, k -&gt; new HashMap&lt;Integer, StreamConfig&gt;());

                config.setChainIndex(chainIndex);
                StreamNode node = streamGraph.getStreamNode(currentNodeId);
                config.setOperatorName(node.getOperatorName());
                chainedConfigs.get(startNodeId).put(currentNodeId, config);
            }

            config.setOperatorID(currentOperatorId);

            if (chainableOutputs.isEmpty()) {
                config.setChainEnd();
            }
            return transitiveOutEdges;

        } else {
            return new ArrayList&lt;&gt;();
        }
    }
</code></pre><p>遍历transitiveOutEdges，并将每一条StreamEdge边作为参数传入connect( )函数中:</p>
<pre><code>private void connect(Integer headOfChain, StreamEdge edge) {
        //将当前edge记录物理边界顺序集合中
        physicalEdgesInOrder.add(edge);
        //获取当前edge的下游节点ID
        Integer downStreamvertexID = edge.getTargetId();
        //获取上下游JobVertex节点
        JobVertex headVertex = jobVertices.get(headOfChain);
        JobVertex downStreamVertex = jobVertices.get(downStreamvertexID);
        //获取下游JobVertex的配置
        StreamConfig downStreamConfig = new StreamConfig(downStreamVertex.getConfiguration());
        //下游JobVertex的输入计数器加1
        downStreamConfig.setNumberOfInputs(downStreamConfig.getNumberOfInputs() + 1);

        StreamPartitioner&lt;?&gt; partitioner = edge.getPartitioner();
        //根据shuffle模式不同创建不同的ResultPartitionType
        ResultPartitionType resultPartitionType;
        switch (edge.getShuffleMode()) {
            case PIPELINED://有限的或无限的
                resultPartitionType = ResultPartitionType.PIPELINED_BOUNDED;
                break;
            case BATCH://仅在生成完整结果后向下游发送数据
                resultPartitionType = ResultPartitionType.BLOCKING;
                break;
            case UNDEFINED://blockingConnectionsBetweenChains 为true BLOCKING  flase 为PIPELINED_BOUNDED
                resultPartitionType = streamGraph.isBlockingConnectionsBetweenChains() ?
                        ResultPartitionType.BLOCKING : ResultPartitionType.PIPELINED_BOUNDED;
                break;
            default:
                throw new UnsupportedOperationException(&quot;Data exchange mode &quot; +
                    edge.getShuffleMode() + &quot; is not supported yet.&quot;);
        }
        //根据ForwardPartitioner和RescalePartitioner两种分区方式建立DistributionPattern.POINTWISE类型的JobEdge
        JobEdge jobEdge;
        if (partitioner instanceof ForwardPartitioner || partitioner instanceof RescalePartitioner) {
            jobEdge = downStreamVertex.connectNewDataSetAsInput(
                headVertex,
                DistributionPattern.POINTWISE,
                resultPartitionType);
        } else {//其他分区方式则是DistributionPattern.ALL_TO_ALL类型
            jobEdge = downStreamVertex.connectNewDataSetAsInput(
                    headVertex,
                    DistributionPattern.ALL_TO_ALL,
                    resultPartitionType);
        }
        // set strategy name so that web interface can show it. 设置策略名称方便web接口显示
        jobEdge.setShipStrategyName(partitioner.toString());

        if (LOG.isDebugEnabled()) {
            LOG.debug(&quot;CONNECTED: {} - {} -&gt; {}&quot;, partitioner.getClass().getSimpleName(),
                    headOfChain, downStreamvertexID);
        }
    }


public JobEdge connectNewDataSetAsInput(
            JobVertex input,
            DistributionPattern distPattern,
            ResultPartitionType partitionType) {
        //JobVertex和JobEdge之间通过创建IntermediateDataSet来连接
        IntermediateDataSet dataSet = input.createAndAddResultDataSet(partitionType);

        JobEdge edge = new JobEdge(dataSet, this, distPattern);
        this.inputs.add(edge);
        dataSet.addConsumer(edge);
        return edge;
    }

最后附上一副    
</code></pre><p><img src="https://upload-images.jianshu.io/upload_images/10507536-92418c0ca2da7a3d.png?imageMogr2/auto-orient/" alt="此处输入图片的描述"></p>
<p>execute方法最后执行。<br>miniCluster.executeJobBlocking(jobGraph);<br>中间一些列Akka 的RPC通讯省略不表，对并发编程有兴趣可以研究下Akka 和Actor</p>
<p>ExecutionGraph：</p>
<pre><code>public JobExecutionResult executeJobBlocking(JobGraph job) throws JobExecutionException, InterruptedException {
        checkNotNull(job, &quot;job is null&quot;);

        final CompletableFuture&lt;JobSubmissionResult&gt; submissionFuture = submitJob(job);

        final CompletableFuture&lt;JobResult&gt; jobResultFuture = submissionFuture.thenCompose(
            (JobSubmissionResult ignored) -&gt; requestJobResult(job.getJobID()));

        final JobResult jobResult;

        try {
            jobResult = jobResultFuture.get();
        } catch (ExecutionException e) {
            throw new JobExecutionException(job.getJobID(), &quot;Could not retrieve JobResult.&quot;, ExceptionUtils.stripExecutionException(e));
        }

        try {
            return jobResult.toJobExecutionResult(Thread.currentThread().getContextClassLoader());
        } catch (IOException | ClassNotFoundException e) {
            throw new JobExecutionException(job.getJobID(), e);
        }
    }
public CompletableFuture&lt;JobSubmissionResult&gt; submitJob(JobGraph jobGraph) {
    final CompletableFuture&lt;DispatcherGateway&gt; dispatcherGatewayFuture = getDispatcherGatewayFuture();

    // we have to allow queued scheduling in Flip-6 mode because we need to request slots
    // from the ResourceManager
    jobGraph.setAllowQueuedScheduling(true);

    final CompletableFuture&lt;InetSocketAddress&gt; blobServerAddressFuture = createBlobServerAddress(dispatcherGatewayFuture);

    final CompletableFuture&lt;Void&gt; jarUploadFuture = uploadAndSetJobFiles(blobServerAddressFuture, jobGraph);

    final CompletableFuture&lt;Acknowledge&gt; acknowledgeCompletableFuture = jarUploadFuture
        .thenCombine(
            dispatcherGatewayFuture,
            (Void ack, DispatcherGateway dispatcherGateway) -&gt; dispatcherGateway.submitJob(jobGraph, rpcTimeout))
        .thenCompose(Function.identity());

    return acknowledgeCompletableFuture.thenApply(
        (Acknowledge ignored) -&gt; new JobSubmissionResult(jobGraph.getJobID()));
}
</code></pre>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;https://upload-images.jianshu.io/upload_images/10507536-19865f27607e82c0.png?imageMogr2/auto-orient/&quot; alt=&quot;此处输入图片的描述&quot;&gt;&lt;/p&gt;
&lt;p&gt;我
    
    </summary>
    
      <category term="大数据" scheme="http://yoursite.com/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
      <category term="flink" scheme="http://yoursite.com/tags/flink/"/>
    
  </entry>
  
  <entry>
    <title>flink源码2</title>
    <link href="http://yoursite.com/2019/08/03/flink%E6%BA%90%E7%A0%812/"/>
    <id>http://yoursite.com/2019/08/03/flink源码2/</id>
    <published>2019-08-03T03:30:00.000Z</published>
    <updated>2019-08-04T15:08:28.849Z</updated>
    
    <content type="html"><![CDATA[<p>根据上篇文章内容扩展一下chaining demo</p>
<p>首先写一个streaming的 wordcount</p>
<pre><code>public class StreamingChainingDemo {

@Data
@AllArgsConstructor
@NoArgsConstructor
public static class KeyCount{
    private String key;
    private int count;
}

public static void main(String[] args) throws Exception {
    // set up the streaming execution environment

    Configuration configuration= new Configuration(){
        {
            setInteger(&quot;rest.port&quot;,9191);
            setBoolean(&quot;local.start-webserver&quot;,true);
        }
    };
    final StreamExecutionEnvironment env = StreamExecutionEnvironment.createLocalEnvironmentWithWebUI(configuration);

    env.setParallelism(2).setStreamTimeCharacteristic(TimeCharacteristic.IngestionTime);
    DataStreamSource&lt;String&gt; dataStreamSource = env.socketTextStream(&quot;localhost&quot;, 9999);
    dataStreamSource.flatMap((String line, Collector&lt;KeyCount&gt; out)
    -&gt; {
         Stream.of(line.split(&quot;\\s+&quot;)).forEach(value -&gt; out.collect(new KeyCount(value,1)));
       }
    ).returns(Types.POJO(KeyCount.class))
    .keyBy(new KeySelector&lt;KeyCount, Object&gt;() {
        @Override
        public Object getKey(KeyCount value) throws Exception {
            return value.getKey();
        }
    }).timeWindow(Time.seconds(10)).sum(&quot;count&quot;).print();
    // execute program
    env.execute(&quot;Flink StreamingChainingDemo&quot;);
}
</code></pre><p>}</p>
<p>运行如上代码后我们看WEB UI<br><img src="https://s2.ax1x.com/2019/08/03/esAc8K.png" alt="此处输入图片的描述"><br>可以看到keyBy操作和sink是chaining在一起的。<br>如果我们在print()的后面加上.disableChaining()</p>
<p><img src="https://s2.ax1x.com/2019/08/03/esErLQ.png" alt="此处输入图片的描述"></p>
<p>可以看到keyBy和sink是forward的并非chaining在一起</p>
<p>此时我们在returns(Types.POJO(KeyCount.class))<br>后面增加.filter(word-&gt; !””.equals(word))<br>大家猜flat和filter会chaining在一起吗？</p>
<p><img src="https://s2.ax1x.com/2019/08/03/esEfzT.png" alt="此处输入图片的描述"></p>
<p>yeah，你答对了吗？flat和filter会chaining在一起。</p>
<p>这时 我引入并行度的概念：<br>在.filter(word-&gt; !””.equals(word))<br>后面机上.setParallelism(3)</p>
<p>就会发现flat和filter是Reblance的关系<br><img src="https://s2.ax1x.com/2019/08/03/esE7w9.png" alt="此处输入图片的描述"></p>
<p>StreamOperator 源码解析<br>这个接口继承 CheckpointListener, KeyContext, Disposable, Serializable</p>
<p>提供了如下方法：</p>
<p>生命周期相关：<br>    open<br>    close<br>    dispose<br>    prepareSnapshotPreBarrier</p>
<p>容错与状态</p>
<pre><code>snapshotState
initializeState
</code></pre><p>与StreamRecord相关</p>
<pre><code>setKeyContextElement1
setKeyContextElement2
</code></pre><p>chain相关</p>
<pre><code>getChainingStrategy
setChainingStrategy
</code></pre><p>监控相关</p>
<pre><code>getMetricGroup
getOperatorID
</code></pre><p>AbstractStreamOperator，OneInputStreamOperator与TwoInputStreamOperator接口继承自StreamOperator</p>
<p>OneInputStreamOperator有3个方法</p>
<pre><code>processElement
processWatermark
processLatencyMarker
</code></pre><p>TwoInputStreamOperator有6个方法</p>
<pre><code>processElement1
processElement2
processWatermark1
processWatermark2
processLatencyMarker1
processLatencyMarker2
</code></pre><p>AbstractStreamOperator 重要的变量：后面会将具体的用法用处<br>决定是否在生成JobGraph时对算子进行Chaining优化：</p>
<pre><code>protected ChainingStrategy chainingStrategy = ChainingStrategy.HEAD; 
</code></pre><p>3个与状态相关的变量</p>
<pre><code>private transient AbstractKeyedStateBackend&lt;?&gt; keyedStateBackend;
private transient DefaultKeyedStateStore keyedStateStore;
private transient OperatorStateBackend operatorStateBackend;
</code></pre><p>监控相关的变量</p>
<pre><code>protected transient OperatorMetricGroup metrics;
protected transient LatencyStats latencyStats;
</code></pre><p>方法作用和父类大同小异此处略</p>
<p>AbstractStreamOperator的子类抽象类AbstractUdfStreamOperator<br>这个抽象类同时实现了OutputTypeConfigurable接口并重写了setOutputType方法设置了输出类型</p>
<p>最后我们来看<br>OneInputStreamOperator这个类的实现类：</p>
<p>StreamFilter，StreamMap与StreamFlatMap算子在实现的processElement分别调用传入的FilterFunction，MapFunction， FlatMapFunction的udf将element传到下游。其中StreamFlatMap用到了TimestampedCollector，它是output的一层封装，将timestamp加入到StreamRecord中发送到下游。</p>
<p>StreamGroupedReduce与StreamGroupedFold算子相似的点是都涉及到了操作状态, 所以在覆盖open方法时通过创建一个状态的描述符以及调用AbstractStreamOperator实现的getPartitionedState方法获取了一个stateBackend的操作句柄。在processElement方法中借助这个句柄获取当前状态值，在用UDF将新的元素聚合进去并更新状态值，最后输出到下游。不同的是Fold的输出类型可能不一样（所以实现了OutputTypeConfigurable接口的setOutputType方法），并且有初始值。</p>
<p>ProcessOperator， LegacyKeyedProcessOperator（@Deprecated）<br>ProcessFunction是比较灵活的UDF，允许用户通过在processElement的时候可以通过传入的ctx操作TimerService<br>注册ProcessingTimeTimer和EventTimeTimer，并且通过实现方法onTimer就可以在Timer被触发的时候执行回调的逻辑。</p>
<p>StreamSink：<br>SimpleContext，可以获取processingTime，watermark和element的时间戳。<br>GenericWriteAheadSink提供了一个可以被实现为Exactly once的sink的抽象类<br>AsyncWaitOperator提供了异步处理的能力，是一个比较特殊的算子，对元素的处理和备份恢复都比较特殊。element的输出通过一个Emitter对象来实现<br>TimestampsAndPeriodicWatermarksOperator，TimestampsAndPunctuatedWatermarksOperator通过TimestampAssigner提取timestamp并生按照规则生成watermark</p>
<p>和TwoInputStreamOperator这个类的实现类<br>CoStreamMap， CoStreamFlatMap基本与单流的逻辑没什么区别，只是针对两个流的Function做类似的处理。<br>IntervalJoinOperator对双流的元素根据提供的ProcessJoinFunction做内连接，并且每个元素都有失效时间。在processElement方法中，每当一个流的元素到达，会将它加入对应流的buffer，并且遍历另一个流的buffer找到所有join的选项。最后再根据失效时间注册一个状态清理的Timer防止buffer无限增长。</p>
<p>CoBroadcastWithKeyedOperator和CoBroadcastWithNonKeyedOperator提供了对(Keyed)BroadcastProcessFunction的支持，和CoProcess有一些类似，只是Broadcast的Stream只有读权限，没有写权限。并且可以通过context直接获得BroadcastState</p>
<p>CoProcessOperator和KeyedCoProcessOperator本质上与单流的处理也没有什么区别，但是提供了双流之间共享状态的可能。CoProcessOperator也被用来实现NonWindowJoin</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;根据上篇文章内容扩展一下chaining demo&lt;/p&gt;
&lt;p&gt;首先写一个streaming的 wordcount&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;public class StreamingChainingDemo {

@Data
@AllArgsConstructor
    
    </summary>
    
      <category term="大数据" scheme="http://yoursite.com/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
      <category term="flink" scheme="http://yoursite.com/tags/flink/"/>
    
  </entry>
  
  <entry>
    <title>flink源码1</title>
    <link href="http://yoursite.com/2019/08/02/flink%E6%BA%90%E7%A0%811/"/>
    <id>http://yoursite.com/2019/08/02/flink源码1/</id>
    <published>2019-08-02T12:30:00.000Z</published>
    <updated>2019-08-04T15:09:27.458Z</updated>
    
    <content type="html"><![CDATA[<p>nc -lk 9000<br> bin/flink run examples/streaming/SocketWindowWordCount.jar –hostname localhost –port 9000</p>
<p>编译flink<br>git clone <a href="https://github.com/apache/flink.git" target="_blank" rel="external">https://github.com/apache/flink.git</a><br>cd flink<br>mvn clean package -DskipTests # this will take up to 10 minutes</p>
<p>Flink源码阅读：<br>从读取文件开始：<br>例如env.readFileStream<br>共有如下DataSource：</p>
<pre><code>fromElements
fromElements
fromCollection
fromCollection
fromCollection
fromCollection
fromParallelCollection
fromParallelCollection
fromParallelCollection
readTextFile
readTextFile
readFile
readFile
readFile
readFileStream
readFile
socketTextStream
socketTextStream
socketTextStream
socketTextStream
socketTextStream
createInput
createInput
createInput
createFileInput
addSource
addSource
addSource
addSource

public DataStream&lt;String&gt; readFileStream(String filePath, long intervalMillis, FileMonitoringFunction.WatchType watchType) {
    DataStream&lt;Tuple3&lt;String, Long, Long&gt;&gt; source = addSource(new FileMonitoringFunction(
            filePath, intervalMillis, watchType), &quot;Read File Stream source&quot;);

    return source.flatMap(new FileReadFunction());
}
</code></pre><p>第三个参数分为：</p>
<pre><code>ONLY_NEW_FILES, // Only new files will be processed. 仅处理新增文件
REPROCESS_WITH_APPENDED, // When some files are appended, all contents of the files will be processed. 当文件内容增加了之后会重新处理整个文件。
PROCESS_ONLY_APPENDED // When some files are appended, only appended  contents will be processed. 当文件内容增加了之后只处理新增加内容
</code></pre><p>FileMonitoringFunction 继承于SourceFunction<br>接口SourceFunction有两个方法：<br>run  业务逻辑方法<br>cancel  取消数据源的数据产生<br>FileMonitoringFunction实现了这两个方法</p>
<pre><code>@Override
public void run(SourceContext&lt;Tuple3&lt;String, Long, Long&gt;&gt; ctx) throws Exception {
    FileSystem fileSystem = FileSystem.get(new URI(path));

    while (isRunning) {
        List&lt;String&gt; files = listNewFiles(fileSystem);//列出新增文件
        for (String filePath : files) {
            if (watchType == WatchType.ONLY_NEW_FILES
                    || watchType == WatchType.REPROCESS_WITH_APPENDED) {
                ctx.collect(new Tuple3&lt;String, Long, Long&gt;(filePath, 0L, -1L));//从头到尾收集数据
                offsetOfFiles.put(filePath, -1L);
            } else if (watchType == WatchType.PROCESS_ONLY_APPENDED) {
                long offset = 0;
                long fileSize = fileSystem.getFileStatus(new Path(filePath)).getLen();
                if (offsetOfFiles.containsKey(filePath)) {
                    offset = offsetOfFiles.get(filePath);
                }
                //只收集新增部分数据，即从上次获取的offset到这次文件末尾filesize
                ctx.collect(new Tuple3&lt;String, Long, Long&gt;(filePath, offset, fileSize));
                offsetOfFiles.put(filePath, fileSize);

                LOG.info(&quot;File processed: {}, {}, {}&quot;, filePath, offset, fileSize);
            }
        }

        Thread.sleep(interval);
    }
}

private List&lt;String&gt; listNewFiles(FileSystem fileSystem) throws IOException {
    List&lt;String&gt; files = new ArrayList&lt;String&gt;();

    FileStatus[] statuses = fileSystem.listStatus(new Path(path));//列出给定路径中文件/目录的状态（如果路径为一个目录。)
    //FileStatus 有getLen，getBlockSize,getReplication,getModificationTime，getAccessTime，isDir,getPath方法

    if (statuses == null) {
        LOG.warn(&quot;Path does not exist: {}&quot;, path);
    } else {
        for (FileStatus status : statuses) {
            Path filePath = status.getPath();
            String fileName = filePath.getName();
            long modificationTime = status.getModificationTime();

            if (!isFiltered(fileName, modificationTime)) {
                //当WatchType 为ONLY_NEW_FILES并且modificationTimes这个map包含读取的文件时即新增文件
                // 或文件修改时间大于modificationTime时为true
                files.add(filePath.toString());
                modificationTimes.put(fileName, modificationTime);
            }
        }
    }

    return files;
}
</code></pre><p>接下来为们看canal方法只做了一件事挺直running</p>
<pre><code>@Override
public void cancel() {
        isRunning = false;
}
</code></pre><p>对FileMonitoringFunction的实现清楚之后，回到StreamExecutionEnvironment中，看addSource方法。</p>
<pre><code>public &lt;OUT&gt; DataStreamSource&lt;OUT&gt; addSource(SourceFunction&lt;OUT&gt; function, String sourceName) {
    return addSource(function, sourceName, null);
}

public &lt;OUT&gt; DataStreamSource&lt;OUT&gt; addSource(SourceFunction&lt;OUT&gt; function, String sourceName, TypeInformation&lt;OUT&gt; typeInfo) {

    if (function instanceof ResultTypeQueryable) {
        //如果传入的function实现了ResultTypeQueryable接口, 则直接通过接口获取
        typeInfo = ((ResultTypeQueryable&lt;OUT&gt;) function).getProducedType();
    }
    if (typeInfo == null) {
        try {
            typeInfo = TypeExtractor.createTypeInfo(
                    SourceFunction.class,
                    function.getClass(), 0, null, null);//这个方法有点长，实际是typeInfo为空通过反射机制来提取typeInfo
        } catch (final InvalidTypesException e) {
            //获取失败返回MissingTypeInfo实例，里面两个变量：functionName，typeException
            typeInfo = (TypeInformation&lt;OUT&gt;) new MissingTypeInfo(sourceName, e);
        }
    }
    //根据function是实现了ParallelSourceFunction来判断是否是一个并行数据源节点
    boolean isParallel = function instanceof ParallelSourceFunction;
    //闭包清理, 可减少序列化内容, 以及防止序列化出错
    clean(function);
    //初始化一个ChainingStrategy.HEAD节点
    final StreamSource&lt;OUT, ?&gt; sourceOperator = new StreamSource&lt;&gt;(function);
    return new DataStreamSource&lt;&gt;(this, typeInfo, sourceOperator, isParallel, sourceName);//返回DataStreamSource
}
</code></pre><p>由于FileMonitoringFunction继承的是SourceFunction不是    ParallelSourceFunction 故isParallel为flase，即并行度为1<br>上面看到ChainingStrategy这个枚举类实际有三个属性：<br>ALWAYS  表示尽可能的与前后operator chaining<br>NEVER  表示不会chaining<br>HEAD  表示只会chaining后面。具体后面详细讲解其作用</p>
<p>接下来看最后一个函数DataStreamSource</p>
<pre><code>public DataStreamSource(StreamExecutionEnvironment environment,
        TypeInformation&lt;T&gt; outTypeInfo, StreamSource&lt;T, ?&gt; operator,
        boolean isParallel, String sourceName) {
    super(environment, new SourceTransformation&lt;&gt;(sourceName, operator, outTypeInfo, environment.getParallelism()));

    this.isParallel = isParallel;
    if (!isParallel) {
        setParallelism(1);
    }
}

protected SingleOutputStreamOperator(StreamExecutionEnvironment environment, Transformation&lt;T&gt; transformation) {
    super(environment, transformation);
}

public DataStream(StreamExecutionEnvironment environment, Transformation&lt;T&gt; transformation) {
    this.environment = Preconditions.checkNotNull(environment, &quot;Execution Environment must not be null.&quot;);
    this.transformation = Preconditions.checkNotNull(transformation, &quot;Stream Transformation must not be null.&quot;);
}
</code></pre><p>后面就是一系列transform 后面章节详细介绍</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;nc -lk 9000&lt;br&gt; bin/flink run examples/streaming/SocketWindowWordCount.jar –hostname localhost –port 9000&lt;/p&gt;
&lt;p&gt;编译flink&lt;br&gt;git clone &lt;a 
    
    </summary>
    
      <category term="大数据" scheme="http://yoursite.com/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
      <category term="flink" scheme="http://yoursite.com/tags/flink/"/>
    
  </entry>
  
  <entry>
    <title>机器学习-神经网络</title>
    <link href="http://yoursite.com/2018/08/25/Machine%20learning%20Artificial%20Neural%20Network/"/>
    <id>http://yoursite.com/2018/08/25/Machine learning Artificial Neural Network/</id>
    <published>2018-08-25T07:36:00.000Z</published>
    <updated>2018-09-01T14:15:55.889Z</updated>
    
    <content type="html"><![CDATA[<p>什么是人工神经网络模型<br>人工神经网络(Artificial Neural Network, ANN)没有一个严格的正式定义。它的基本特点，是试图模仿大脑的神经元之间传递，处理信息的模式。</p>
<p>一个计算模型，要被称为为神经网络，通常需要大量彼此连接的节点 （也称 ‘神经元’），并且具备两个特性：<br>每个神经元，通过某种特定的输出函数 （也叫激励函数 activation function），计算处理来自其它相邻神经元的加权输入值<br>神经元之间的信息传递的强度，用所谓加权值来定义，算法会不断自我学习，调整这个加权值<br>总结：神经网络算法的核心就是：计算、连接、评估、纠错、学习</p>
<h4 id="神经网络模型可以分为："><a href="#神经网络模型可以分为：" class="headerlink" title="神经网络模型可以分为："></a><strong>神经网络模型可以分为：</strong></h4><h6 id="前向网络"><a href="#前向网络" class="headerlink" title="前向网络"></a><strong>前向网络</strong></h6><p>网络中各个神经元接受前一级的输入，并输出到下一级，网络中没有反馈，可以用一个有向无环路图表示。这种网络实现信号从输入空间到输出空间的变换，它的信息处理能力来自于简单非线性函数的多次复合。网络结构简单，易于实现。反传网络是一种典型的前向网络。</p>
<h6 id="反馈网络"><a href="#反馈网络" class="headerlink" title="反馈网络"></a><strong>反馈网络</strong></h6><p>网络内神经元间有反馈，可以用一个无向的完备图表示。这种神经网络的信息处理是状态的变换，可以用动力学系统理论处理。系统的稳定性与联想记忆功能有密切关系。Hopfield网络、波耳兹曼机均属于这种类型。</p>
<h4 id="激活函数"><a href="#激活函数" class="headerlink" title="激活函数"></a><strong>激活函数</strong></h4><p>用于处理复杂的非线性分类情况。比线性回归、logistic回归灵活。训练的时候注意过拟合。<br>非线性激活函数<br>Sigmoid<br>𝑓(𝑥)=1/(1+exp⁡(−𝑥))<br>特点：<br>当x趋近负无穷时，y趋近于0；趋近于正无穷时，y趋近于1；<br>x超出[-6,6]的范围后，函数值基本上没有变化，值非常接近0或者1<br>该函数的值域范围限制在(0,1)之间，这样sigmoid函数就能与一个概率分布联系起来了。<br>𝑓^′ (𝑥)=𝑓(𝑥)(1−𝑓(𝑥))</p>
<h4 id="双曲正切"><a href="#双曲正切" class="headerlink" title="双曲正切"></a><strong>双曲正切</strong></h4><p>tanh⁡(𝑥)=(𝑒^𝑥−𝑒^(−𝑥))/(𝑒^𝑥+𝑒^(−𝑥) )<br>特点：<br>当x趋近负无穷时，y趋近于-1；趋近于正无穷时，y趋近于1；<br>x超出[-3,3]的范围后，函数值基本上没有变化，值非常接近-1或者1<br>该函数的值域范围限制在(-1,1)之间<br>tanh^′ (𝑥)=1−tanh(x)^2</p>
<h4 id="修正线性单元Rectifier-Linear-Units（ReLU）"><a href="#修正线性单元Rectifier-Linear-Units（ReLU）" class="headerlink" title="修正线性单元Rectifier Linear Units（ReLU）"></a><strong>修正线性单元Rectifier Linear Units（ReLU）</strong></h4><p>𝑓(𝑥)=max⁡(0,𝑥)<br>特点：<br>只有有一半隐含层是处于激活状态，其余都是输出为0<br>不会出现梯度消失的问题（即在sigmoid接近饱和区时，导数趋于0，这种情况会造成信息丢失）<br>只需比较、乘加运算，因此计算方便，计算速度快，加速了网络的训练<br>ReLU比sigmoid更接近生物学的激活模型<br>还有一些改进或的变体</p>
<h4 id="Softplus"><a href="#Softplus" class="headerlink" title="Softplus"></a><strong>Softplus</strong></h4><p>𝑓(𝑥)=log⁡(1+𝑒^𝑥 )<br>特点：<br>x趋于负无穷时，softplus趋于0；x趋于正无穷时， softplus趋于x<br>它是ReLU的平滑版<br>它是sigmoid的原函数</p>
<h3 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a><strong>损失函数</strong></h3><p>用于回归中的均方损失：<br>𝐸=1/2 (𝑦−𝑦 ̂ )^2<br>用于分类中的交叉熵损失函数：<br>𝐸=−∑▒〖𝑦<em>𝑘 𝑙𝑜𝑔((𝑦</em>𝑘 ) ̂ )” “ 〗<br>k=1,2,…,m表示m种类别。在违约预测中m=2</p>
<p>基于 Anaconda 的安装<br>安装tensorflow<br>建立一个 conda 计算环境名字叫tensorflow:</p>
<h1 id="Python-2-7"><a href="#Python-2-7" class="headerlink" title="Python 2.7"></a>Python 2.7</h1><p>$ conda create -n tensorflow python=2.7</p>
<h1 id="Python-3-4"><a href="#Python-3-4" class="headerlink" title="Python 3.4"></a>Python 3.4</h1><p>$ conda create -n tensorflow python=3.4</p>
<p>activate tensorflow</p>
<p>安装tensorflow<br>conda install –channel <a href="https://conda.anaconda.org/conda-forge" target="_blank" rel="external">https://conda.anaconda.org/conda-forge</a> tensorflow</p>
<p>import tensorflow as tf<br>退出python3环境或当你不用 TensorFlow 的时候,关闭环境:<br>(tensorflow)$  deactivate<br>$  # Your prompt should change back</p>
<p>windows下安装<br>升级pip<br>python -m pip install –upgrade pip<br>安装tensorflow<br>pip3 install –upgrade <a href="https://storage.googleapis.com/tensorflow/windows/cpu/tensorflow-0.12.0-cp35-cp35m-win_amd64.whl" target="_blank" rel="external">https://storage.googleapis.com/tensorflow/windows/cpu/tensorflow-0.12.0-cp35-cp35m-win_amd64.whl</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;什么是人工神经网络模型&lt;br&gt;人工神经网络(Artificial Neural Network, ANN)没有一个严格的正式定义。它的基本特点，是试图模仿大脑的神经元之间传递，处理信息的模式。&lt;/p&gt;
&lt;p&gt;一个计算模型，要被称为为神经网络，通常需要大量彼此连接的节点 （也
    
    </summary>
    
      <category term="机器学习" scheme="http://yoursite.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="机器学习" scheme="http://yoursite.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>TensorFlow 安装使用</title>
    <link href="http://yoursite.com/2018/08/18/Install%20TensorFlow/"/>
    <id>http://yoursite.com/2018/08/18/Install TensorFlow/</id>
    <published>2018-08-18T03:30:00.000Z</published>
    <updated>2018-09-01T14:15:41.490Z</updated>
    
    <content type="html"><![CDATA[<h2 id="基于Anaconda的Tensorflow"><a href="#基于Anaconda的Tensorflow" class="headerlink" title="基于Anaconda的Tensorflow"></a>基于Anaconda的Tensorflow</h2><h3 id="安装Anaconda"><a href="#安装Anaconda" class="headerlink" title="安装Anaconda"></a>安装Anaconda</h3><p>根据官网选择基于不同的python版本安装：<br><a href="https://www.anaconda.com/download/#windows" target="_blank" rel="external">https://www.anaconda.com/download/#windows</a></p>
<p>博主选择Python 3.6 version，windows 64bit</p>
<p>安装完成后需要配置环境变量，根目录和Scripts目录加入到Path下面<br>G:\ProgramData\Anaconda3;G:\ProgramData\Anaconda3\Scripts</p>
<p>1.检测anaconda环境是否安装成功：conda –version<br>2.检测目前安装了哪些环境变量：conda info –envs</p>
<p>3.安装python版本（博主选择3.5）：conda create –name tensorflow python=3.5<br>安装后是3.5.6<br>4.激活tensflow的环境：activate tensorflow<br>5.检测tensflow的环境添加到了Anaconda里面：conda info –envs<br><img src="http://oh6ybr0jg.bkt.clouddn.com/TENSORFLOW_ENV.png" alt="此处输入图片的描述"><br>6.安装tensorflow gru版本<br>pip install –ignore-installed –upgrade tensorflow-gpu</p>
<p>安装其他组件：<br>pip install pandas<br>conda install scikit-learn<br>conda install matplotlib</p>
<p>IDE想要使用tensorflow 需要制定tensorflow的python版本<br><img src="http://oh6ybr0jg.bkt.clouddn.com/QQ%E6%88%AA%E5%9B%BE20180901134100.png" alt="此处输入图片的描述"></p>
]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;基于Anaconda的Tensorflow&quot;&gt;&lt;a href=&quot;#基于Anaconda的Tensorflow&quot; class=&quot;headerlink&quot; title=&quot;基于Anaconda的Tensorflow&quot;&gt;&lt;/a&gt;基于Anaconda的Tensorflow&lt;/
    
    </summary>
    
      <category term="机器学习" scheme="http://yoursite.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="机器学习" scheme="http://yoursite.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>机器学习-随机森林</title>
    <link href="http://yoursite.com/2018/08/16/Mathematical%20%20Random%20Forest/"/>
    <id>http://yoursite.com/2018/08/16/Mathematical  Random Forest/</id>
    <published>2018-08-16T01:30:00.000Z</published>
    <updated>2018-09-01T14:13:49.214Z</updated>
    
    <content type="html"><![CDATA[<p>sklearn.ensemble.RandomForestClassifier</p>
<ul>
<li><strong>n_estimators</strong> : integer, optional (default=10)<br> 森林里（决策）树的数目</li>
<li><strong>criterion</strong> : string, optional (default=”gini”)<br> 衡量分裂质量的性能（函数）。 受支持的标准是基尼不纯度的”gini”,和信息增益的”entropy”（熵）。<br>注意：这个参数是特定树的</li>
<li><p><strong>max_features</strong> : int, float, string or None, optional (default=”auto”)<br> 选择最适属性时划分的特征不能超过此值:</p>
<pre><code>如果是int，就要考虑每一次分割处的max_feature特征
如果是float，那么max_features就是一个百分比，那么（max_feature*n_features）特征整数值是在每个分割处考虑的。
如果是auto，那么max_features=sqrt(n_features)，即n_features的平方根值。
如果是log2，那么max_features=log2(n_features)
如果是None,那么max_features=n_features
</code></pre><p>注意：寻找分割点不会停止，直到找到最少一个有效的节点划分区，即使它需要有效检查超过max_features的特征。</p>
</li>
<li><p><strong>max_depth</strong> : integer or None, optional (default=None)<br>（决策）树的最大深度。如果值为None，那么会扩展节点，直到所有的叶子是纯净的，或者直到所有叶子包含少于min_sample_split的样本。</p>
</li>
<li><p><strong>min_samples_split</strong> : int, float, optional (default=2)<br> 根据属性划分节点时，每个划分最少的样本数。</p>
<pre><code>如果为int，那么考虑min_samples_split作为最小的数字。
如果为float，那么min_samples_split是一个百分比，并且把ceil(min_samples_split*n_samples)是每一个分割最小的样本数量。
</code></pre><p> 在版本0.18中更改：为百分比添加浮点值。<br> 叶子节点最少的样本数。</p>
<pre><code>如果为int，那么考虑min_samples_leaf作为最小的数字。
如果为float，那么min_samples_leaf为一个百分比，并且ceil(min_samples_leaf*n_samples)是每一个节点的最小样本数量。
</code></pre><p> 在版本0.18中更改：为百分比添加浮点值。</p>
</li>
<li><strong>min_weight_fraction_leaf</strong> : float, optional (default=0.)<br> 一个叶子节点所需要的权重总和（所有的输入样本）的最小加权分数。当sample_weight没有提供时，样本具有相同的权重</li>
<li><strong>max_leaf_nodes</strong> : int or None, optional (default=None)<br> 叶子树的最大样本数。<br> 以最优的方法使用max_leaf_nodes来生长树。最好的节点被定义为不纯度上的相对减少。如果为None,那么不限制叶子节点的数量。</li>
<li><strong>min_impurity_split</strong> : float,<br> 树早期生长的阈值。如果一个节点的不纯度超过阈值那么这个节点将会分裂，否则它还是一片叶子。<br> 自0.19版以后不推荐使用：min_impurity_split已被弃用，取而代之的是0.19中的min_impurity_decrease。min_impurity_split将在0.21中被删除。 使用min_impurity_decrease</li>
<li><strong>min_impurity_decrease</strong> : float, optional (default=0.)<br> 如果节点的分裂导致的不纯度的下降程度大于或者等于这个节点的值，那么这个节点将会被分裂。<br> 不纯度加权减少方程式如下：<br> N_t / N <em> (impurity - N_t_R / N_t </em> right_impurity<pre><code>- N_t_L / N_t * left_impurity)
</code></pre> N是样本总的数量，N_t是当前节点处的样本数量，N_t_L是左孩子节点样本的数量,还有N_t_R是右孩子节点的样本数量。<br> N，N_t，N_t_R和N_t_L全部是指加权总和，如果sample_weight通过的话。<br> 0.19版本新加的参数。</li>
<li><strong>bootstrap</strong> : boolean, optional (default=True)<br> 建立决策树时，是否使用有放回抽样。</li>
<li><strong>oob_score</strong> : bool (default=False)<br> 是否使用袋外样本来估计泛化精度。</li>
<li><strong>n_jobs</strong> : integer, optional (default=1)<br> 用于拟合和预测的并行运行的工作（作业）数量。如果值为-1，那么工作数量被设置为核的数量。</li>
<li><strong>random_state</strong> : int, RandomState instance or None, optional (default=None)<br> RandomStateIf int，random_state是随机数生成器使用的种子;<br> 如果是RandomState实例，random_state就是随机数生成器;<br> 如果为None，则随机数生成器是np.random使用的RandomState实例。</li>
<li><strong>verbose</strong> : int, optional (default=0)<br> 控制决策树建立过程的冗余度。</li>
<li><strong>warm_start</strong> : bool, optional (default=False)<br> 当被设置为True时，重新使用之前呼叫的解决方案，用来给全体拟合和添加更多的估计器，反之，仅仅只是为了拟合一个全新的森林。</li>
<li>class_weight : dict, list of dicts, “balanced”,<br> “balanced_subsample” 或者None,（默认值为None）,与格式{class_label: weight}相关联的类的可选的权值。如果没有给值，所有的类到都应该有一个权值。对于多输出问题，一个字典序    列可以按照y的列的顺利被提供。<br> 请注意，对于多输出（包括多标签），其权值应该被定义为它自己字典的每一列的每一个类。例如，对于四类多标签分类，权值应该如[{0: 1, 1: 1}, {0: 1, 1: 5}, {0: 1, 1: 1}, {0: 1, 1: 1}] 这样，而不是[{1:1}, {2:5}, {3:1}, {4:1}].这样。<br> “balanced”模式使用y的值来自动的调整权值，与输入数据中类别频率成反比，如：<pre><code>n_samples / (n_classes * np.bincount(y))
</code></pre> “balanced_subsample”模式和”balanced”相同，除了权值是基于每棵成长树有放回抽样计算的。<br> 对于多输出，y的每列权值将相乘。<br> 请注意，如果指定了sample_weight,这些权值将会和sample_weight相乘（通过拟合方法传递）。</li>
</ul>
<p>Attributes:    属性</p>
<ul>
<li><strong>estimators_</strong> :  决策树分类器的序列<br> 拟合的子估计器的集合。</li>
<li><strong>classes_</strong> :  数组维度=[n_classes]的数组或者一个这样数组的序列。<br> 类别标签（单一输出问题），或者类别标签的数组序列（多输出问题）。</li>
<li><strong>n<em>classes</em></strong> : int or list<br> 类别的数量（单输出问题），或者一个序列，包含每一个输出的类别数量（多输出问题）</li>
<li><strong>n<em>features</em></strong> : int<br> 执行拟合时的特征数量。</li>
<li><strong>n<em>outputs</em></strong> : int<br> 执行拟合时的输出数量。</li>
<li><strong>feature<em>importances</em></strong> : array of shape = [n_features]<br> 特征的重要性（值越高，特征越重要）</li>
<li><strong>oob<em>score</em></strong> : float<br>使用袋外估计获得的训练数据集的得分。</li>
<li><strong>oob_decision<em>function</em></strong> :维度=[n_samples,n_classes]的数组<br> 在训练集上用袋外估计计算的决策函数。如果n_estimators很小的话，那么在有放回抽样中，一个数据点也不会被忽略是可能的。在这种情况下，oob_decision<em>function</em> 可能包括NaN。</li>
</ul>
<p>参数的默认值控制决策树的大小（例如，max_depth，，min_samples_leaf等等），导致完全的生长和在某些数据集上可能非常大的未修剪的树。为了降低内容消耗，决策树的复杂度和大小应该通过设置这些参数值来控制。<br>这些特征总是在每个分割中随机排列。 因此，即使使用相同的训练数据，max_features = n_features和bootstrap = False，如果在搜索最佳分割期间所列举的若干分割的准则的改进是相同的，那么找到的最佳分割点可能会不同。 为了在拟合过程中获得一个确定的行为，random_state将不得不被修正。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;sklearn.ensemble.RandomForestClassifier&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;n_estimators&lt;/strong&gt; : integer, optional (default=10)&lt;br&gt; 森林里（决策）树的数目&lt;/li&gt;

    
    </summary>
    
      <category term="机器学习" scheme="http://yoursite.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="机器学习" scheme="http://yoursite.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>机器学习-梯度下降</title>
    <link href="http://yoursite.com/2018/04/27/Mathematical%20regression%20gradient%20descent/"/>
    <id>http://yoursite.com/2018/04/27/Mathematical regression gradient descent/</id>
    <published>2018-04-27T01:30:00.000Z</published>
    <updated>2018-07-25T16:09:57.310Z</updated>
    
    <content type="html"><![CDATA[<h3 id="梯度下降："><a href="#梯度下降：" class="headerlink" title="梯度下降："></a>梯度下降：</h3><p>批量梯度下降法（Batch Gradient Descent，简称BGD）<br>    优点：全局最优解；易于并行实现；<br>　　缺点：当样本数目很多时，训练过程会很慢。<br>随机梯度下降法（Stochastic Gradient Descent，简称SGD）<br>    优点：训练速度快；迭代次数少<br>    缺点：准确度下降，并不是全局最优；不易于并行实现。<br>小批量梯度下降算法（MBGD）<br>如果损失函数是凸函数，梯度下降法得到的解就一定是全局最优解。</p>
<h4 id="凸凹函数："><a href="#凸凹函数：" class="headerlink" title="凸凹函数："></a>凸凹函数：</h4><p>设f(x)在区间D上连续，如果对D上任意两点a、b恒有<br>f（（a+b）/2）&lt;(f(a)+f(b))/2<br>那么称f(x)在D上的图形是（向上）凹的（或凹弧）；如果恒有<br>f（（a+b）/2）&gt;(f(a)+f(b))/2<br>那么称f(x)在D上的图形是（向上）凸的（或凸弧）</p>
<h3 id="梯度下降相关概念："><a href="#梯度下降相关概念：" class="headerlink" title="梯度下降相关概念："></a>梯度下降相关概念：</h3><ol>
<li>步长（Learning rate）：步长决定了在梯度下降迭代的过程中，每一步沿梯度负方向前进的长度。用上面下山的例子，步长就是在当前这一步所在位置沿着最陡峭最易下山的位置走的那一步的长度。</li>
</ol>
<p>2.特征（feature）：指的是样本中输入部分，比如2个单特征的样本（x(0),y(0)）,（x(1),y(1)）（x(0),y(0)）,（x(1),y(1)）,则第一个样本特征为x(0)x(0)，第一个样本输出为y(0)y(0)。</p>
<ol>
<li><p>假设函数（hypothesis function）：在监督学习中，为了拟合输入样本，而使用的假设函数，记为hθ(x)hθ(x)。比如对于单个特征的m个样本（x(i),y(i)）(i=1,2,…m)（x(i),y(i)）(i=1,2,…m),可以采用拟合函数如下： hθ(x)=θ0+θ1xhθ(x)=θ0+θ1x。</p>
</li>
<li><p>损失函数（loss function）：为了评估模型拟合的好坏，通常用损失函数来度量拟合的程度。损失函数极小化，意味着拟合程度最好，对应的模型参数即为最优参数。在线性回归中，损失函数通常为样本输出和假设函数的差取平方。比如对于m个样本（xi,yi）(i=1,2,…m)（xi,yi）(i=1,2,…m),采用线性回归，损失函数为：</p>
<pre><code>J(θ0,θ1)=∑i=1m(hθ(xi)−yi)2J(θ0,θ1)=∑i=1m(hθ(xi)−yi)2
</code></pre><p>其中xixi表示第i个样本特征，yiyi表示第i个样本对应的输出，hθ(xi)hθ(xi)为假设函数。
　　　　</p>
</li>
</ol>
<h3 id="局部加权回归"><a href="#局部加权回归" class="headerlink" title="局部加权回归"></a>局部加权回归</h3><p>简单来说，这个过程其实是在先拟合出一条曲线，然后再用这个曲线去预测需要预测的点。(源自百度)<br>为什么改进要用加权回归呢？ 很简单，因为非线性拟合出直线误差会很大，这里的局部加权类似于knn算法的权重，即距离中心点越近的权重越大，对拟合曲线的影响也就越大，所以也有了局部加权这一名词</p>
<p>参考文献：<br><a href="https://blog.csdn.net/Gentle_Guan/article/details/76586689?locationNum=8&amp;fps=1" target="_blank" rel="external">https://blog.csdn.net/Gentle_Guan/article/details/76586689?locationNum=8&amp;fps=1</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;梯度下降：&quot;&gt;&lt;a href=&quot;#梯度下降：&quot; class=&quot;headerlink&quot; title=&quot;梯度下降：&quot;&gt;&lt;/a&gt;梯度下降：&lt;/h3&gt;&lt;p&gt;批量梯度下降法（Batch Gradient Descent，简称BGD）&lt;br&gt;    优点：全局最优解；易于并行
    
    </summary>
    
      <category term="机器学习" scheme="http://yoursite.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="机器学习" scheme="http://yoursite.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>机器学习-逻辑回归模型特征处理</title>
    <link href="http://yoursite.com/2018/04/08/Mathematical%20Feature%20processing%20of%20logistic%20regression%20model/"/>
    <id>http://yoursite.com/2018/04/08/Mathematical Feature processing of logistic regression model/</id>
    <published>2018-04-08T01:30:00.000Z</published>
    <updated>2018-07-25T16:10:12.622Z</updated>
    
    <content type="html"><![CDATA[<p>如果有异常值，使用极大-极小归一化或均值-标准差归一化，计算之前需要将极端值排除在外。<br>例如：<br>x’=x−min/ max−min<br>计算max与min时需要用P1与P99来代替。新生成的值如果超过1用1表示，如果小于0 用0表示</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;如果有异常值，使用极大-极小归一化或均值-标准差归一化，计算之前需要将极端值排除在外。&lt;br&gt;例如：&lt;br&gt;x’=x−min/ max−min&lt;br&gt;计算max与min时需要用P1与P99来代替。新生成的值如果超过1用1表示，如果小于0 用0表示&lt;/p&gt;

    
    </summary>
    
      <category term="机器学习" scheme="http://yoursite.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="机器学习" scheme="http://yoursite.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>机器学习-回归算法实例</title>
    <link href="http://yoursite.com/2018/03/27/Mathematical%20regression%20/"/>
    <id>http://yoursite.com/2018/03/27/Mathematical regression /</id>
    <published>2018-03-27T01:30:00.000Z</published>
    <updated>2018-12-21T08:14:28.452Z</updated>
    
    <content type="html"><![CDATA[<h2 id="概念梳理："><a href="#概念梳理：" class="headerlink" title="概念梳理："></a>概念梳理：</h2><p>数学期望：<br>在概率论和统计学中，数学期望(mean)（或均值，亦简称期望）是试验中每次可能结果的概率乘以其结果的总和，是最基本的数学特征之一。它反映随机变量平均取值的大小</p>
<p>方差：<br>（variance)是在概率论和统计方差衡量随机变量或一组数据时离散程度的度量。概率论中方差用来度量随机变量和其数学期望（即均值）之间的偏离程度。统计中的方差（样本方差）是每个样本值与全体样本值的平均数之差的平方值的平均数。在许多实际问题中，研究方差即偏离程度有着重要意义。</p>
<p>概率密度函数：<br>在数学中，连续型随机变量的概率密度函数（在不至于混淆时可以简称为密度函数）是一个描述这个随机变量的输出值，在某个确定的取值点附近的可能性的函数。而随机变量的取值落在某个区域之内的概率则为概率密度函数在这个区域上的积分。当概率密度函数存在的时候，累积分布函数是概率密度函数的积分。概率密度函数一般以小写标记<br>正态分布是重要的概率分布。它的概率密度函数是：<br><img src="http://oh6ybr0jg.bkt.clouddn.com/gailvmidu.jpg" alt="此处输入图片的描述"><br>随着参数μ和σ变化，概率分布也产生变化。<br>期望：μ<br>方差：σ^2<br>中位数：μ<br>众44o6fdeswq    DFGI-数：μ<br>偏度：0<br>峰度：3<br>\]<br><a id="more"></a><br>正态分布：<br>又称为常态分布，高斯分布。<br>若随机变量X服从一个数学期望为μ、方差为σ^2的正态分布，记为N(μ，σ^2)。其概率密度函数为正态分布的期望值μ决定了其位置，其标准差σ决定了分布的幅度。当μ = 0,σ = 1时的正态分布是标准正态分布。</p>
<p>线性回归：<br>线性回归是利用数理统计中回归分析，来确定两种或两种以上变量间相互依赖的定量关系的一种统计分析方法，运用十分广泛。其表达形式为y = w’x+e，e为误差服从均值为0的正态分布。</p>
<p>回归数据：<br><a href="http://archive.ics.uci.edu/ml/datasets/Individual+household+electric+power+consumption" target="_blank" rel="external">http://archive.ics.uci.edu/ml/datasets/Individual+household+electric+power+consumption</a></p>
<p>属性信息：</p>
<p>1.date：格式dd/mm/yyyy日期<br>2.time：格式HH时间：MM：SS<br>3.global_active_power：家用全球分钟平均有功<strong>功率</strong>（千瓦）<br>4.global_reactive_power: 家用全球分钟平均无功<strong>功率</strong>（千瓦）<br>5.voltage：分钟平均<strong>电压</strong>（伏特）<br>6.global_intensity：家用全球分钟平均<strong>电流</strong>强度（安培）<br>7.sub_metering_1：能耗分项计量1号（中有功电能电能）。它与<strong>厨房</strong>相对应，主要包括洗碗机、烤箱和微波炉（热板不是电动的，而是燃气驱动的）。<br>8.sub_metering_2：能耗分项计量2号（中有功电能电能）。它对应<strong>洗衣</strong>房，包括洗衣机、滚筒烘干机、冰箱和灯。<br>9.sub_metering_3：能耗分项计量3号（中有功电能电能）。它相当于一个<strong>电热水器</strong>和一个空调。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</div><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"><span class="keyword">import</span> time</div><div class="line"><span class="keyword">import</span> sklearn</div><div class="line"><span class="keyword">import</span> matplotlib <span class="keyword">as</span> mpl</div><div class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</div><div class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LinearRegression</div><div class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</div><div class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</div><div class="line"></div><div class="line"></div><div class="line">path=<span class="string">'C:/Users/zhanghongming/Documents/data/100.txt'</span></div><div class="line">names = [<span class="string">'Date'</span>,<span class="string">'Time'</span>,<span class="string">'Global_active_power'</span>,<span class="string">'Global_reactive_power'</span>,<span class="string">'Voltage'</span>,<span class="string">'Global_intensity'</span>,<span class="string">'Sub_metering_1'</span>,<span class="string">'Sub_metering_2'</span>,<span class="string">'Sub_metering_3'</span>]</div><div class="line"></div><div class="line"></div><div class="line">df=pd.read_csv(path,sep=<span class="string">';'</span>)</div><div class="line">print(df.head())</div></pre></td></tr></table></figure>
<pre><code>Date      Time  Global_active_power  Global_reactive_power  Voltage  \
</code></pre><p>0  16/12/2006  17:24:00                4.216                  0.418   234.84<br>1  16/12/2006  17:25:00                5.360                  0.436   233.63<br>2  16/12/2006  17:26:00                5.374                  0.498   233.29<br>3  16/12/2006  17:27:00                5.388                  0.502   233.74<br>4  16/12/2006  17:28:00                3.666                  0.528   235.68   </p>
<p>   Global_intensity  Sub_metering_1  Sub_metering_2  Sub_metering_3<br>0              18.4             0.0             1.0            17.0<br>1              23.0             0.0             1.0            16.0<br>2              23.0             0.0             2.0            17.0<br>3              23.0             0.0             1.0            17.0<br>4              15.8             0.0             1.0            17.0  </p>
<h4 id="看所有的变量值"><a href="#看所有的变量值" class="headerlink" title="看所有的变量值"></a>看所有的变量值</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"></div><div class="line"><span class="keyword">for</span> i <span class="keyword">in</span> df.columns:</div><div class="line">    print(df[i].value_counts())</div></pre></td></tr></table></figure>
<p>Name: Date, dtype: int64<br>19:01:00    1<br>17:27:00    1<br>18:24:00    1<br>           ..</p>
<p>Name: Time, Length: 99, dtype: int64<br>4.230    2<br>2.912    2<br>4.218    2<br>6.072    1<br>5.412    1<br>           ..</p>
<p>Name: Global_active_power, Length: 96, dtype: int64<br>0.000    33<br>0.090     7<br>0.054     4<br>0.144     3<br>           ..</p>
<p>Name: Global_reactive_power, dtype: int64<br>235.84    3<br>234.20    2<br>235.68    2<br>233.74    2<br>           ..</p>
<p>Name: Voltage, Length: 90, dtype: int64<br>12.4    7<br>13.8    5<br>15.8    5<br>           ..<br>Name: Global_intensity, dtype: int64<br>0.0    99<br>Name: Sub_metering_1, dtype: int64<br>1.0     50<br>0.0     26<br>2.0      8</p>
<p>Name: Sub_metering_2, dtype: int64<br>17.0    77<br>16.0    18<br>18.0     4</p>
<p>Name: Sub_metering_3, dtype: int64</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#空值处理</span></div><div class="line">new_df= df.replace(<span class="string">'?'</span>,np.nan)</div><div class="line"></div><div class="line">datas = new_df.dropna(how=<span class="string">'any'</span>)</div><div class="line"></div><div class="line"><span class="comment">#定义时间格式化</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">datae_format</span><span class="params">(dt)</span>:</span></div><div class="line">    t = time.strptime(<span class="string">' '</span>.join(dt),<span class="string">'%d/%m/%Y %H:%M:%S'</span>)</div><div class="line">    <span class="keyword">return</span> (t.tm_year,t.tm_mon,t.tm_mday,t.tm_hour,t.tm_min,t.tm_sec)</div><div class="line"></div><div class="line"><span class="comment">##分析功率和时间的线性关系。将时间转换为连续的</span></div><div class="line"></div><div class="line">X = datas[names[<span class="number">0</span>:<span class="number">2</span>]]</div><div class="line">X = X.apply(<span class="keyword">lambda</span> x :pd.Series(datae_format(x)),axis=<span class="number">1</span>)</div><div class="line">Y = datas[names[<span class="number">2</span>]]</div><div class="line"></div><div class="line"></div><div class="line">print(X.head(<span class="number">5</span>))</div><div class="line">print(Y.head(<span class="number">5</span>))</div></pre></td></tr></table></figure>
<pre><code>0   1   2   3   4  5
</code></pre><p>0  2006  12  16  17  24  0<br>1  2006  12  16  17  25  0<br>2  2006  12  16  17  26  0<br>3  2006  12  16  17  27  0<br>4  2006  12  16  17  28  0<br>0    4.216<br>1    5.360<br>2    5.374<br>3    5.388<br>4    3.666<br>Name: Global_active_power, dtype: float64</p>
<h6 id="函数讲解"><a href="#函数讲解" class="headerlink" title="函数讲解"></a>函数讲解</h6><p>sklearn.model_selection.train_test_split随机划分训练集和测试集<br>一般形式：<br>train_test_split是交叉验证中常用的函数，功能是从样本中随机的按比例选取train data和testdata，形式为：<br>X_train,X_test, y_train, y_test =<br>cross_validation.train_test_split(train_data,train_target,test_size=0.4, random_state=0)<br>参数解释：<br>train_data：所要划分的样本特征集<br>train_target：所要划分的样本结果<br>test_size：样本占比，如果是整数的话就是样本的数量<br>random_state：是随机数的种子。<br>随机数种子：其实就是该组随机数的编号，在需要重复试验的时候，保证得到一组一样的随机数。比如你每次都填1，其他参数一样的情况下你得到的随机数组是一样的。但填0或不填，每次都会不一样。<br>随机数的产生取决于种子，随机数和种子之间的关系遵从以下两个规则：<br>种子不同，产生不同的随机数；种子相同，即使实例不同也产生相同的随机数。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line">X_train,X_test,Y_train,Y_test = train_test_split( X, Y, test_size=<span class="number">0.2</span>, random_state=<span class="number">42</span>)</div><div class="line"></div><div class="line"></div><div class="line"><span class="comment">## 数据标准换行</span></div><div class="line">ss = StandardScaler()</div><div class="line">X_train = ss.fit_transform(X_train)</div><div class="line">X_test = ss.fit_transform(X_test)</div><div class="line"></div><div class="line"></div><div class="line"><span class="comment">##训练数据</span></div><div class="line">lr = LinearRegression()</div><div class="line">lr.fit(X_train,Y_train)</div><div class="line"></div><div class="line"><span class="comment">##预测Y值</span></div><div class="line">y_predict = lr.predict(X_test)</div><div class="line"></div><div class="line">print(<span class="string">"准确率:"</span>,lr.score(X_test,Y_test))</div></pre></td></tr></table></figure>
<p>样本数据100条：<br>准确率: 0.0226499044921<br>样本数据1000条：<br>0.103073016594</p>
<p>模型保存及加载：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> sklearn.externals <span class="keyword">import</span> joblib</div><div class="line"><span class="comment">## 模型保存：</span></div><div class="line">joblib.dump(ss,<span class="string">"data_ss.model"</span>)</div><div class="line">joblib.dump(lr,<span class="string">"data_lr.model"</span>)</div><div class="line"></div><div class="line"><span class="comment">## 加载模型</span></div><div class="line">joblib,load(<span class="string">"data_ss.model"</span>)</div><div class="line">joblib,load(<span class="string">"data_lr.model"</span>)</div></pre></td></tr></table></figure></p>
<p>plot文档：<br><a href="https://matplotlib.org/api/pyplot_api.html#matplotlib.pyplot.plot" target="_blank" rel="external">https://matplotlib.org/api/pyplot_api.html#matplotlib.pyplot.plot</a></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line"><span class="comment">## 解决中文问题</span></div><div class="line">mpl.rcParams[<span class="string">'font.sans-serif'</span>] = [<span class="string">u'SimHei'</span>];</div><div class="line">mpl.rcParams[<span class="string">'axes.unicode_minus'</span>] = <span class="keyword">False</span></div><div class="line"></div><div class="line">t=np.arange(len(X_test))</div><div class="line">plt.figure(facecolor=<span class="string">'w'</span>)</div><div class="line">plt.plot(t,Y_test,<span class="string">'r--'</span>,linewidth=<span class="number">2</span>,label=<span class="string">u'真实值'</span>)</div><div class="line">plt.plot(t,y_predict,<span class="string">'g--'</span>,linewidth=<span class="number">2</span>,label=<span class="string">u'预测值'</span>)</div><div class="line">plt.legend(loc =<span class="string">'lower right'</span>)</div><div class="line">plt.title(<span class="string">u'线性回归时间与电压的关系'</span>,fontsize=<span class="number">20</span> )</div><div class="line">plt.grid(b=<span class="keyword">True</span>)</div><div class="line">plt.show()</div></pre></td></tr></table></figure>
<p>100条数据：<br><img src="http://oh6ybr0jg.bkt.clouddn.com/linear_regression_100.png" alt="此处输入图片的描述"></p>
<p>1000条数据：<br><img src="http://oh6ybr0jg.bkt.clouddn.com/linear_regression_1000.png" alt="此处输入图片的描述"></p>
<h3 id="linear多项式"><a href="#linear多项式" class="headerlink" title="linear多项式"></a>linear多项式</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> sklearn.pipeline <span class="keyword">import</span> Pipeline</div><div class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> PolynomialFeatures</div><div class="line"><span class="keyword">from</span> sklearn.grid_search <span class="keyword">import</span> GridSearchCV</div><div class="line">models = [Pipeline([(<span class="string">'Poly'</span>,PolynomialFeatures()),(<span class="string">'Linear'</span>,LinearRegression())])]</div><div class="line">model = models[<span class="number">0</span>]</div><div class="line"></div><div class="line"></div><div class="line"><span class="comment">##获取X，Y变量，并将时间变量转换为数值型连续的</span></div><div class="line">X = datas[names[<span class="number">0</span>:<span class="number">2</span>]]</div><div class="line">X = X.apply(<span class="keyword">lambda</span> x :pd.Series(datae_format(x)),axis=<span class="number">1</span>)</div><div class="line">Y = datas[names[<span class="number">4</span>]]</div><div class="line"></div><div class="line"><span class="comment">## 对数据集进行划分</span></div><div class="line">X_train,X_test,Y_train,Y_test = train_test_split( X, Y, test_size=<span class="number">0.2</span>, random_state=<span class="number">0</span>)</div><div class="line"></div><div class="line"><span class="comment">## 数据标准化</span></div><div class="line">ss = StandardScaler()</div><div class="line">X_train = ss.fit_transform(X_train)</div><div class="line">X_test = ss.fit_transform(X_test)</div><div class="line"></div><div class="line"><span class="comment">## 模型训练</span></div><div class="line">t=np.arange(len(X_test))</div><div class="line">N =<span class="number">5</span></div><div class="line">d_pool= np.arange(<span class="number">1</span>,N,<span class="number">1</span>)</div><div class="line">m=d_pool.size</div><div class="line">clrs = []  <span class="comment"># 颜色</span></div><div class="line"><span class="keyword">for</span> c <span class="keyword">in</span> np.linspace(<span class="number">16711680</span>, <span class="number">255</span>, m,dtype=<span class="string">'int64'</span>):</div><div class="line">    clrs.append(<span class="string">'#%06x'</span> % c)</div><div class="line">line_width = <span class="number">3</span></div><div class="line"></div><div class="line">plt.figure(figsize=(<span class="number">12</span>,<span class="number">6</span>),facecolor=<span class="string">'w'</span>)</div><div class="line"><span class="keyword">for</span> i,d <span class="keyword">in</span> enumerate(d_pool):</div><div class="line">    plt.subplot(N<span class="number">-1</span>,<span class="number">1</span>,i+<span class="number">1</span>)</div><div class="line">    plt.plot(t,Y_test,<span class="string">'r--'</span>,label=<span class="string">u'真实值'</span>,ms=<span class="number">10</span>,zorder=N)</div><div class="line">    model.set_params(Poly__degree=d) <span class="comment"># 设置多项式的阶</span></div><div class="line">    model.fit(X_train,Y_train)</div><div class="line">    lin = model.get_params(<span class="string">'Linear'</span>)[<span class="string">'Linear'</span>]</div><div class="line">    output =<span class="string">u'%d阶，系数为：'</span>%d</div><div class="line">    print( output,lin.coef_.ravel())</div><div class="line"></div><div class="line">    y_hat = model.predict(X_test)</div><div class="line">    s = model.score(X_test,Y_test)</div><div class="line"></div><div class="line">    z=N<span class="number">-1</span> <span class="keyword">if</span> (d==<span class="number">2</span>) <span class="keyword">else</span> <span class="number">0</span></div><div class="line">    label=<span class="string">u'%d阶,准确率=%.3f'</span>%(d,s)</div><div class="line"></div><div class="line"></div><div class="line">    plt.plot(t,y_hat,color=clrs[i],lw=line_width,alpha = <span class="number">0.75</span>,label=label,zorder=z)</div><div class="line">    plt.legend(loc = <span class="string">'upper left'</span>)</div><div class="line">    plt.grid(<span class="keyword">True</span>)</div><div class="line">    plt.ylabel(<span class="string">u'%d阶结果'</span>%d,fontsize=<span class="number">12</span>)</div><div class="line"></div><div class="line"><span class="comment"># 预测值和真实值画图比较</span></div><div class="line">plt.legend(loc = <span class="string">'lower right'</span>)</div><div class="line">plt.suptitle(<span class="string">u'线性回归时间与电压之间多项式关系'</span>)</div><div class="line">plt.grid(b=<span class="keyword">True</span>)</div><div class="line">plt.show()</div></pre></td></tr></table></figure>
<p>1阶，系数为： [  0.00000000e+00   5.55111512e-17   0.00000000e+00   0.00000000e+00<br>  -4.22939297e-01  -4.34494704e-01   0.00000000e+00]<br>2阶，系数为： [  2.47983335e-17   1.11022302e-16  -2.22044605e-16  -1.11022302e-16<br>  -5.05820937e-01  -3.46571423e-01   0.00000000e+00   0.00000000e+00<br>   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00<br>   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00<br>   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00<br>   0.00000000e+00   0.00000000e+00  -8.58357173e-01  -7.57689882e-01<br>   0.00000000e+00  -1.60364055e-01   0.00000000e+00   0.00000000e+00]<br>3阶，系数为： [ -1.69309011e-15  -2.99760217e-15   3.33066907e-16   5.55111512e-16<br>  -4.41970713e-02  -3.57278153e-01   0.00000000e+00   2.22044605e-16<br>   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00<br>   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00<br>   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00<br>   0.00000000e+00   0.00000000e+00   3.43644538e-01   4.86208530e-01<br>   0.00000000e+00   3.26242425e-02   0.00000000e+00   0.00000000e+00<br>   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00<br>   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00<br>   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00<br>   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00<br>   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00<br>   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00<br>   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00<br>   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00<br>   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00<br>   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00<br>   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00<br>   0.00000000e+00   0.00000000e+00   4.48140740e-01   6.37890832e-01<br>   0.00000000e+00  -7.45035081e-01   0.00000000e+00   0.00000000e+00<br>  -5.02511111e-01   0.00000000e+00   0.00000000e+00   0.00000000e+00]<br>4阶，系数为： [  2.22002972e-013  -8.01497757e-013   5.37209166e-014  -4.53519167e-013<br>   7.19933381e-003   2.05441337e-001   3.86510268e-013  -5.94066463e-013<br>   6.66133815e-015   6.66133815e-016  -1.88737914e-015   6.27276009e-015<br>  -5.30131494e-015  -1.01585407e-014   3.35287353e-014   8.21565038e-015<br>  -2.55351296e-015  -2.22044605e-016  -6.31088724e-030   3.02922588e-028<br>   1.00974196e-028  -5.04870979e-029  -4.89052469e-002   3.28220946e-001<br>   0.00000000e+000   6.15440583e-003   0.00000000e+000   0.00000000e+000<br>   1.26217745e-029   0.00000000e+000  -5.60519386e-044  -8.40779079e-045<br>  -7.00649232e-045  -2.24207754e-044  -5.60519386e-045   2.80259693e-045<br>   1.40129846e-045   0.00000000e+000   0.00000000e+000   4.97841222e-060<br>   1.55575382e-061  -1.24460306e-060  -2.48920611e-060   0.00000000e+000<br>  -3.11150764e-061  -1.16681536e-061  -3.11150764e-061  -4.66726146e-061<br>   2.21085915e-075  -5.52714788e-076  -1.38178697e-076   2.76357394e-076<br>  -1.38178697e-076  -3.45446742e-077   0.00000000e+000   1.34940134e-079<br>   0.00000000e+000   1.91761463e-093   1.49813643e-095  -5.99254573e-095<br>   4.49440930e-095   1.12360233e-095   0.00000000e+000   7.49068217e-096<br>  -2.34083818e-097   0.00000000e+000   0.00000000e+000   0.00000000e+000<br>   0.00000000e+000   0.00000000e+000  -1.66326556e-111   4.15816391e-112<br>  -2.07908195e-112   0.00000000e+000  -6.13741990e-002  -8.70197287e-001<br>   8.39734513e-140  -1.48604949e+000   0.00000000e+000   0.00000000e+000<br>  -4.67097255e-001   0.00000000e+000   0.00000000e+000   0.00000000e+000<br>   0.00000000e+000   0.00000000e+000   0.00000000e+000   0.00000000e+000<br>   0.00000000e+000   0.00000000e+000   0.00000000e+000   0.00000000e+000<br>   0.00000000e+000   0.00000000e+000   0.00000000e+000   0.00000000e+000<br>   0.00000000e+000   0.00000000e+000   0.00000000e+000   0.00000000e+000<br>   0.00000000e+000   0.00000000e+000   0.00000000e+000   0.00000000e+000<br>   0.00000000e+000   0.00000000e+000   0.00000000e+000   0.00000000e+000<br>   0.00000000e+000   0.00000000e+000   0.00000000e+000   0.00000000e+000<br>   0.00000000e+000   0.00000000e+000   0.00000000e+000   0.00000000e+000<br>   0.00000000e+000   0.00000000e+000   0.00000000e+000   0.00000000e+000<br>   0.00000000e+000   0.00000000e+000   0.00000000e+000   0.00000000e+000<br>   0.00000000e+000   0.00000000e+000   0.00000000e+000   0.00000000e+000<br>   0.00000000e+000   0.00000000e+000   0.00000000e+000   0.00000000e+000<br>   0.00000000e+000   0.00000000e+000   0.00000000e+000   0.00000000e+000<br>   0.00000000e+000   0.00000000e+000   0.00000000e+000   0.00000000e+000<br>   0.00000000e+000   0.00000000e+000   0.00000000e+000   0.00000000e+000<br>   0.00000000e+000   0.00000000e+000   0.00000000e+000   0.00000000e+000<br>   0.00000000e+000   0.00000000e+000   0.00000000e+000   0.00000000e+000<br>   0.00000000e+000   0.00000000e+000   0.00000000e+000   0.00000000e+000<br>   0.00000000e+000   0.00000000e+000   0.00000000e+000   0.00000000e+000<br>   0.00000000e+000   0.00000000e+000   0.00000000e+000   0.00000000e+000<br>   0.00000000e+000   0.00000000e+000   0.00000000e+000   0.00000000e+000<br>   0.00000000e+000   0.00000000e+000   0.00000000e+000   0.00000000e+000<br>   0.00000000e+000   0.00000000e+000   0.00000000e+000   0.00000000e+000<br>   0.00000000e+000   0.00000000e+000   0.00000000e+000   0.00000000e+000<br>   0.00000000e+000   0.00000000e+000   0.00000000e+000   0.00000000e+000<br>   0.00000000e+000   0.00000000e+000   0.00000000e+000   0.00000000e+000<br>   0.00000000e+000   0.00000000e+000   0.00000000e+000   0.00000000e+000<br>   0.00000000e+000   0.00000000e+000   0.00000000e+000  -2.42848401e-001<br>  -9.28403263e-001   0.00000000e+000  -8.91115491e-001   0.00000000e+000<br>   0.00000000e+000   1.33924630e-001   0.00000000e+000   0.00000000e+000<br>   0.00000000e+000   2.81909059e-001   0.00000000e+000   0.00000000e+000<br>   0.00000000e+000   0.00000000e+000]</p>
<p>   <img src="http://oh6ybr0jg.bkt.clouddn.com/linear_regression_polynomial.png" alt="此处输入图片的描述"></p>
]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;概念梳理：&quot;&gt;&lt;a href=&quot;#概念梳理：&quot; class=&quot;headerlink&quot; title=&quot;概念梳理：&quot;&gt;&lt;/a&gt;概念梳理：&lt;/h2&gt;&lt;p&gt;数学期望：&lt;br&gt;在概率论和统计学中，数学期望(mean)（或均值，亦简称期望）是试验中每次可能结果的概率乘以其结果的总和，是最基本的数学特征之一。它反映随机变量平均取值的大小&lt;/p&gt;
&lt;p&gt;方差：&lt;br&gt;（variance)是在概率论和统计方差衡量随机变量或一组数据时离散程度的度量。概率论中方差用来度量随机变量和其数学期望（即均值）之间的偏离程度。统计中的方差（样本方差）是每个样本值与全体样本值的平均数之差的平方值的平均数。在许多实际问题中，研究方差即偏离程度有着重要意义。&lt;/p&gt;
&lt;p&gt;概率密度函数：&lt;br&gt;在数学中，连续型随机变量的概率密度函数（在不至于混淆时可以简称为密度函数）是一个描述这个随机变量的输出值，在某个确定的取值点附近的可能性的函数。而随机变量的取值落在某个区域之内的概率则为概率密度函数在这个区域上的积分。当概率密度函数存在的时候，累积分布函数是概率密度函数的积分。概率密度函数一般以小写标记&lt;br&gt;正态分布是重要的概率分布。它的概率密度函数是：&lt;br&gt;&lt;img src=&quot;http://oh6ybr0jg.bkt.clouddn.com/gailvmidu.jpg&quot; alt=&quot;此处输入图片的描述&quot;&gt;&lt;br&gt;随着参数μ和σ变化，概率分布也产生变化。&lt;br&gt;期望：μ&lt;br&gt;方差：σ^2&lt;br&gt;中位数：μ&lt;br&gt;众44o6fdeswq    DFGI-数：μ&lt;br&gt;偏度：0&lt;br&gt;峰度：3&lt;br&gt;\]&lt;br&gt;
    
    </summary>
    
      <category term="机器学习" scheme="http://yoursite.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="机器学习" scheme="http://yoursite.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>scikit-learn pca</title>
    <link href="http://yoursite.com/2018/03/03/scikit-learn%20pca/"/>
    <id>http://yoursite.com/2018/03/03/scikit-learn pca/</id>
    <published>2018-03-03T03:06:30.000Z</published>
    <updated>2018-12-21T08:14:17.397Z</updated>
    
    <content type="html"><![CDATA[<p>from sklearn import datasets</p>
<p>digits = datasets.load_digits()<br>x = digits.data<br>y = digits.target</p>
<p>from sklearn.model_selection import  train_test_split<br>x_train,x_test,y_train,y_test = train_test_split(x,y,random_state=666)</p>
<p>print(x_train.shape)</p>
<p>#(1347, 64)<br>from sklearn.neighbors import KNeighborsClassifier<br>import time<br>start = time.clock()<br>knn_clf = KNeighborsClassifier()</p>
<p>knn_clf.fit(x_train,y_train)<br>end = time.clock()</p>
<p>print(end-start)</p>
<p>#0.009107513739889835<br>score = knn_clf.score(x_test,y_test)</p>
<p>print(score)</p>
<p>#0.986666666667</p>
<p>from sklearn.decomposition import  PCA</p>
<p>pca = PCA(n_components=2)<br>pca.fit(x_train)<br>X_train_reduction = pca.transform(x_train)<br>X_test_reduction = pca.transform(x_test)</p>
<p>start2 = time.clock()<br>knn_clf = KNeighborsClassifier()<br>knn_clf.fit(X_train_reduction,y_train)<br>end2 = time.clock()</p>
<p>print(end2-start2)</p>
<p>#0.0019209365663966915<br>score = knn_clf.score(X_test_reduction,y_test)<br>print(score)</p>
<p>#0.606666666667</p>
<p>print(pca.explained<em>variance</em>)</p>
<p>pca = PCA(n_components=x_train.shape[1])</p>
<p>pca3 = PCA(0.95)<br>pca3.fit(x_train)<br>print(pca3.n<em>components</em>)</p>
<p>#28</p>
<p>start3 = time.clock()<br>knn_clf3 = KNeighborsClassifier()<br>X_train_reduction = pca3.transform(x_train)<br>X_test_reduction = pca3.transform(x_test)<br>knn_clf3.fit(X_train_reduction,y_train)<br>end3 = time.clock()</p>
<p>print(end3-start3)</p>
<p>#0.006395458395239972<br>score = knn_clf3.score(X_test_reduction,y_test)<br>print(score)</p>
<p>#0.98</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;from sklearn import datasets&lt;/p&gt;
&lt;p&gt;digits = datasets.load_digits()&lt;br&gt;x = digits.data&lt;br&gt;y = digits.target&lt;/p&gt;
&lt;p&gt;from sklearn.model_sel
    
    </summary>
    
    
      <category term="机器学习" scheme="http://yoursite.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>scikit-learn KNN</title>
    <link href="http://yoursite.com/2018/03/02/scikit-learn%20KNN/"/>
    <id>http://yoursite.com/2018/03/02/scikit-learn KNN/</id>
    <published>2018-03-02T02:06:30.000Z</published>
    <updated>2018-12-21T08:14:37.220Z</updated>
    
    <content type="html"><![CDATA[<p>地址：<br><a href="http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#sklearn.neighbors.KNeighborsClassifier" target="_blank" rel="external">http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#sklearn.neighbors.KNeighborsClassifier</a></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> KNeighborsClassifier</div><div class="line"></div><div class="line">X = [[<span class="number">0</span>], [<span class="number">1</span>], [<span class="number">2</span>], [<span class="number">3</span>]]</div><div class="line">y = [<span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">1</span>]</div><div class="line">neigh = KNeighborsClassifier(n_neighbors=<span class="number">3</span>)</div><div class="line">neigh.fit(X, y)</div><div class="line"></div><div class="line">print(neigh.predict([[<span class="number">1.1</span>]]))</div><div class="line"><span class="comment"># [0]</span></div><div class="line">print(neigh.predict_proba([[<span class="number">0.9</span>]]))</div><div class="line"><span class="comment">#[[ 0.66666667  0.33333333]]</span></div></pre></td></tr></table></figure>
<a id="more"></a>
<p>手写数字练习：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets</div><div class="line"></div><div class="line">digits = datasets.load_digits()</div><div class="line">x= digits.data</div><div class="line">y= digits.target</div><div class="line">print(x.shape)</div><div class="line"><span class="comment">#(1797, 64)</span></div><div class="line"></div><div class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span>  train_test_split</div><div class="line">x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=<span class="number">0.2</span>,random_state=<span class="number">666</span>)</div><div class="line"></div><div class="line"></div><div class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> KNeighborsClassifier</div><div class="line"></div><div class="line">knn_clf = KNeighborsClassifier(n_neighbors=<span class="number">3</span>)</div><div class="line">knn_clf.fit(x_train,y_train)</div><div class="line">score= knn_clf.score(x_test,y_test)</div><div class="line">print(score)</div><div class="line"><span class="comment">#0.988888888889</span></div></pre></td></tr></table></figure>
<p>查找最佳超参数<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line">beat_score=<span class="number">0</span></div><div class="line">break_k =<span class="number">-1</span></div><div class="line"><span class="keyword">for</span> k <span class="keyword">in</span> range(<span class="number">1</span>,<span class="number">11</span>):</div><div class="line">    knn_clf2 = KNeighborsClassifier(n_neighbors=k)</div><div class="line">    knn_clf2.fit(x_train,y_train)</div><div class="line">    score= knn_clf2.score(x_test,y_test)</div><div class="line">    <span class="keyword">if</span>(score &gt;beat_score):</div><div class="line">        break_k =k</div><div class="line">        beat_score = score</div><div class="line"></div><div class="line">print(<span class="string">"beat_score"</span>,beat_score)</div><div class="line">print(<span class="string">"break_k"</span>,break_k)</div></pre></td></tr></table></figure></p>
<p>beat_score 0.991666666667<br>break_k 4</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line">beat_score=<span class="number">0</span></div><div class="line">break_k =<span class="number">-1</span></div><div class="line">beat_method=<span class="string">''</span></div><div class="line"><span class="keyword">for</span> method <span class="keyword">in</span> [<span class="string">'uniform'</span>,<span class="string">'distance'</span>]:</div><div class="line">    <span class="keyword">for</span> k <span class="keyword">in</span> range(<span class="number">1</span>,<span class="number">11</span>):</div><div class="line">        knn_clf2 = KNeighborsClassifier(n_neighbors=k,weights=method)</div><div class="line">        knn_clf2.fit(x_train,y_train)</div><div class="line">        score= knn_clf2.score(x_test,y_test)</div><div class="line">        <span class="keyword">if</span>(score &gt;beat_score):</div><div class="line">            beat_method = method</div><div class="line">            break_k =k</div><div class="line">            beat_score = score</div><div class="line"></div><div class="line">print(<span class="string">"beat_score"</span>,beat_score)</div><div class="line">print(<span class="string">"break_k"</span>,break_k)</div></pre></td></tr></table></figure>
<p>网格搜素：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> time</div><div class="line">start = time.clock()</div><div class="line">param_grid=[</div><div class="line">    &#123;</div><div class="line">        <span class="string">'weights'</span>:[<span class="string">'uniform'</span>],</div><div class="line">        <span class="string">'n_neighbors'</span>:[i  <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>,<span class="number">11</span>)]</div><div class="line">    &#125;,</div><div class="line">    &#123;</div><div class="line">        <span class="string">'weights'</span>:[<span class="string">'distance'</span>],</div><div class="line">        <span class="string">'n_neighbors'</span>:[i  <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>,<span class="number">11</span>)],</div><div class="line">        <span class="string">'p'</span>:[i  <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>,<span class="number">6</span>)]</div><div class="line">    &#125;</div><div class="line">]</div><div class="line"></div><div class="line">knn_clf = KNeighborsClassifier()</div><div class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span>  GridSearchCV</div><div class="line">grid_search = GridSearchCV(knn_clf,param_grid)</div><div class="line">grid_search.fit(x_train,y_train)</div><div class="line">print(<span class="string">"grid_search.best_estimator_:"</span>,grid_search.best_estimator_)</div><div class="line">print(<span class="string">"grid_search.best_score_:"</span>,grid_search.best_score_)</div><div class="line">print(<span class="string">"grid_search.best_params_:"</span>,grid_search.best_params_)</div><div class="line"></div><div class="line">knn_clf = grid_search.best_estimator_</div><div class="line">knn_clf_score = knn_clf.score(x_test,y_test)</div><div class="line">print(knn_clf_score)</div><div class="line">end = time.clock()</div><div class="line">print(end-start)</div></pre></td></tr></table></figure></p>
<p>grid_search.best<em>estimator</em>: KNeighborsClassifier(algorithm=’auto’, leaf_size=30, metric=’minkowski’,<br>           metric_params=None, n_jobs=1, n_neighbors=3, p=3,<br>           weights=’distance’)<br>grid_search.best<em>score</em>: 0.985386221294<br>grid_search.best<em>params</em>: {‘n_neighbors’: 3, ‘p’: 3, ‘weights’: ‘distance’}<br>0.983333333333<br>296.18877317471</p>
<p>增加并行化处理：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">grid_search = GridSearchCV(knn_clf,param_grid,n_jobs=<span class="number">2</span>,verbose=<span class="number">2</span>)</div></pre></td></tr></table></figure></p>
<p>速度变为：156.67693082041933</p>
<p>最值归一化：<br>适用于分布有明显边界的情况，受outlier影响较大<br>均值方差归一化：<br>适用于分布没有明显边界的情况，有可能存在极端数值</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;地址：&lt;br&gt;&lt;a href=&quot;http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#sklearn.neighbors.KNeighborsClassifier&quot;&gt;http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#sklearn.neighbors.KNeighborsClassifier&lt;/a&gt;&lt;/p&gt;
&lt;figure class=&quot;highlight python&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;2&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;3&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;4&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;5&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;6&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;7&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;8&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;9&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;10&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;11&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;from&lt;/span&gt; sklearn.neighbors &lt;span class=&quot;keyword&quot;&gt;import&lt;/span&gt; KNeighborsClassifier&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;X = [[&lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;], [&lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;], [&lt;span class=&quot;number&quot;&gt;2&lt;/span&gt;], [&lt;span class=&quot;number&quot;&gt;3&lt;/span&gt;]]&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;y = [&lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;, &lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;, &lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;, &lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;]&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;neigh = KNeighborsClassifier(n_neighbors=&lt;span class=&quot;number&quot;&gt;3&lt;/span&gt;)&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;neigh.fit(X, y)&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;print(neigh.predict([[&lt;span class=&quot;number&quot;&gt;1.1&lt;/span&gt;]]))&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# [0]&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;print(neigh.predict_proba([[&lt;span class=&quot;number&quot;&gt;0.9&lt;/span&gt;]]))&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;#[[ 0.66666667  0.33333333]]&lt;/span&gt;&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
    
    </summary>
    
    
      <category term="机器学习" scheme="http://yoursite.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>scikit-learn regression</title>
    <link href="http://yoursite.com/2018/03/01/scikit-learn%20regression/"/>
    <id>http://yoursite.com/2018/03/01/scikit-learn regression/</id>
    <published>2018-03-01T03:06:30.000Z</published>
    <updated>2018-12-21T08:14:24.851Z</updated>
    
    <content type="html"><![CDATA[<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets</div><div class="line"></div><div class="line">boston = datasets.load_boston()</div><div class="line">x= boston.data</div><div class="line">y= boston.targe</div><div class="line"></div><div class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span>  train_test_split</div><div class="line">x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=<span class="number">0.2</span>,random_state=<span class="number">666</span>)</div><div class="line"></div><div class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> linear_model</div><div class="line">clf = linear_model.LinearRegression()</div><div class="line"></div><div class="line">clf.fit(x_train,y_train)</div><div class="line">y_predict = clf.predict(x_test)</div><div class="line"></div><div class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> mean_squared_error</div><div class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> mean_absolute_error</div><div class="line"></div><div class="line">MSE = mean_squared_error(y_test,y_predict)</div><div class="line">print(MSE)</div><div class="line">MAE = mean_absolute_error(y_test,y_predict)</div><div class="line">print(MAE)</div></pre></td></tr></table></figure>
]]></content>
    
    <summary type="html">
    
      &lt;figure class=&quot;highlight python&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;2&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;3&lt;/d
    
    </summary>
    
    
      <category term="机器学习" scheme="http://yoursite.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>机器学习-决策树算法实例</title>
    <link href="http://yoursite.com/2018/02/18/Mathematical%20decision%20tree/"/>
    <id>http://yoursite.com/2018/02/18/Mathematical decision tree/</id>
    <published>2018-02-18T01:30:00.000Z</published>
    <updated>2018-07-25T16:10:05.738Z</updated>
    
    <content type="html"><![CDATA[<h2 id="决策树："><a href="#决策树：" class="headerlink" title="决策树："></a>决策树：</h2><p>有监督学习方法<br>是一种预测模型<br>是在已知各种情况发生概率基础上，通过构建决策树来进行分析的一种方法</p>
<h3 id="树形结构"><a href="#树形结构" class="headerlink" title="树形结构"></a>树形结构</h3><p>从跟节点开始，预测待分类项对应的特征属性，按照值选择输出分支，直到叶子节点，将叶子节点的存放类别作为树的结果</p>
<p>决策树分为两类：<br>分类，回归<br>前者用于分类标签值，后者用于预测连续值<br>常用算法ID3，C4,5，CART</p>
<h3 id="数据标准化："><a href="#数据标准化：" class="headerlink" title="数据标准化："></a>数据标准化：</h3><p>StandardScaler (基于特征矩阵的列，将属性值转换至服从正态分布)<br>标准化是依照特征矩阵的列处理数据，其通过求z-score的方法，将样本的特征值转换到同一量纲下<br>常用与基于正态分布的算法，比如回归<br>数据归一化<br>MinMaxScaler （区间缩放，基于最大最小值，将数据转换到0,1区间上的）<br>提升模型收敛速度，提升模型精度<br>常见用于神经网络<br>Normalizer （基于矩阵的行，将样本向量转换为单位向量）<br>其目的在于样本向量在点乘运算或其他核函数计算相似性时，拥有统一的标准<br>常见用于文本分类和聚类、logistic回归中也会使用，有效防止过拟合</p>
<h3 id="特征选择："><a href="#特征选择：" class="headerlink" title="特征选择："></a>特征选择：</h3><p>从已有的特征中选择出影响目标值最大的特征属性</p>
<h2 id="常用方法：-分类：F统计量、卡方系数，互信息mutual-info-classif"><a href="#常用方法：-分类：F统计量、卡方系数，互信息mutual-info-classif" class="headerlink" title="常用方法：{ 分类：F统计量、卡方系数，互信息mutual_info_classif"></a>常用方法：{ 分类：F统计量、卡方系数，互信息mutual_info_classif</h2><pre><code>{ 连续：皮尔逊相关系数 F统计量 互信息mutual_info_classif
</code></pre><h2 id="SelectKBest（卡方系数）"><a href="#SelectKBest（卡方系数）" class="headerlink" title="SelectKBest（卡方系数）"></a>SelectKBest（卡方系数）</h2>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;决策树：&quot;&gt;&lt;a href=&quot;#决策树：&quot; class=&quot;headerlink&quot; title=&quot;决策树：&quot;&gt;&lt;/a&gt;决策树：&lt;/h2&gt;&lt;p&gt;有监督学习方法&lt;br&gt;是一种预测模型&lt;br&gt;是在已知各种情况发生概率基础上，通过构建决策树来进行分析的一种方法&lt;/p&gt;
&lt;h
    
    </summary>
    
      <category term="机器学习" scheme="http://yoursite.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="机器学习" scheme="http://yoursite.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>设计模式-结构模式</title>
    <link href="http://yoursite.com/2018/02/11/Design%20pattern%20structural/"/>
    <id>http://yoursite.com/2018/02/11/Design pattern structural/</id>
    <published>2018-02-11T01:30:00.000Z</published>
    <updated>2018-07-25T16:17:19.158Z</updated>
    
    <content type="html"><![CDATA[<h3 id="1-适配器"><a href="#1-适配器" class="headerlink" title="1.适配器"></a>1.适配器</h3><p>效果及优缺点：<br>对于类适配器：</p>
<ol>
<li>用一个具体的Adapter类对Adaptee和Taget进行匹配。结果是当我们想要匹配一个类以及所有它的子类时，类Adapter将不能胜任工作。</li>
<li>使得Adapter可以override（重定义） Adaptee的部分行为，因为Adapter是Adaptee的一个子类。<br>对于对象适配器：</li>
<li>允许一个Adapter与多个Adaptee，即Adaptee本身以及它的所有子类（如果有子类的话）同时工作。Adapter也可以一次给所有的Adaptee添加功能。</li>
<li>使得override（重定义）Adaptee的行为比较困难。如果一定要override Adaptee的方法，就只好先做一个Adaptee的子类以override Adaptee的方法，然后再把这个子类当作真正的Adaptee源进行适配。</li>
</ol>
<h3 id="2-桥接"><a href="#2-桥接" class="headerlink" title="2.桥接"></a>2.桥接</h3><p>继承是一种强耦合的结果，父类变，子类就必须要变。可以使用组合/继承来解耦合。将抽象和他的实现分离<br><img src="https://images.cnblogs.com/cnblogs_com/houleixx/Snap1.jpg" alt="此处输入图片的描述"></p>
<h3 id="3-组合"><a href="#3-组合" class="headerlink" title="3.组合"></a>3.组合</h3><p>将对象组合成属性结构以表示‘部分-整体’的层次结构。组合模式使得用户对单个对象和组合对象的使用具有一致性。</p>
<p>组合模式描述了如何使用递归的组合，使客户不用区分这些类</p>
<h3 id="4-装配器"><a href="#4-装配器" class="headerlink" title="4.装配器"></a>4.装配器</h3><h3 id="5-外观"><a href="#5-外观" class="headerlink" title="5.外观"></a>5.外观</h3><h3 id="6-享元模式"><a href="#6-享元模式" class="headerlink" title="6.享元模式"></a>6.享元模式</h3><h3 id="7-代理模式"><a href="#7-代理模式" class="headerlink" title="7.代理模式"></a>7.代理模式</h3><p>Copy-on-writedai代理：即写即复制“快照”虚拟代理的一种，把复制拖延到只有客户端需要时，才真正执行<br>保护代理：允许在访问对象时附加管理任务</p>
<p>1.什么是代理模式：例如我们找房子找中介<br>2.为什么要使用代理：我们不需要自己找房子</p>
]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;1-适配器&quot;&gt;&lt;a href=&quot;#1-适配器&quot; class=&quot;headerlink&quot; title=&quot;1.适配器&quot;&gt;&lt;/a&gt;1.适配器&lt;/h3&gt;&lt;p&gt;效果及优缺点：&lt;br&gt;对于类适配器：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;用一个具体的Adapter类对Adaptee和Tag
    
    </summary>
    
      <category term="设计模式" scheme="http://yoursite.com/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"/>
    
    
      <category term="设计模式" scheme="http://yoursite.com/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"/>
    
  </entry>
  
  <entry>
    <title>设计模式-行为模式</title>
    <link href="http://yoursite.com/2018/02/10/Design%20pattern%20behavior/"/>
    <id>http://yoursite.com/2018/02/10/Design pattern behavior/</id>
    <published>2018-02-10T01:30:00.000Z</published>
    <updated>2018-03-30T15:45:16.730Z</updated>
    
    <content type="html"><![CDATA[<h3 id="责任链模式"><a href="#责任链模式" class="headerlink" title="责任链模式"></a>责任链模式</h3><h4 id="命令模式"><a href="#命令模式" class="headerlink" title="命令模式"></a>命令模式</h4><p>命令Command<br>    ——声明执行操作的接口。<br>具体命令ConcreteCommand<br>    ——定义接收对象和动作之间的绑定关系。<br>    ——通过引起接收者的相应动作来实现执行。<br>客户Client<br>    ——产生一个ConcreteCommand对象，并设置接收者。<br>引发者Invoker<br>    ——要求命令执行请求。<br>接收者Receiver<br>    ——知道如何执行与请求相联系的操作。</p>
<a id="more"></a>
<h3 id="迭代器模式"><a href="#迭代器模式" class="headerlink" title="迭代器模式"></a>迭代器模式</h3><h3 id="模板方法模式"><a href="#模板方法模式" class="headerlink" title="模板方法模式"></a>模板方法模式</h3><p>准备一个抽象类，定义一个算法的大体框架<br>将部分逻辑以具体方法以及具体构造子的形式实现<br>剩余的逻辑通过声明一些抽象方法来描述<br>这些抽象方法要求子类实现，<br>不同的子类可以以不同的方式实现这些抽象方法，从而对剩余的逻辑有不同的实现。<br>子类不改变算法的结构而重定义算法</p>
<h3 id="观察者模式"><a href="#观察者模式" class="headerlink" title="观察者模式"></a>观察者模式</h3><p>同一应用对象不同展示形式，如一组数据映射为表格和柱状图。用户更改表格数据，柱状图要同步修改</p>
<p>关键对象：<br>抽象主题Subject<br>提供一个连接观察者对象和解除连接的接口。<br>知道它的观察者。可有任意数目的观察者对象观察一个主题。<br>可以增加和删除观察者对象，<br>具体主题ConcreteSubject：<br>通常用一个具体子类实现。<br>负责实现对观察者引用的聚集的管理力注。<br>将有关状态存入ConcreteObserver对象。<br>在具体主题内部状态改变时向它的观察者发送通知。</p>
<p>抽象观察者Observer ：<br>一般用一个抽象类或者一个接口实现，<br>为所有的具体观察者定义一个更新接口<br>更新接口包含的方法叫更新方法。<br>具体观察者ConcreteObserver<br>通常用一个具体子类实现，<br>保存一个指向ConcreteSubject对象的引用。<br>存储要与主题一致的状态。<br>实现抽象观察者角色所要求的更新接口，以便使本身的状态与主题的状态相协调。</p>
<h3 id="状态模式"><a href="#状态模式" class="headerlink" title="状态模式"></a>状态模式</h3><h3 id="策略模式"><a href="#策略模式" class="headerlink" title="策略模式"></a>策略模式</h3><h3 id="访问者模式"><a href="#访问者模式" class="headerlink" title="访问者模式"></a>访问者模式</h3><h3 id="解释器模式"><a href="#解释器模式" class="headerlink" title="解释器模式"></a>解释器模式</h3>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;责任链模式&quot;&gt;&lt;a href=&quot;#责任链模式&quot; class=&quot;headerlink&quot; title=&quot;责任链模式&quot;&gt;&lt;/a&gt;责任链模式&lt;/h3&gt;&lt;h4 id=&quot;命令模式&quot;&gt;&lt;a href=&quot;#命令模式&quot; class=&quot;headerlink&quot; title=&quot;命令模式&quot;&gt;&lt;/a&gt;命令模式&lt;/h4&gt;&lt;p&gt;命令Command&lt;br&gt;    ——声明执行操作的接口。&lt;br&gt;具体命令ConcreteCommand&lt;br&gt;    ——定义接收对象和动作之间的绑定关系。&lt;br&gt;    ——通过引起接收者的相应动作来实现执行。&lt;br&gt;客户Client&lt;br&gt;    ——产生一个ConcreteCommand对象，并设置接收者。&lt;br&gt;引发者Invoker&lt;br&gt;    ——要求命令执行请求。&lt;br&gt;接收者Receiver&lt;br&gt;    ——知道如何执行与请求相联系的操作。&lt;/p&gt;
    
    </summary>
    
      <category term="设计模式" scheme="http://yoursite.com/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"/>
    
    
      <category term="设计模式" scheme="http://yoursite.com/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"/>
    
  </entry>
  
  <entry>
    <title>2018学习计划</title>
    <link href="http://yoursite.com/2018/02/07/2018%E5%AD%A6%E4%B9%A0%E8%AE%A1%E5%88%92/"/>
    <id>http://yoursite.com/2018/02/07/2018学习计划/</id>
    <published>2018-02-07T00:00:00.000Z</published>
    <updated>2018-12-21T08:12:32.620Z</updated>
    
    <content type="html"><![CDATA[<h2 id="大数据及机器学习学习计划"><a href="#大数据及机器学习学习计划" class="headerlink" title="大数据及机器学习学习计划"></a>大数据及机器学习学习计划</h2><ol>
<li><p>编程基础：Python<br><a href="https://cn.udacity.com/course/programming-foundations-with-python--ud036" target="_blank" rel="external">https://cn.udacity.com/course/programming-foundations-with-python--ud036</a></p>
</li>
<li><p>计算机科学导论  72小时<br><a href="https://cn.udacity.com/course/intro-to-computer-science--cs101" target="_blank" rel="external">https://cn.udacity.com/course/intro-to-computer-science--cs101</a></p>
</li>
<li>推论统计学  48小时<br><a href="https://cn.udacity.com/course/intro-to-inferential-statistics--ud201" target="_blank" rel="external">https://cn.udacity.com/course/intro-to-inferential-statistics--ud201</a></li>
<li>描述统计学  48小时<br><a href="https://cn.udacity.com/course/intro-to-inferential-statistics--ud201" target="_blank" rel="external">https://cn.udacity.com/course/intro-to-inferential-statistics--ud201</a></li>
<li>机器学习  240小时<br><a href="https://cn.udacity.com/course/machine-learning--ud262" target="_blank" rel="external">https://cn.udacity.com/course/machine-learning--ud262</a></li>
<li>统计学入门<br><a href="https://cn.udacity.com/course/intro-to-statistics--st101" target="_blank" rel="external">https://cn.udacity.com/course/intro-to-statistics--st101</a></li>
<li>基础线性代数<br><a href="https://cn.udacity.com/course/linear-algebra-refresher-course--ud953" target="_blank" rel="external">https://cn.udacity.com/course/linear-algebra-refresher-course--ud953</a></li>
<li><p>机器学习<br><a href="https://cn.udacity.com/course/machine-learning-engineer-nanodegree--nd009" target="_blank" rel="external">https://cn.udacity.com/course/machine-learning-engineer-nanodegree--nd009</a></p>
</li>
<li><p>Apache Storm 进行实时分析  48小时<br><a href="https://cn.udacity.com/course/real-time-analytics-with-apache-storm--ud381" target="_blank" rel="external">https://cn.udacity.com/course/real-time-analytics-with-apache-storm--ud381</a></p>
</li>
<li><p>Bash脚本  40+小时</p>
</li>
</ol>
]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;大数据及机器学习学习计划&quot;&gt;&lt;a href=&quot;#大数据及机器学习学习计划&quot; class=&quot;headerlink&quot; title=&quot;大数据及机器学习学习计划&quot;&gt;&lt;/a&gt;大数据及机器学习学习计划&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;&lt;p&gt;编程基础：Python&lt;br&gt;&lt;a hre
    
    </summary>
    
      <category term="学习计划" scheme="http://yoursite.com/categories/%E5%AD%A6%E4%B9%A0%E8%AE%A1%E5%88%92/"/>
    
    
      <category term="学习" scheme="http://yoursite.com/tags/%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>机器学习-支持向量机</title>
    <link href="http://yoursite.com/2018/02/05/Mathematical%20Support%20Vector%20Machine/"/>
    <id>http://yoursite.com/2018/02/05/Mathematical Support Vector Machine/</id>
    <published>2018-02-05T01:30:00.000Z</published>
    <updated>2018-12-21T08:13:30.038Z</updated>
    
    <content type="html"><![CDATA[<h3 id="支持向量机（Support-Vector-Machine，SVM）的基本概念："><a href="#支持向量机（Support-Vector-Machine，SVM）的基本概念：" class="headerlink" title="支持向量机（Support Vector Machine，SVM）的基本概念："></a>支持向量机（Support Vector Machine，SVM）的基本概念：</h3><h5 id="点到超平面的距离"><a href="#点到超平面的距离" class="headerlink" title="点到超平面的距离"></a>点到超平面的距离</h5><p>在分类任务中，为了获取稳健的线性分类器，一个很自然的想法是，找出一条分割线使得两侧样本与该分割线的平均距离足够的远。在欧式空间中，定义一个点𝒙到直线（或者高维空间中的超平面）𝒘^𝑇 𝒙+𝑏=0的距离公式是：<br>            𝑟(𝑥)=  (|𝒘^𝑇 𝒙+𝑏|)/(||𝒘||)<br>在分类问题中，如果这样的分割线或者分割平面能够准确地将样本分开，对于样本{𝒙<em>𝑖,𝑦</em>𝑖}∈𝐷, 𝑦<em>𝑖=±1 而言，若𝑦</em>𝑖=1，则有𝒘^𝑇 𝒙<em>𝒊+𝑏≥1，反之若𝑦</em>𝑖=-1，则有𝒘^𝑇 𝒙_𝒊+𝑏≤−1.</p>
]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;支持向量机（Support-Vector-Machine，SVM）的基本概念：&quot;&gt;&lt;a href=&quot;#支持向量机（Support-Vector-Machine，SVM）的基本概念：&quot; class=&quot;headerlink&quot; title=&quot;支持向量机（Support 
    
    </summary>
    
      <category term="机器学习" scheme="http://yoursite.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="机器学习" scheme="http://yoursite.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>设计模式-工厂模式</title>
    <link href="http://yoursite.com/2018/01/27/Design%20pattern%20factory/"/>
    <id>http://yoursite.com/2018/01/27/Design pattern factory/</id>
    <published>2018-01-27T01:30:00.000Z</published>
    <updated>2018-02-08T16:00:47.673Z</updated>
    
    <content type="html"><![CDATA[<p>创建几个套皮肤，所有的UI控件 如按钮，滚动条，窗口 都要创建出来。现在需要红色主题，黑色主题，和蓝色主题3套皮肤。</p>
<p>接口类：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">Button</span> </span>&#123;</div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">display</span><span class="params">()</span></span>;</div><div class="line">&#125;</div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">ScrollBar</span> </span>&#123;</div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">display</span><span class="params">()</span></span>;</div><div class="line">&#125;</div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">Window</span> </span>&#123;</div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">display</span><span class="params">()</span></span>;</div><div class="line">&#125;</div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">SkinFactory</span> </span>&#123;</div><div class="line">    <span class="function"><span class="keyword">public</span> ScrollBar <span class="title">createScrollBar</span><span class="params">()</span></span>;</div><div class="line">    <span class="function"><span class="keyword">public</span> Button <span class="title">createButton</span><span class="params">()</span></span>;</div><div class="line">    <span class="function"><span class="keyword">public</span> Window <span class="title">createWindow</span><span class="params">()</span></span>;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<a id="more"></a>
<p>红色皮肤工厂<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">RedSkinFactory</span> <span class="keyword">implements</span> <span class="title">SkinFactory</span> </span>&#123;</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">public</span> ScrollBar <span class="title">createScrollBar</span><span class="params">()</span> </span>&#123;</div><div class="line">        <span class="keyword">return</span> <span class="keyword">new</span> RedScrollBar();</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">public</span> Button <span class="title">createButton</span><span class="params">()</span> </span>&#123;</div><div class="line">        <span class="keyword">return</span> <span class="keyword">new</span> RedButton();</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">public</span> Window <span class="title">createWindow</span><span class="params">()</span> </span>&#123;</div><div class="line">        <span class="keyword">return</span> <span class="keyword">new</span> RedWindow();</div><div class="line">    &#125;</div><div class="line">&#125;</div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">RedScrollBar</span> <span class="keyword">implements</span> <span class="title">ScrollBar</span> </span>&#123;</div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">display</span><span class="params">()</span> </span>&#123;</div><div class="line">        System.out.println(<span class="string">"创建红色滚动条。"</span>);</div><div class="line">    &#125;</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">RedButton</span> <span class="keyword">implements</span> <span class="title">Button</span> </span>&#123;</div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">display</span><span class="params">()</span> </span>&#123;</div><div class="line">        System.out.println(<span class="string">"创建红色按钮"</span>);</div><div class="line">    &#125;</div><div class="line">&#125;</div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">RedWindow</span> <span class="keyword">implements</span> <span class="title">Window</span> </span>&#123;</div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">display</span><span class="params">()</span> </span>&#123;</div><div class="line">        System.out.println(<span class="string">"创建红色窗口。"</span>);</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>实现类<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">SkinClient</span> </span>&#123;</div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</div><div class="line">        SkinFactory BlackSkinFactory = <span class="keyword">new</span> BlackSkinFactory();</div><div class="line">        BlackSkinFactory.createButton().display();</div><div class="line">        BlackSkinFactory.createScrollBar().display();</div><div class="line">        BlackSkinFactory.createWindow().display();</div><div class="line"></div><div class="line">        SkinFactory RedSkinFactory = <span class="keyword">new</span> RedSkinFactory();</div><div class="line">        RedSkinFactory.createButton().display();</div><div class="line">        RedSkinFactory.createScrollBar().display();</div><div class="line">        RedSkinFactory.createWindow().display();</div><div class="line"></div><div class="line">        SkinFactory BlueSkinFactory = <span class="keyword">new</span> BlueSkinFactory();</div><div class="line">        BlueSkinFactory.createButton().display();</div><div class="line">        BlueSkinFactory.createScrollBar().display();</div><div class="line">        BlueSkinFactory.createWindow().display();</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>sh输出结果<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">创建黑色按钮</div><div class="line">创建黑色滚动条。</div><div class="line">创建黑色窗口。</div><div class="line">创建红色按钮</div><div class="line">创建红色滚动条。</div><div class="line">创建红色窗口。</div><div class="line">创建蓝色按钮</div><div class="line">创建蓝色滚动条。</div><div class="line">创建蓝色窗口。</div></pre></td></tr></table></figure></p>
<p>其他颜色同上<br>代码结构截图：<br><img src="http://oh6ybr0jg.bkt.clouddn.com/daimajiegoutu-gongchang.png" alt="此处输入图片的描述"><br>结果截图：<br><img src="http://oh6ybr0jg.bkt.clouddn.com/jieguojietu-gongchang1.png" alt="此处输入图片的描述"></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;创建几个套皮肤，所有的UI控件 如按钮，滚动条，窗口 都要创建出来。现在需要红色主题，黑色主题，和蓝色主题3套皮肤。&lt;/p&gt;
&lt;p&gt;接口类：&lt;br&gt;&lt;figure class=&quot;highlight java&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;2&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;3&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;4&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;5&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;6&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;7&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;8&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;9&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;10&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;11&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;12&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;13&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;14&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;class&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;interface&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;Button&lt;/span&gt; &lt;/span&gt;&amp;#123;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    &lt;span class=&quot;function&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;display&lt;/span&gt;&lt;span class=&quot;params&quot;&gt;()&lt;/span&gt;&lt;/span&gt;;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&amp;#125;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;class&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;interface&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;ScrollBar&lt;/span&gt; &lt;/span&gt;&amp;#123;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    &lt;span class=&quot;function&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;display&lt;/span&gt;&lt;span class=&quot;params&quot;&gt;()&lt;/span&gt;&lt;/span&gt;;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&amp;#125;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;class&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;interface&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;Window&lt;/span&gt; &lt;/span&gt;&amp;#123;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    &lt;span class=&quot;function&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;display&lt;/span&gt;&lt;span class=&quot;params&quot;&gt;()&lt;/span&gt;&lt;/span&gt;;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&amp;#125;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;class&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;interface&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;SkinFactory&lt;/span&gt; &lt;/span&gt;&amp;#123;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    &lt;span class=&quot;function&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;public&lt;/span&gt; ScrollBar &lt;span class=&quot;title&quot;&gt;createScrollBar&lt;/span&gt;&lt;span class=&quot;params&quot;&gt;()&lt;/span&gt;&lt;/span&gt;;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    &lt;span class=&quot;function&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;public&lt;/span&gt; Button &lt;span class=&quot;title&quot;&gt;createButton&lt;/span&gt;&lt;span class=&quot;params&quot;&gt;()&lt;/span&gt;&lt;/span&gt;;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    &lt;span class=&quot;function&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;public&lt;/span&gt; Window &lt;span class=&quot;title&quot;&gt;createWindow&lt;/span&gt;&lt;span class=&quot;params&quot;&gt;()&lt;/span&gt;&lt;/span&gt;;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&amp;#125;&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="设计模式" scheme="http://yoursite.com/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"/>
    
    
      <category term="设计模式" scheme="http://yoursite.com/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"/>
    
  </entry>
  
  <entry>
    <title>设计模式目录</title>
    <link href="http://yoursite.com/2018/01/27/Design%20pattern%20catalog/"/>
    <id>http://yoursite.com/2018/01/27/Design pattern catalog/</id>
    <published>2018-01-27T01:30:00.000Z</published>
    <updated>2018-02-06T14:27:35.863Z</updated>
    
    <content type="html"><![CDATA[<h3 id="创建性模式："><a href="#创建性模式：" class="headerlink" title="创建性模式："></a>创建性模式：</h3><p>1.类的创建模式——使用继承关系，把类的创建延迟到子类<br>2.对象的创建模式——把对象的创建过程动态地委派给另一个对象<br>    封装要创建的具体类（类的实例）的信息<br>    隐藏这些类（类的实例）被创建和组合的过程</p>
<p>包含<br>抽象工厂、建造者、工厂方式、原型、单例</p>
<h3 id="结构性模式："><a href="#结构性模式：" class="headerlink" title="结构性模式："></a>结构性模式：</h3><p>考虑如何组合类和对象构成较大的结构。<br>1.结构性类模式：使用继承来组合接口或实现<br>2.结构性对象模式：对象合成实现新功能。<br><a id="more"></a><br>包含：<br>适配器、桥接、组合、装饰着、外观、轻量、代理</p>
<h3 id="行为模式："><a href="#行为模式：" class="headerlink" title="行为模式："></a>行为模式：</h3><p>主要解决算法和对象之间的责任分配问题。<br>对象或类的模式<br>它们之间的通信模式。<br>包含：<br>责任链、命令、解释器、迭代、中介者、备忘录、观察者、状态、策略、模板方法、观察者</p>
<p>工厂方法主要针对一个产品等级结构<br>抽象工厂模式需要面对多个产品等级结构</p>
]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;创建性模式：&quot;&gt;&lt;a href=&quot;#创建性模式：&quot; class=&quot;headerlink&quot; title=&quot;创建性模式：&quot;&gt;&lt;/a&gt;创建性模式：&lt;/h3&gt;&lt;p&gt;1.类的创建模式——使用继承关系，把类的创建延迟到子类&lt;br&gt;2.对象的创建模式——把对象的创建过程动态地委派给另一个对象&lt;br&gt;    封装要创建的具体类（类的实例）的信息&lt;br&gt;    隐藏这些类（类的实例）被创建和组合的过程&lt;/p&gt;
&lt;p&gt;包含&lt;br&gt;抽象工厂、建造者、工厂方式、原型、单例&lt;/p&gt;
&lt;h3 id=&quot;结构性模式：&quot;&gt;&lt;a href=&quot;#结构性模式：&quot; class=&quot;headerlink&quot; title=&quot;结构性模式：&quot;&gt;&lt;/a&gt;结构性模式：&lt;/h3&gt;&lt;p&gt;考虑如何组合类和对象构成较大的结构。&lt;br&gt;1.结构性类模式：使用继承来组合接口或实现&lt;br&gt;2.结构性对象模式：对象合成实现新功能。&lt;br&gt;
    
    </summary>
    
      <category term="设计模式" scheme="http://yoursite.com/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"/>
    
    
      <category term="设计模式" scheme="http://yoursite.com/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"/>
    
  </entry>
  
  <entry>
    <title>kNN实现手写数字识别</title>
    <link href="http://yoursite.com/2018/01/25/kNN%E5%AE%9E%E7%8E%B0%E6%89%8B%E5%86%99%E6%95%B0%E5%AD%97%E8%AF%86%E5%88%AB/"/>
    <id>http://yoursite.com/2018/01/25/kNN实现手写数字识别/</id>
    <published>2018-01-25T10:42:30.000Z</published>
    <updated>2018-12-21T08:21:57.435Z</updated>
    
    <content type="html"><![CDATA[<p>需求<br>利用一个手写数字“先验数据”集，使用knn算法来实现对手写数字的自动识别；<br>先验数据（训练数据）集：<br>    数据维度比较大，样本数比较多。<br>    数据集包括数字0-9的手写体。<br>    每个数字大约有200个样本。<br>    每个样本保持在一个txt文件中。<br>    手写体图像本身的大小是32x32的二值图，转换到txt文件保存后，内容也是32x32个数字，0或者1，如下：<br><a id="more"></a><br><img src="http://oh6ybr0jg.bkt.clouddn.com/%E6%95%B0%E5%AD%97012.png" alt="此处输入图片的描述"></p>
<p>首先准备测试文件:<br>1934个训练数据<br>946个测试数据</p>
<p>分析：<br>1、手写体因为每个人，甚至每次写的字都不会完全精确一致，所以，识别手写体的关键是“相似度”<br>2、既然是要求样本之间的相似度，那么，首先需要将样本进行抽象，将每个样本变成一系列特征数据（即特征向量）<br>3、手写体在直观上就是一个个的图片，而图片是由上述图示中的像素点来描述的，样本的相似度其实就是像素的位置和颜色之间的组合的相似度<br>4、因此，将图片的像素按照固定顺序读取到一个个的向量中，即可很好地表示手写体样本<br>5、抽象出了样本向量，及相似度计算模型，即可应用KNN来实现</p>
<p>代码：<br>1)    一个用来生成将每个样本的txt文件转换为对应的一个向量，<br>2)    一个用来加载整个数据集，<br>3)    一个实现kNN分类算法。<br>4)    最后就是实现加载、测试的函数。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div><div class="line">118</div><div class="line">119</div><div class="line">120</div><div class="line">121</div><div class="line">122</div><div class="line">123</div><div class="line">124</div><div class="line">125</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#########################################</span></div><div class="line"><span class="comment"># kNN: k Nearest Neighbors</span></div><div class="line"></div><div class="line"><span class="comment"># 参数:        inX: vector to compare to existing dataset (1xN)</span></div><div class="line"><span class="comment">#             dataSet: size m data set of known vectors (NxM)</span></div><div class="line"><span class="comment">#             labels: data set labels (1xM vector)</span></div><div class="line"><span class="comment">#             k: number of neighbors to use for comparison </span></div><div class="line">            </div><div class="line"><span class="comment"># 输出:     多数类</span></div><div class="line"><span class="comment">#########################################</span></div><div class="line"></div><div class="line"><span class="keyword">from</span> numpy <span class="keyword">import</span> *</div><div class="line"><span class="keyword">import</span> operator</div><div class="line"><span class="keyword">import</span> os</div><div class="line"></div><div class="line"></div><div class="line"><span class="comment"># KNN分类核心方法</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">kNNClassify</span><span class="params">(newInput, dataSet, labels, k)</span>:</span></div><div class="line">	numSamples = dataSet.shape[<span class="number">0</span>]  <span class="comment"># shape[0]代表行数</span></div><div class="line"></div><div class="line">	<span class="comment">## step 1: 计算欧式距离</span></div><div class="line">	<span class="comment"># tile(A, reps): 将A重复reps次来构造一个矩阵</span></div><div class="line">	<span class="comment"># the following copy numSamples rows for dataSet</span></div><div class="line">	diff = tile(newInput, (numSamples, <span class="number">1</span>)) - dataSet  <span class="comment"># Subtract element-wise</span></div><div class="line">	squaredDiff = diff ** <span class="number">2</span> <span class="comment"># squared for the subtract</span></div><div class="line">	squaredDist = sum(squaredDiff, axis = <span class="number">1</span>)  <span class="comment"># sum is performed by row</span></div><div class="line">	distance = squaredDist ** <span class="number">0.5</span></div><div class="line"></div><div class="line">	<span class="comment">## step 2: 对距离排序</span></div><div class="line">	<span class="comment"># argsort()返回排序后的索引</span></div><div class="line">	sortedDistIndices = argsort(distance)</div><div class="line"></div><div class="line">	classCount = &#123;&#125;  <span class="comment"># 定义一个空的字典</span></div><div class="line">	<span class="keyword">for</span> i <span class="keyword">in</span> xrange(k):</div><div class="line">		<span class="comment">## step 3: 选择k个最小距离</span></div><div class="line">		voteLabel = labels[sortedDistIndices[i]]</div><div class="line"></div><div class="line">		<span class="comment">## step 4: 计算类别的出现次数</span></div><div class="line">		<span class="comment"># when the key voteLabel is not in dictionary classCount, get()</span></div><div class="line">		<span class="comment"># will return 0</span></div><div class="line">		classCount[voteLabel] = classCount.get(voteLabel, <span class="number">0</span>) + <span class="number">1</span></div><div class="line"></div><div class="line">	<span class="comment">## step 5: 返回出现次数最多的类别作为分类结果</span></div><div class="line">	maxCount = <span class="number">0</span></div><div class="line">	<span class="keyword">for</span> key, value <span class="keyword">in</span> classCount.items():</div><div class="line">		<span class="keyword">if</span> value &gt; maxCount:</div><div class="line">			maxCount = value</div><div class="line">			maxIndex = key</div><div class="line"></div><div class="line">	<span class="keyword">return</span> maxIndex	</div><div class="line"></div><div class="line"><span class="comment"># 将图片转换为向量</span></div><div class="line"><span class="function"><span class="keyword">def</span>  <span class="title">img2vector</span><span class="params">(filename)</span>:</span></div><div class="line"> 	rows = <span class="number">32</span></div><div class="line"> 	cols = <span class="number">32</span></div><div class="line"> 	imgVector = zeros((<span class="number">1</span>, rows * cols)) </div><div class="line"> 	fileIn = open(filename)</div><div class="line"> 	<span class="keyword">for</span> row <span class="keyword">in</span> xrange(rows):</div><div class="line"> 		lineStr = fileIn.readline()</div><div class="line"> 		<span class="keyword">for</span> col <span class="keyword">in</span> xrange(cols):</div><div class="line"> 			imgVector[<span class="number">0</span>, row * <span class="number">32</span> + col] = int(lineStr[col])</div><div class="line"></div><div class="line"> 	<span class="keyword">return</span> imgVector</div><div class="line"></div><div class="line"><span class="comment"># 加载数据集</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">loadDataSet</span><span class="params">()</span>:</span></div><div class="line">	<span class="comment">## step 1: 读取训练数据集</span></div><div class="line">	<span class="keyword">print</span> <span class="string">"---Getting training set..."</span></div><div class="line">	dataSetDir = <span class="string">'E:/Python/ml/knn/'</span></div><div class="line">	trainingFileList = os.listdir(dataSetDir + <span class="string">'trainingDigits'</span>)  <span class="comment"># 加载测试数据</span></div><div class="line">	numSamples = len(trainingFileList)</div><div class="line"></div><div class="line">	train_x = zeros((numSamples, <span class="number">1024</span>))</div><div class="line">	train_y = []</div><div class="line">	<span class="keyword">for</span> i <span class="keyword">in</span> xrange(numSamples):</div><div class="line">		filename = trainingFileList[i]</div><div class="line"></div><div class="line">		<span class="comment"># get train_x</span></div><div class="line">		train_x[i, :] = img2vector(dataSetDir + <span class="string">'trainingDigits/%s'</span> % filename) </div><div class="line"></div><div class="line">		<span class="comment"># get label from file name such as "1_18.txt"</span></div><div class="line">		label = int(filename.split(<span class="string">'_'</span>)[<span class="number">0</span>]) <span class="comment"># return 1</span></div><div class="line">		train_y.append(label)</div><div class="line"></div><div class="line">	<span class="comment">## step 2:读取测试数据集</span></div><div class="line">	<span class="keyword">print</span> <span class="string">"---Getting testing set..."</span></div><div class="line">	testingFileList = os.listdir(dataSetDir + <span class="string">'testDigits'</span>) <span class="comment"># load the testing set</span></div><div class="line">	numSamples = len(testingFileList)</div><div class="line">	test_x = zeros((numSamples, <span class="number">1024</span>))</div><div class="line">	test_y = []</div><div class="line">	<span class="keyword">for</span> i <span class="keyword">in</span> xrange(numSamples):</div><div class="line">		filename = testingFileList[i]</div><div class="line"></div><div class="line">		<span class="comment"># get train_x</span></div><div class="line">		test_x[i, :] = img2vector(dataSetDir + <span class="string">'testDigits/%s'</span> % filename) </div><div class="line"></div><div class="line">		<span class="comment"># get label from file name such as "1_18.txt"</span></div><div class="line">		label = int(filename.split(<span class="string">'_'</span>)[<span class="number">0</span>]) <span class="comment"># return 1</span></div><div class="line">		test_y.append(label)</div><div class="line"></div><div class="line">	<span class="keyword">return</span> train_x, train_y, test_x, test_y</div><div class="line"></div><div class="line"><span class="comment"># 手写识别主流程</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">testHandWritingClass</span><span class="params">()</span>:</span></div><div class="line">	<span class="comment">## step 1: 加载数据</span></div><div class="line">	<span class="keyword">print</span> <span class="string">"step 1: load data..."</span></div><div class="line">	train_x, train_y, test_x, test_y = loadDataSet()</div><div class="line"></div><div class="line">	<span class="comment">## step 2: 模型训练.</span></div><div class="line">	<span class="keyword">print</span> <span class="string">"step 2: training..."</span></div><div class="line">	<span class="keyword">pass</span></div><div class="line"></div><div class="line">	<span class="comment">## step 3: 测试</span></div><div class="line">	<span class="keyword">print</span> <span class="string">"step 3: testing..."</span></div><div class="line">	numTestSamples = test_x.shape[<span class="number">0</span>]</div><div class="line">	matchCount = <span class="number">0</span></div><div class="line">	<span class="keyword">for</span> i <span class="keyword">in</span> xrange(numTestSamples):</div><div class="line">		predict = kNNClassify(test_x[i], train_x, train_y, <span class="number">3</span>)</div><div class="line">		<span class="keyword">if</span> predict == test_y[i]:</div><div class="line">			matchCount += <span class="number">1</span></div><div class="line">	accuracy = float(matchCount) / numTestSamples</div><div class="line"></div><div class="line">	<span class="comment">## step 4: 输出结果</span></div><div class="line">	<span class="keyword">print</span> <span class="string">"step 4: show the result..."</span></div><div class="line">	<span class="keyword">print</span> <span class="string">'The classify accuracy is: %.2f%%'</span> % (accuracy * <span class="number">100</span>)</div></pre></td></tr></table></figure>
<p>测试<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> kNN</div><div class="line">kNN.testHandWritingClass()</div></pre></td></tr></table></figure></p>
<p>执行结果：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">tep <span class="number">1</span>: load data...</div><div class="line">---Getting training set...</div><div class="line">---Getting testing set...</div><div class="line">step <span class="number">2</span>: training...</div><div class="line">step <span class="number">3</span>: testing...</div><div class="line">step <span class="number">4</span>: show the result...</div><div class="line">The classify accuracy <span class="keyword">is</span>: <span class="number">98.84</span>%</div></pre></td></tr></table></figure></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;需求&lt;br&gt;利用一个手写数字“先验数据”集，使用knn算法来实现对手写数字的自动识别；&lt;br&gt;先验数据（训练数据）集：&lt;br&gt;    数据维度比较大，样本数比较多。&lt;br&gt;    数据集包括数字0-9的手写体。&lt;br&gt;    每个数字大约有200个样本。&lt;br&gt;    每个样本保持在一个txt文件中。&lt;br&gt;    手写体图像本身的大小是32x32的二值图，转换到txt文件保存后，内容也是32x32个数字，0或者1，如下：&lt;br&gt;
    
    </summary>
    
      <category term="python" scheme="http://yoursite.com/categories/python/"/>
    
    
      <category term="机器学习" scheme="http://yoursite.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
</feed>
