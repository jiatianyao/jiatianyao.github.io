<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>张洪铭的个人博客</title>
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2018-09-01T14:15:55.889Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>张洪铭</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>机器学习-神经网络</title>
    <link href="http://yoursite.com/2018/08/25/Machine%20learning%20Artificial%20Neural%20Network/"/>
    <id>http://yoursite.com/2018/08/25/Machine learning Artificial Neural Network/</id>
    <published>2018-08-25T07:36:00.000Z</published>
    <updated>2018-09-01T14:15:55.889Z</updated>
    
    <content type="html"><![CDATA[<p>什么是人工神经网络模型<br>人工神经网络(Artificial Neural Network, ANN)没有一个严格的正式定义。它的基本特点，是试图模仿大脑的神经元之间传递，处理信息的模式。</p>
<p>一个计算模型，要被称为为神经网络，通常需要大量彼此连接的节点 （也称 ‘神经元’），并且具备两个特性：<br>每个神经元，通过某种特定的输出函数 （也叫激励函数 activation function），计算处理来自其它相邻神经元的加权输入值<br>神经元之间的信息传递的强度，用所谓加权值来定义，算法会不断自我学习，调整这个加权值<br>总结：神经网络算法的核心就是：计算、连接、评估、纠错、学习</p>
<h4 id="神经网络模型可以分为："><a href="#神经网络模型可以分为：" class="headerlink" title="神经网络模型可以分为："></a><strong>神经网络模型可以分为：</strong></h4><h6 id="前向网络"><a href="#前向网络" class="headerlink" title="前向网络"></a><strong>前向网络</strong></h6><p>网络中各个神经元接受前一级的输入，并输出到下一级，网络中没有反馈，可以用一个有向无环路图表示。这种网络实现信号从输入空间到输出空间的变换，它的信息处理能力来自于简单非线性函数的多次复合。网络结构简单，易于实现。反传网络是一种典型的前向网络。</p>
<h6 id="反馈网络"><a href="#反馈网络" class="headerlink" title="反馈网络"></a><strong>反馈网络</strong></h6><p>网络内神经元间有反馈，可以用一个无向的完备图表示。这种神经网络的信息处理是状态的变换，可以用动力学系统理论处理。系统的稳定性与联想记忆功能有密切关系。Hopfield网络、波耳兹曼机均属于这种类型。</p>
<h4 id="激活函数"><a href="#激活函数" class="headerlink" title="激活函数"></a><strong>激活函数</strong></h4><p>用于处理复杂的非线性分类情况。比线性回归、logistic回归灵活。训练的时候注意过拟合。<br>非线性激活函数<br>Sigmoid<br>𝑓(𝑥)=1/(1+exp⁡(−𝑥))<br>特点：<br>当x趋近负无穷时，y趋近于0；趋近于正无穷时，y趋近于1；<br>x超出[-6,6]的范围后，函数值基本上没有变化，值非常接近0或者1<br>该函数的值域范围限制在(0,1)之间，这样sigmoid函数就能与一个概率分布联系起来了。<br>𝑓^′ (𝑥)=𝑓(𝑥)(1−𝑓(𝑥))</p>
<h4 id="双曲正切"><a href="#双曲正切" class="headerlink" title="双曲正切"></a><strong>双曲正切</strong></h4><p>tanh⁡(𝑥)=(𝑒^𝑥−𝑒^(−𝑥))/(𝑒^𝑥+𝑒^(−𝑥) )<br>特点：<br>当x趋近负无穷时，y趋近于-1；趋近于正无穷时，y趋近于1；<br>x超出[-3,3]的范围后，函数值基本上没有变化，值非常接近-1或者1<br>该函数的值域范围限制在(-1,1)之间<br>tanh^′ (𝑥)=1−tanh(x)^2</p>
<h4 id="修正线性单元Rectifier-Linear-Units（ReLU）"><a href="#修正线性单元Rectifier-Linear-Units（ReLU）" class="headerlink" title="修正线性单元Rectifier Linear Units（ReLU）"></a><strong>修正线性单元Rectifier Linear Units（ReLU）</strong></h4><p>𝑓(𝑥)=max⁡(0,𝑥)<br>特点：<br>只有有一半隐含层是处于激活状态，其余都是输出为0<br>不会出现梯度消失的问题（即在sigmoid接近饱和区时，导数趋于0，这种情况会造成信息丢失）<br>只需比较、乘加运算，因此计算方便，计算速度快，加速了网络的训练<br>ReLU比sigmoid更接近生物学的激活模型<br>还有一些改进或的变体</p>
<h4 id="Softplus"><a href="#Softplus" class="headerlink" title="Softplus"></a><strong>Softplus</strong></h4><p>𝑓(𝑥)=log⁡(1+𝑒^𝑥 )<br>特点：<br>x趋于负无穷时，softplus趋于0；x趋于正无穷时， softplus趋于x<br>它是ReLU的平滑版<br>它是sigmoid的原函数</p>
<h3 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a><strong>损失函数</strong></h3><p>用于回归中的均方损失：<br>𝐸=1/2 (𝑦−𝑦 ̂ )^2<br>用于分类中的交叉熵损失函数：<br>𝐸=−∑▒〖𝑦<em>𝑘 𝑙𝑜𝑔((𝑦</em>𝑘 ) ̂ )” “ 〗<br>k=1,2,…,m表示m种类别。在违约预测中m=2</p>
<p>基于 Anaconda 的安装<br>安装tensorflow<br>建立一个 conda 计算环境名字叫tensorflow:</p>
<h1 id="Python-2-7"><a href="#Python-2-7" class="headerlink" title="Python 2.7"></a>Python 2.7</h1><p>$ conda create -n tensorflow python=2.7</p>
<h1 id="Python-3-4"><a href="#Python-3-4" class="headerlink" title="Python 3.4"></a>Python 3.4</h1><p>$ conda create -n tensorflow python=3.4</p>
<p>activate tensorflow</p>
<p>安装tensorflow<br>conda install –channel <a href="https://conda.anaconda.org/conda-forge" target="_blank" rel="external">https://conda.anaconda.org/conda-forge</a> tensorflow</p>
<p>import tensorflow as tf<br>退出python3环境或当你不用 TensorFlow 的时候,关闭环境:<br>(tensorflow)$  deactivate<br>$  # Your prompt should change back</p>
<p>windows下安装<br>升级pip<br>python -m pip install –upgrade pip<br>安装tensorflow<br>pip3 install –upgrade <a href="https://storage.googleapis.com/tensorflow/windows/cpu/tensorflow-0.12.0-cp35-cp35m-win_amd64.whl" target="_blank" rel="external">https://storage.googleapis.com/tensorflow/windows/cpu/tensorflow-0.12.0-cp35-cp35m-win_amd64.whl</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;什么是人工神经网络模型&lt;br&gt;人工神经网络(Artificial Neural Network, ANN)没有一个严格的正式定义。它的基本特点，是试图模仿大脑的神经元之间传递，处理信息的模式。&lt;/p&gt;
&lt;p&gt;一个计算模型，要被称为为神经网络，通常需要大量彼此连接的节点 （也
    
    </summary>
    
      <category term="机器学习" scheme="http://yoursite.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="机器学习" scheme="http://yoursite.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>TensorFlow 安装使用</title>
    <link href="http://yoursite.com/2018/08/18/Install%20TensorFlow/"/>
    <id>http://yoursite.com/2018/08/18/Install TensorFlow/</id>
    <published>2018-08-18T03:30:00.000Z</published>
    <updated>2018-09-01T14:15:41.490Z</updated>
    
    <content type="html"><![CDATA[<h2 id="基于Anaconda的Tensorflow"><a href="#基于Anaconda的Tensorflow" class="headerlink" title="基于Anaconda的Tensorflow"></a>基于Anaconda的Tensorflow</h2><h3 id="安装Anaconda"><a href="#安装Anaconda" class="headerlink" title="安装Anaconda"></a>安装Anaconda</h3><p>根据官网选择基于不同的python版本安装：<br><a href="https://www.anaconda.com/download/#windows" target="_blank" rel="external">https://www.anaconda.com/download/#windows</a></p>
<p>博主选择Python 3.6 version，windows 64bit</p>
<p>安装完成后需要配置环境变量，根目录和Scripts目录加入到Path下面<br>G:\ProgramData\Anaconda3;G:\ProgramData\Anaconda3\Scripts</p>
<p>1.检测anaconda环境是否安装成功：conda –version<br>2.检测目前安装了哪些环境变量：conda info –envs</p>
<p>3.安装python版本（博主选择3.5）：conda create –name tensorflow python=3.5<br>安装后是3.5.6<br>4.激活tensflow的环境：activate tensorflow<br>5.检测tensflow的环境添加到了Anaconda里面：conda info –envs<br><img src="http://oh6ybr0jg.bkt.clouddn.com/TENSORFLOW_ENV.png" alt="此处输入图片的描述"><br>6.安装tensorflow gru版本<br>pip install –ignore-installed –upgrade tensorflow-gpu</p>
<p>安装其他组件：<br>pip install pandas<br>conda install scikit-learn<br>conda install matplotlib</p>
<p>IDE想要使用tensorflow 需要制定tensorflow的python版本<br><img src="http://oh6ybr0jg.bkt.clouddn.com/QQ%E6%88%AA%E5%9B%BE20180901134100.png" alt="此处输入图片的描述"></p>
]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;基于Anaconda的Tensorflow&quot;&gt;&lt;a href=&quot;#基于Anaconda的Tensorflow&quot; class=&quot;headerlink&quot; title=&quot;基于Anaconda的Tensorflow&quot;&gt;&lt;/a&gt;基于Anaconda的Tensorflow&lt;/
    
    </summary>
    
      <category term="机器学习" scheme="http://yoursite.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="机器学习" scheme="http://yoursite.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>机器学习-随机森林</title>
    <link href="http://yoursite.com/2018/08/16/Mathematical%20%20Random%20Forest/"/>
    <id>http://yoursite.com/2018/08/16/Mathematical  Random Forest/</id>
    <published>2018-08-16T01:30:00.000Z</published>
    <updated>2018-09-01T14:13:49.214Z</updated>
    
    <content type="html"><![CDATA[<p>sklearn.ensemble.RandomForestClassifier</p>
<ul>
<li><strong>n_estimators</strong> : integer, optional (default=10)<br> 森林里（决策）树的数目</li>
<li><strong>criterion</strong> : string, optional (default=”gini”)<br> 衡量分裂质量的性能（函数）。 受支持的标准是基尼不纯度的”gini”,和信息增益的”entropy”（熵）。<br>注意：这个参数是特定树的</li>
<li><p><strong>max_features</strong> : int, float, string or None, optional (default=”auto”)<br> 选择最适属性时划分的特征不能超过此值:</p>
<pre><code>如果是int，就要考虑每一次分割处的max_feature特征
如果是float，那么max_features就是一个百分比，那么（max_feature*n_features）特征整数值是在每个分割处考虑的。
如果是auto，那么max_features=sqrt(n_features)，即n_features的平方根值。
如果是log2，那么max_features=log2(n_features)
如果是None,那么max_features=n_features
</code></pre><p>注意：寻找分割点不会停止，直到找到最少一个有效的节点划分区，即使它需要有效检查超过max_features的特征。</p>
</li>
<li><p><strong>max_depth</strong> : integer or None, optional (default=None)<br>（决策）树的最大深度。如果值为None，那么会扩展节点，直到所有的叶子是纯净的，或者直到所有叶子包含少于min_sample_split的样本。</p>
</li>
<li><p><strong>min_samples_split</strong> : int, float, optional (default=2)<br> 根据属性划分节点时，每个划分最少的样本数。</p>
<pre><code>如果为int，那么考虑min_samples_split作为最小的数字。
如果为float，那么min_samples_split是一个百分比，并且把ceil(min_samples_split*n_samples)是每一个分割最小的样本数量。
</code></pre><p> 在版本0.18中更改：为百分比添加浮点值。<br> 叶子节点最少的样本数。</p>
<pre><code>如果为int，那么考虑min_samples_leaf作为最小的数字。
如果为float，那么min_samples_leaf为一个百分比，并且ceil(min_samples_leaf*n_samples)是每一个节点的最小样本数量。
</code></pre><p> 在版本0.18中更改：为百分比添加浮点值。</p>
</li>
<li><strong>min_weight_fraction_leaf</strong> : float, optional (default=0.)<br> 一个叶子节点所需要的权重总和（所有的输入样本）的最小加权分数。当sample_weight没有提供时，样本具有相同的权重</li>
<li><strong>max_leaf_nodes</strong> : int or None, optional (default=None)<br> 叶子树的最大样本数。<br> 以最优的方法使用max_leaf_nodes来生长树。最好的节点被定义为不纯度上的相对减少。如果为None,那么不限制叶子节点的数量。</li>
<li><strong>min_impurity_split</strong> : float,<br> 树早期生长的阈值。如果一个节点的不纯度超过阈值那么这个节点将会分裂，否则它还是一片叶子。<br> 自0.19版以后不推荐使用：min_impurity_split已被弃用，取而代之的是0.19中的min_impurity_decrease。min_impurity_split将在0.21中被删除。 使用min_impurity_decrease</li>
<li><strong>min_impurity_decrease</strong> : float, optional (default=0.)<br> 如果节点的分裂导致的不纯度的下降程度大于或者等于这个节点的值，那么这个节点将会被分裂。<br> 不纯度加权减少方程式如下：<br> N_t / N <em> (impurity - N_t_R / N_t </em> right_impurity<pre><code>- N_t_L / N_t * left_impurity)
</code></pre> N是样本总的数量，N_t是当前节点处的样本数量，N_t_L是左孩子节点样本的数量,还有N_t_R是右孩子节点的样本数量。<br> N，N_t，N_t_R和N_t_L全部是指加权总和，如果sample_weight通过的话。<br> 0.19版本新加的参数。</li>
<li><strong>bootstrap</strong> : boolean, optional (default=True)<br> 建立决策树时，是否使用有放回抽样。</li>
<li><strong>oob_score</strong> : bool (default=False)<br> 是否使用袋外样本来估计泛化精度。</li>
<li><strong>n_jobs</strong> : integer, optional (default=1)<br> 用于拟合和预测的并行运行的工作（作业）数量。如果值为-1，那么工作数量被设置为核的数量。</li>
<li><strong>random_state</strong> : int, RandomState instance or None, optional (default=None)<br> RandomStateIf int，random_state是随机数生成器使用的种子;<br> 如果是RandomState实例，random_state就是随机数生成器;<br> 如果为None，则随机数生成器是np.random使用的RandomState实例。</li>
<li><strong>verbose</strong> : int, optional (default=0)<br> 控制决策树建立过程的冗余度。</li>
<li><strong>warm_start</strong> : bool, optional (default=False)<br> 当被设置为True时，重新使用之前呼叫的解决方案，用来给全体拟合和添加更多的估计器，反之，仅仅只是为了拟合一个全新的森林。</li>
<li>class_weight : dict, list of dicts, “balanced”,<br> “balanced_subsample” 或者None,（默认值为None）,与格式{class_label: weight}相关联的类的可选的权值。如果没有给值，所有的类到都应该有一个权值。对于多输出问题，一个字典序    列可以按照y的列的顺利被提供。<br> 请注意，对于多输出（包括多标签），其权值应该被定义为它自己字典的每一列的每一个类。例如，对于四类多标签分类，权值应该如[{0: 1, 1: 1}, {0: 1, 1: 5}, {0: 1, 1: 1}, {0: 1, 1: 1}] 这样，而不是[{1:1}, {2:5}, {3:1}, {4:1}].这样。<br> “balanced”模式使用y的值来自动的调整权值，与输入数据中类别频率成反比，如：<pre><code>n_samples / (n_classes * np.bincount(y))
</code></pre> “balanced_subsample”模式和”balanced”相同，除了权值是基于每棵成长树有放回抽样计算的。<br> 对于多输出，y的每列权值将相乘。<br> 请注意，如果指定了sample_weight,这些权值将会和sample_weight相乘（通过拟合方法传递）。</li>
</ul>
<p>Attributes:    属性</p>
<ul>
<li><strong>estimators_</strong> :  决策树分类器的序列<br> 拟合的子估计器的集合。</li>
<li><strong>classes_</strong> :  数组维度=[n_classes]的数组或者一个这样数组的序列。<br> 类别标签（单一输出问题），或者类别标签的数组序列（多输出问题）。</li>
<li><strong>n<em>classes</em></strong> : int or list<br> 类别的数量（单输出问题），或者一个序列，包含每一个输出的类别数量（多输出问题）</li>
<li><strong>n<em>features</em></strong> : int<br> 执行拟合时的特征数量。</li>
<li><strong>n<em>outputs</em></strong> : int<br> 执行拟合时的输出数量。</li>
<li><strong>feature<em>importances</em></strong> : array of shape = [n_features]<br> 特征的重要性（值越高，特征越重要）</li>
<li><strong>oob<em>score</em></strong> : float<br>使用袋外估计获得的训练数据集的得分。</li>
<li><strong>oob_decision<em>function</em></strong> :维度=[n_samples,n_classes]的数组<br> 在训练集上用袋外估计计算的决策函数。如果n_estimators很小的话，那么在有放回抽样中，一个数据点也不会被忽略是可能的。在这种情况下，oob_decision<em>function</em> 可能包括NaN。</li>
</ul>
<p>参数的默认值控制决策树的大小（例如，max_depth，，min_samples_leaf等等），导致完全的生长和在某些数据集上可能非常大的未修剪的树。为了降低内容消耗，决策树的复杂度和大小应该通过设置这些参数值来控制。<br>这些特征总是在每个分割中随机排列。 因此，即使使用相同的训练数据，max_features = n_features和bootstrap = False，如果在搜索最佳分割期间所列举的若干分割的准则的改进是相同的，那么找到的最佳分割点可能会不同。 为了在拟合过程中获得一个确定的行为，random_state将不得不被修正。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;sklearn.ensemble.RandomForestClassifier&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;n_estimators&lt;/strong&gt; : integer, optional (default=10)&lt;br&gt; 森林里（决策）树的数目&lt;/li&gt;

    
    </summary>
    
      <category term="机器学习" scheme="http://yoursite.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="机器学习" scheme="http://yoursite.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>机器学习-梯度下降</title>
    <link href="http://yoursite.com/2018/04/27/Mathematical%20regression%20gradient%20descent/"/>
    <id>http://yoursite.com/2018/04/27/Mathematical regression gradient descent/</id>
    <published>2018-04-27T01:30:00.000Z</published>
    <updated>2018-07-25T16:09:57.310Z</updated>
    
    <content type="html"><![CDATA[<h3 id="梯度下降："><a href="#梯度下降：" class="headerlink" title="梯度下降："></a>梯度下降：</h3><p>批量梯度下降法（Batch Gradient Descent，简称BGD）<br>    优点：全局最优解；易于并行实现；<br>　　缺点：当样本数目很多时，训练过程会很慢。<br>随机梯度下降法（Stochastic Gradient Descent，简称SGD）<br>    优点：训练速度快；迭代次数少<br>    缺点：准确度下降，并不是全局最优；不易于并行实现。<br>小批量梯度下降算法（MBGD）<br>如果损失函数是凸函数，梯度下降法得到的解就一定是全局最优解。</p>
<h4 id="凸凹函数："><a href="#凸凹函数：" class="headerlink" title="凸凹函数："></a>凸凹函数：</h4><p>设f(x)在区间D上连续，如果对D上任意两点a、b恒有<br>f（（a+b）/2）&lt;(f(a)+f(b))/2<br>那么称f(x)在D上的图形是（向上）凹的（或凹弧）；如果恒有<br>f（（a+b）/2）&gt;(f(a)+f(b))/2<br>那么称f(x)在D上的图形是（向上）凸的（或凸弧）</p>
<h3 id="梯度下降相关概念："><a href="#梯度下降相关概念：" class="headerlink" title="梯度下降相关概念："></a>梯度下降相关概念：</h3><ol>
<li>步长（Learning rate）：步长决定了在梯度下降迭代的过程中，每一步沿梯度负方向前进的长度。用上面下山的例子，步长就是在当前这一步所在位置沿着最陡峭最易下山的位置走的那一步的长度。</li>
</ol>
<p>2.特征（feature）：指的是样本中输入部分，比如2个单特征的样本（x(0),y(0)）,（x(1),y(1)）（x(0),y(0)）,（x(1),y(1)）,则第一个样本特征为x(0)x(0)，第一个样本输出为y(0)y(0)。</p>
<ol>
<li><p>假设函数（hypothesis function）：在监督学习中，为了拟合输入样本，而使用的假设函数，记为hθ(x)hθ(x)。比如对于单个特征的m个样本（x(i),y(i)）(i=1,2,…m)（x(i),y(i)）(i=1,2,…m),可以采用拟合函数如下： hθ(x)=θ0+θ1xhθ(x)=θ0+θ1x。</p>
</li>
<li><p>损失函数（loss function）：为了评估模型拟合的好坏，通常用损失函数来度量拟合的程度。损失函数极小化，意味着拟合程度最好，对应的模型参数即为最优参数。在线性回归中，损失函数通常为样本输出和假设函数的差取平方。比如对于m个样本（xi,yi）(i=1,2,…m)（xi,yi）(i=1,2,…m),采用线性回归，损失函数为：</p>
<pre><code>J(θ0,θ1)=∑i=1m(hθ(xi)−yi)2J(θ0,θ1)=∑i=1m(hθ(xi)−yi)2
</code></pre><p>其中xixi表示第i个样本特征，yiyi表示第i个样本对应的输出，hθ(xi)hθ(xi)为假设函数。
　　　　</p>
</li>
</ol>
<h3 id="局部加权回归"><a href="#局部加权回归" class="headerlink" title="局部加权回归"></a>局部加权回归</h3><p>简单来说，这个过程其实是在先拟合出一条曲线，然后再用这个曲线去预测需要预测的点。(源自百度)<br>为什么改进要用加权回归呢？ 很简单，因为非线性拟合出直线误差会很大，这里的局部加权类似于knn算法的权重，即距离中心点越近的权重越大，对拟合曲线的影响也就越大，所以也有了局部加权这一名词</p>
<p>参考文献：<br><a href="https://blog.csdn.net/Gentle_Guan/article/details/76586689?locationNum=8&amp;fps=1" target="_blank" rel="external">https://blog.csdn.net/Gentle_Guan/article/details/76586689?locationNum=8&amp;fps=1</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;梯度下降：&quot;&gt;&lt;a href=&quot;#梯度下降：&quot; class=&quot;headerlink&quot; title=&quot;梯度下降：&quot;&gt;&lt;/a&gt;梯度下降：&lt;/h3&gt;&lt;p&gt;批量梯度下降法（Batch Gradient Descent，简称BGD）&lt;br&gt;    优点：全局最优解；易于并行
    
    </summary>
    
      <category term="机器学习" scheme="http://yoursite.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="机器学习" scheme="http://yoursite.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>机器学习-逻辑回归模型特征处理</title>
    <link href="http://yoursite.com/2018/04/08/Mathematical%20Feature%20processing%20of%20logistic%20regression%20model/"/>
    <id>http://yoursite.com/2018/04/08/Mathematical Feature processing of logistic regression model/</id>
    <published>2018-04-08T01:30:00.000Z</published>
    <updated>2018-07-25T16:10:12.622Z</updated>
    
    <content type="html"><![CDATA[<p>如果有异常值，使用极大-极小归一化或均值-标准差归一化，计算之前需要将极端值排除在外。<br>例如：<br>x’=x−min/ max−min<br>计算max与min时需要用P1与P99来代替。新生成的值如果超过1用1表示，如果小于0 用0表示</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;如果有异常值，使用极大-极小归一化或均值-标准差归一化，计算之前需要将极端值排除在外。&lt;br&gt;例如：&lt;br&gt;x’=x−min/ max−min&lt;br&gt;计算max与min时需要用P1与P99来代替。新生成的值如果超过1用1表示，如果小于0 用0表示&lt;/p&gt;

    
    </summary>
    
      <category term="机器学习" scheme="http://yoursite.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="机器学习" scheme="http://yoursite.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>机器学习-回归算法实例</title>
    <link href="http://yoursite.com/2018/03/27/Mathematical%20regression%20/"/>
    <id>http://yoursite.com/2018/03/27/Mathematical regression /</id>
    <published>2018-03-27T01:30:00.000Z</published>
    <updated>2018-12-21T08:14:28.452Z</updated>
    
    <content type="html"><![CDATA[<h2 id="概念梳理："><a href="#概念梳理：" class="headerlink" title="概念梳理："></a>概念梳理：</h2><p>数学期望：<br>在概率论和统计学中，数学期望(mean)（或均值，亦简称期望）是试验中每次可能结果的概率乘以其结果的总和，是最基本的数学特征之一。它反映随机变量平均取值的大小</p>
<p>方差：<br>（variance)是在概率论和统计方差衡量随机变量或一组数据时离散程度的度量。概率论中方差用来度量随机变量和其数学期望（即均值）之间的偏离程度。统计中的方差（样本方差）是每个样本值与全体样本值的平均数之差的平方值的平均数。在许多实际问题中，研究方差即偏离程度有着重要意义。</p>
<p>概率密度函数：<br>在数学中，连续型随机变量的概率密度函数（在不至于混淆时可以简称为密度函数）是一个描述这个随机变量的输出值，在某个确定的取值点附近的可能性的函数。而随机变量的取值落在某个区域之内的概率则为概率密度函数在这个区域上的积分。当概率密度函数存在的时候，累积分布函数是概率密度函数的积分。概率密度函数一般以小写标记<br>正态分布是重要的概率分布。它的概率密度函数是：<br><img src="http://oh6ybr0jg.bkt.clouddn.com/gailvmidu.jpg" alt="此处输入图片的描述"><br>随着参数μ和σ变化，概率分布也产生变化。<br>期望：μ<br>方差：σ^2<br>中位数：μ<br>众44o6fdeswq    DFGI-数：μ<br>偏度：0<br>峰度：3<br>\]<br><a id="more"></a><br>正态分布：<br>又称为常态分布，高斯分布。<br>若随机变量X服从一个数学期望为μ、方差为σ^2的正态分布，记为N(μ，σ^2)。其概率密度函数为正态分布的期望值μ决定了其位置，其标准差σ决定了分布的幅度。当μ = 0,σ = 1时的正态分布是标准正态分布。</p>
<p>线性回归：<br>线性回归是利用数理统计中回归分析，来确定两种或两种以上变量间相互依赖的定量关系的一种统计分析方法，运用十分广泛。其表达形式为y = w’x+e，e为误差服从均值为0的正态分布。</p>
<p>回归数据：<br><a href="http://archive.ics.uci.edu/ml/datasets/Individual+household+electric+power+consumption" target="_blank" rel="external">http://archive.ics.uci.edu/ml/datasets/Individual+household+electric+power+consumption</a></p>
<p>属性信息：</p>
<p>1.date：格式dd/mm/yyyy日期<br>2.time：格式HH时间：MM：SS<br>3.global_active_power：家用全球分钟平均有功<strong>功率</strong>（千瓦）<br>4.global_reactive_power: 家用全球分钟平均无功<strong>功率</strong>（千瓦）<br>5.voltage：分钟平均<strong>电压</strong>（伏特）<br>6.global_intensity：家用全球分钟平均<strong>电流</strong>强度（安培）<br>7.sub_metering_1：能耗分项计量1号（中有功电能电能）。它与<strong>厨房</strong>相对应，主要包括洗碗机、烤箱和微波炉（热板不是电动的，而是燃气驱动的）。<br>8.sub_metering_2：能耗分项计量2号（中有功电能电能）。它对应<strong>洗衣</strong>房，包括洗衣机、滚筒烘干机、冰箱和灯。<br>9.sub_metering_3：能耗分项计量3号（中有功电能电能）。它相当于一个<strong>电热水器</strong>和一个空调。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</div><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"><span class="keyword">import</span> time</div><div class="line"><span class="keyword">import</span> sklearn</div><div class="line"><span class="keyword">import</span> matplotlib <span class="keyword">as</span> mpl</div><div class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</div><div class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LinearRegression</div><div class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</div><div class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</div><div class="line"></div><div class="line"></div><div class="line">path=<span class="string">'C:/Users/zhanghongming/Documents/data/100.txt'</span></div><div class="line">names = [<span class="string">'Date'</span>,<span class="string">'Time'</span>,<span class="string">'Global_active_power'</span>,<span class="string">'Global_reactive_power'</span>,<span class="string">'Voltage'</span>,<span class="string">'Global_intensity'</span>,<span class="string">'Sub_metering_1'</span>,<span class="string">'Sub_metering_2'</span>,<span class="string">'Sub_metering_3'</span>]</div><div class="line"></div><div class="line"></div><div class="line">df=pd.read_csv(path,sep=<span class="string">';'</span>)</div><div class="line">print(df.head())</div></pre></td></tr></table></figure>
<pre><code>Date      Time  Global_active_power  Global_reactive_power  Voltage  \
</code></pre><p>0  16/12/2006  17:24:00                4.216                  0.418   234.84<br>1  16/12/2006  17:25:00                5.360                  0.436   233.63<br>2  16/12/2006  17:26:00                5.374                  0.498   233.29<br>3  16/12/2006  17:27:00                5.388                  0.502   233.74<br>4  16/12/2006  17:28:00                3.666                  0.528   235.68   </p>
<p>   Global_intensity  Sub_metering_1  Sub_metering_2  Sub_metering_3<br>0              18.4             0.0             1.0            17.0<br>1              23.0             0.0             1.0            16.0<br>2              23.0             0.0             2.0            17.0<br>3              23.0             0.0             1.0            17.0<br>4              15.8             0.0             1.0            17.0  </p>
<h4 id="看所有的变量值"><a href="#看所有的变量值" class="headerlink" title="看所有的变量值"></a>看所有的变量值</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"></div><div class="line"><span class="keyword">for</span> i <span class="keyword">in</span> df.columns:</div><div class="line">    print(df[i].value_counts())</div></pre></td></tr></table></figure>
<p>Name: Date, dtype: int64<br>19:01:00    1<br>17:27:00    1<br>18:24:00    1<br>           ..</p>
<p>Name: Time, Length: 99, dtype: int64<br>4.230    2<br>2.912    2<br>4.218    2<br>6.072    1<br>5.412    1<br>           ..</p>
<p>Name: Global_active_power, Length: 96, dtype: int64<br>0.000    33<br>0.090     7<br>0.054     4<br>0.144     3<br>           ..</p>
<p>Name: Global_reactive_power, dtype: int64<br>235.84    3<br>234.20    2<br>235.68    2<br>233.74    2<br>           ..</p>
<p>Name: Voltage, Length: 90, dtype: int64<br>12.4    7<br>13.8    5<br>15.8    5<br>           ..<br>Name: Global_intensity, dtype: int64<br>0.0    99<br>Name: Sub_metering_1, dtype: int64<br>1.0     50<br>0.0     26<br>2.0      8</p>
<p>Name: Sub_metering_2, dtype: int64<br>17.0    77<br>16.0    18<br>18.0     4</p>
<p>Name: Sub_metering_3, dtype: int64</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#空值处理</span></div><div class="line">new_df= df.replace(<span class="string">'?'</span>,np.nan)</div><div class="line"></div><div class="line">datas = new_df.dropna(how=<span class="string">'any'</span>)</div><div class="line"></div><div class="line"><span class="comment">#定义时间格式化</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">datae_format</span><span class="params">(dt)</span>:</span></div><div class="line">    t = time.strptime(<span class="string">' '</span>.join(dt),<span class="string">'%d/%m/%Y %H:%M:%S'</span>)</div><div class="line">    <span class="keyword">return</span> (t.tm_year,t.tm_mon,t.tm_mday,t.tm_hour,t.tm_min,t.tm_sec)</div><div class="line"></div><div class="line"><span class="comment">##分析功率和时间的线性关系。将时间转换为连续的</span></div><div class="line"></div><div class="line">X = datas[names[<span class="number">0</span>:<span class="number">2</span>]]</div><div class="line">X = X.apply(<span class="keyword">lambda</span> x :pd.Series(datae_format(x)),axis=<span class="number">1</span>)</div><div class="line">Y = datas[names[<span class="number">2</span>]]</div><div class="line"></div><div class="line"></div><div class="line">print(X.head(<span class="number">5</span>))</div><div class="line">print(Y.head(<span class="number">5</span>))</div></pre></td></tr></table></figure>
<pre><code>0   1   2   3   4  5
</code></pre><p>0  2006  12  16  17  24  0<br>1  2006  12  16  17  25  0<br>2  2006  12  16  17  26  0<br>3  2006  12  16  17  27  0<br>4  2006  12  16  17  28  0<br>0    4.216<br>1    5.360<br>2    5.374<br>3    5.388<br>4    3.666<br>Name: Global_active_power, dtype: float64</p>
<h6 id="函数讲解"><a href="#函数讲解" class="headerlink" title="函数讲解"></a>函数讲解</h6><p>sklearn.model_selection.train_test_split随机划分训练集和测试集<br>一般形式：<br>train_test_split是交叉验证中常用的函数，功能是从样本中随机的按比例选取train data和testdata，形式为：<br>X_train,X_test, y_train, y_test =<br>cross_validation.train_test_split(train_data,train_target,test_size=0.4, random_state=0)<br>参数解释：<br>train_data：所要划分的样本特征集<br>train_target：所要划分的样本结果<br>test_size：样本占比，如果是整数的话就是样本的数量<br>random_state：是随机数的种子。<br>随机数种子：其实就是该组随机数的编号，在需要重复试验的时候，保证得到一组一样的随机数。比如你每次都填1，其他参数一样的情况下你得到的随机数组是一样的。但填0或不填，每次都会不一样。<br>随机数的产生取决于种子，随机数和种子之间的关系遵从以下两个规则：<br>种子不同，产生不同的随机数；种子相同，即使实例不同也产生相同的随机数。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line">X_train,X_test,Y_train,Y_test = train_test_split( X, Y, test_size=<span class="number">0.2</span>, random_state=<span class="number">42</span>)</div><div class="line"></div><div class="line"></div><div class="line"><span class="comment">## 数据标准换行</span></div><div class="line">ss = StandardScaler()</div><div class="line">X_train = ss.fit_transform(X_train)</div><div class="line">X_test = ss.fit_transform(X_test)</div><div class="line"></div><div class="line"></div><div class="line"><span class="comment">##训练数据</span></div><div class="line">lr = LinearRegression()</div><div class="line">lr.fit(X_train,Y_train)</div><div class="line"></div><div class="line"><span class="comment">##预测Y值</span></div><div class="line">y_predict = lr.predict(X_test)</div><div class="line"></div><div class="line">print(<span class="string">"准确率:"</span>,lr.score(X_test,Y_test))</div></pre></td></tr></table></figure>
<p>样本数据100条：<br>准确率: 0.0226499044921<br>样本数据1000条：<br>0.103073016594</p>
<p>模型保存及加载：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> sklearn.externals <span class="keyword">import</span> joblib</div><div class="line"><span class="comment">## 模型保存：</span></div><div class="line">joblib.dump(ss,<span class="string">"data_ss.model"</span>)</div><div class="line">joblib.dump(lr,<span class="string">"data_lr.model"</span>)</div><div class="line"></div><div class="line"><span class="comment">## 加载模型</span></div><div class="line">joblib,load(<span class="string">"data_ss.model"</span>)</div><div class="line">joblib,load(<span class="string">"data_lr.model"</span>)</div></pre></td></tr></table></figure></p>
<p>plot文档：<br><a href="https://matplotlib.org/api/pyplot_api.html#matplotlib.pyplot.plot" target="_blank" rel="external">https://matplotlib.org/api/pyplot_api.html#matplotlib.pyplot.plot</a></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line"><span class="comment">## 解决中文问题</span></div><div class="line">mpl.rcParams[<span class="string">'font.sans-serif'</span>] = [<span class="string">u'SimHei'</span>];</div><div class="line">mpl.rcParams[<span class="string">'axes.unicode_minus'</span>] = <span class="keyword">False</span></div><div class="line"></div><div class="line">t=np.arange(len(X_test))</div><div class="line">plt.figure(facecolor=<span class="string">'w'</span>)</div><div class="line">plt.plot(t,Y_test,<span class="string">'r--'</span>,linewidth=<span class="number">2</span>,label=<span class="string">u'真实值'</span>)</div><div class="line">plt.plot(t,y_predict,<span class="string">'g--'</span>,linewidth=<span class="number">2</span>,label=<span class="string">u'预测值'</span>)</div><div class="line">plt.legend(loc =<span class="string">'lower right'</span>)</div><div class="line">plt.title(<span class="string">u'线性回归时间与电压的关系'</span>,fontsize=<span class="number">20</span> )</div><div class="line">plt.grid(b=<span class="keyword">True</span>)</div><div class="line">plt.show()</div></pre></td></tr></table></figure>
<p>100条数据：<br><img src="http://oh6ybr0jg.bkt.clouddn.com/linear_regression_100.png" alt="此处输入图片的描述"></p>
<p>1000条数据：<br><img src="http://oh6ybr0jg.bkt.clouddn.com/linear_regression_1000.png" alt="此处输入图片的描述"></p>
<h3 id="linear多项式"><a href="#linear多项式" class="headerlink" title="linear多项式"></a>linear多项式</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> sklearn.pipeline <span class="keyword">import</span> Pipeline</div><div class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> PolynomialFeatures</div><div class="line"><span class="keyword">from</span> sklearn.grid_search <span class="keyword">import</span> GridSearchCV</div><div class="line">models = [Pipeline([(<span class="string">'Poly'</span>,PolynomialFeatures()),(<span class="string">'Linear'</span>,LinearRegression())])]</div><div class="line">model = models[<span class="number">0</span>]</div><div class="line"></div><div class="line"></div><div class="line"><span class="comment">##获取X，Y变量，并将时间变量转换为数值型连续的</span></div><div class="line">X = datas[names[<span class="number">0</span>:<span class="number">2</span>]]</div><div class="line">X = X.apply(<span class="keyword">lambda</span> x :pd.Series(datae_format(x)),axis=<span class="number">1</span>)</div><div class="line">Y = datas[names[<span class="number">4</span>]]</div><div class="line"></div><div class="line"><span class="comment">## 对数据集进行划分</span></div><div class="line">X_train,X_test,Y_train,Y_test = train_test_split( X, Y, test_size=<span class="number">0.2</span>, random_state=<span class="number">0</span>)</div><div class="line"></div><div class="line"><span class="comment">## 数据标准化</span></div><div class="line">ss = StandardScaler()</div><div class="line">X_train = ss.fit_transform(X_train)</div><div class="line">X_test = ss.fit_transform(X_test)</div><div class="line"></div><div class="line"><span class="comment">## 模型训练</span></div><div class="line">t=np.arange(len(X_test))</div><div class="line">N =<span class="number">5</span></div><div class="line">d_pool= np.arange(<span class="number">1</span>,N,<span class="number">1</span>)</div><div class="line">m=d_pool.size</div><div class="line">clrs = []  <span class="comment"># 颜色</span></div><div class="line"><span class="keyword">for</span> c <span class="keyword">in</span> np.linspace(<span class="number">16711680</span>, <span class="number">255</span>, m,dtype=<span class="string">'int64'</span>):</div><div class="line">    clrs.append(<span class="string">'#%06x'</span> % c)</div><div class="line">line_width = <span class="number">3</span></div><div class="line"></div><div class="line">plt.figure(figsize=(<span class="number">12</span>,<span class="number">6</span>),facecolor=<span class="string">'w'</span>)</div><div class="line"><span class="keyword">for</span> i,d <span class="keyword">in</span> enumerate(d_pool):</div><div class="line">    plt.subplot(N<span class="number">-1</span>,<span class="number">1</span>,i+<span class="number">1</span>)</div><div class="line">    plt.plot(t,Y_test,<span class="string">'r--'</span>,label=<span class="string">u'真实值'</span>,ms=<span class="number">10</span>,zorder=N)</div><div class="line">    model.set_params(Poly__degree=d) <span class="comment"># 设置多项式的阶</span></div><div class="line">    model.fit(X_train,Y_train)</div><div class="line">    lin = model.get_params(<span class="string">'Linear'</span>)[<span class="string">'Linear'</span>]</div><div class="line">    output =<span class="string">u'%d阶，系数为：'</span>%d</div><div class="line">    print( output,lin.coef_.ravel())</div><div class="line"></div><div class="line">    y_hat = model.predict(X_test)</div><div class="line">    s = model.score(X_test,Y_test)</div><div class="line"></div><div class="line">    z=N<span class="number">-1</span> <span class="keyword">if</span> (d==<span class="number">2</span>) <span class="keyword">else</span> <span class="number">0</span></div><div class="line">    label=<span class="string">u'%d阶,准确率=%.3f'</span>%(d,s)</div><div class="line"></div><div class="line"></div><div class="line">    plt.plot(t,y_hat,color=clrs[i],lw=line_width,alpha = <span class="number">0.75</span>,label=label,zorder=z)</div><div class="line">    plt.legend(loc = <span class="string">'upper left'</span>)</div><div class="line">    plt.grid(<span class="keyword">True</span>)</div><div class="line">    plt.ylabel(<span class="string">u'%d阶结果'</span>%d,fontsize=<span class="number">12</span>)</div><div class="line"></div><div class="line"><span class="comment"># 预测值和真实值画图比较</span></div><div class="line">plt.legend(loc = <span class="string">'lower right'</span>)</div><div class="line">plt.suptitle(<span class="string">u'线性回归时间与电压之间多项式关系'</span>)</div><div class="line">plt.grid(b=<span class="keyword">True</span>)</div><div class="line">plt.show()</div></pre></td></tr></table></figure>
<p>1阶，系数为： [  0.00000000e+00   5.55111512e-17   0.00000000e+00   0.00000000e+00<br>  -4.22939297e-01  -4.34494704e-01   0.00000000e+00]<br>2阶，系数为： [  2.47983335e-17   1.11022302e-16  -2.22044605e-16  -1.11022302e-16<br>  -5.05820937e-01  -3.46571423e-01   0.00000000e+00   0.00000000e+00<br>   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00<br>   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00<br>   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00<br>   0.00000000e+00   0.00000000e+00  -8.58357173e-01  -7.57689882e-01<br>   0.00000000e+00  -1.60364055e-01   0.00000000e+00   0.00000000e+00]<br>3阶，系数为： [ -1.69309011e-15  -2.99760217e-15   3.33066907e-16   5.55111512e-16<br>  -4.41970713e-02  -3.57278153e-01   0.00000000e+00   2.22044605e-16<br>   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00<br>   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00<br>   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00<br>   0.00000000e+00   0.00000000e+00   3.43644538e-01   4.86208530e-01<br>   0.00000000e+00   3.26242425e-02   0.00000000e+00   0.00000000e+00<br>   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00<br>   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00<br>   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00<br>   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00<br>   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00<br>   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00<br>   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00<br>   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00<br>   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00<br>   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00<br>   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00<br>   0.00000000e+00   0.00000000e+00   4.48140740e-01   6.37890832e-01<br>   0.00000000e+00  -7.45035081e-01   0.00000000e+00   0.00000000e+00<br>  -5.02511111e-01   0.00000000e+00   0.00000000e+00   0.00000000e+00]<br>4阶，系数为： [  2.22002972e-013  -8.01497757e-013   5.37209166e-014  -4.53519167e-013<br>   7.19933381e-003   2.05441337e-001   3.86510268e-013  -5.94066463e-013<br>   6.66133815e-015   6.66133815e-016  -1.88737914e-015   6.27276009e-015<br>  -5.30131494e-015  -1.01585407e-014   3.35287353e-014   8.21565038e-015<br>  -2.55351296e-015  -2.22044605e-016  -6.31088724e-030   3.02922588e-028<br>   1.00974196e-028  -5.04870979e-029  -4.89052469e-002   3.28220946e-001<br>   0.00000000e+000   6.15440583e-003   0.00000000e+000   0.00000000e+000<br>   1.26217745e-029   0.00000000e+000  -5.60519386e-044  -8.40779079e-045<br>  -7.00649232e-045  -2.24207754e-044  -5.60519386e-045   2.80259693e-045<br>   1.40129846e-045   0.00000000e+000   0.00000000e+000   4.97841222e-060<br>   1.55575382e-061  -1.24460306e-060  -2.48920611e-060   0.00000000e+000<br>  -3.11150764e-061  -1.16681536e-061  -3.11150764e-061  -4.66726146e-061<br>   2.21085915e-075  -5.52714788e-076  -1.38178697e-076   2.76357394e-076<br>  -1.38178697e-076  -3.45446742e-077   0.00000000e+000   1.34940134e-079<br>   0.00000000e+000   1.91761463e-093   1.49813643e-095  -5.99254573e-095<br>   4.49440930e-095   1.12360233e-095   0.00000000e+000   7.49068217e-096<br>  -2.34083818e-097   0.00000000e+000   0.00000000e+000   0.00000000e+000<br>   0.00000000e+000   0.00000000e+000  -1.66326556e-111   4.15816391e-112<br>  -2.07908195e-112   0.00000000e+000  -6.13741990e-002  -8.70197287e-001<br>   8.39734513e-140  -1.48604949e+000   0.00000000e+000   0.00000000e+000<br>  -4.67097255e-001   0.00000000e+000   0.00000000e+000   0.00000000e+000<br>   0.00000000e+000   0.00000000e+000   0.00000000e+000   0.00000000e+000<br>   0.00000000e+000   0.00000000e+000   0.00000000e+000   0.00000000e+000<br>   0.00000000e+000   0.00000000e+000   0.00000000e+000   0.00000000e+000<br>   0.00000000e+000   0.00000000e+000   0.00000000e+000   0.00000000e+000<br>   0.00000000e+000   0.00000000e+000   0.00000000e+000   0.00000000e+000<br>   0.00000000e+000   0.00000000e+000   0.00000000e+000   0.00000000e+000<br>   0.00000000e+000   0.00000000e+000   0.00000000e+000   0.00000000e+000<br>   0.00000000e+000   0.00000000e+000   0.00000000e+000   0.00000000e+000<br>   0.00000000e+000   0.00000000e+000   0.00000000e+000   0.00000000e+000<br>   0.00000000e+000   0.00000000e+000   0.00000000e+000   0.00000000e+000<br>   0.00000000e+000   0.00000000e+000   0.00000000e+000   0.00000000e+000<br>   0.00000000e+000   0.00000000e+000   0.00000000e+000   0.00000000e+000<br>   0.00000000e+000   0.00000000e+000   0.00000000e+000   0.00000000e+000<br>   0.00000000e+000   0.00000000e+000   0.00000000e+000   0.00000000e+000<br>   0.00000000e+000   0.00000000e+000   0.00000000e+000   0.00000000e+000<br>   0.00000000e+000   0.00000000e+000   0.00000000e+000   0.00000000e+000<br>   0.00000000e+000   0.00000000e+000   0.00000000e+000   0.00000000e+000<br>   0.00000000e+000   0.00000000e+000   0.00000000e+000   0.00000000e+000<br>   0.00000000e+000   0.00000000e+000   0.00000000e+000   0.00000000e+000<br>   0.00000000e+000   0.00000000e+000   0.00000000e+000   0.00000000e+000<br>   0.00000000e+000   0.00000000e+000   0.00000000e+000   0.00000000e+000<br>   0.00000000e+000   0.00000000e+000   0.00000000e+000   0.00000000e+000<br>   0.00000000e+000   0.00000000e+000   0.00000000e+000   0.00000000e+000<br>   0.00000000e+000   0.00000000e+000   0.00000000e+000   0.00000000e+000<br>   0.00000000e+000   0.00000000e+000   0.00000000e+000   0.00000000e+000<br>   0.00000000e+000   0.00000000e+000   0.00000000e+000   0.00000000e+000<br>   0.00000000e+000   0.00000000e+000   0.00000000e+000   0.00000000e+000<br>   0.00000000e+000   0.00000000e+000   0.00000000e+000  -2.42848401e-001<br>  -9.28403263e-001   0.00000000e+000  -8.91115491e-001   0.00000000e+000<br>   0.00000000e+000   1.33924630e-001   0.00000000e+000   0.00000000e+000<br>   0.00000000e+000   2.81909059e-001   0.00000000e+000   0.00000000e+000<br>   0.00000000e+000   0.00000000e+000]</p>
<p>   <img src="http://oh6ybr0jg.bkt.clouddn.com/linear_regression_polynomial.png" alt="此处输入图片的描述"></p>
]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;概念梳理：&quot;&gt;&lt;a href=&quot;#概念梳理：&quot; class=&quot;headerlink&quot; title=&quot;概念梳理：&quot;&gt;&lt;/a&gt;概念梳理：&lt;/h2&gt;&lt;p&gt;数学期望：&lt;br&gt;在概率论和统计学中，数学期望(mean)（或均值，亦简称期望）是试验中每次可能结果的概率乘以其结果的总和，是最基本的数学特征之一。它反映随机变量平均取值的大小&lt;/p&gt;
&lt;p&gt;方差：&lt;br&gt;（variance)是在概率论和统计方差衡量随机变量或一组数据时离散程度的度量。概率论中方差用来度量随机变量和其数学期望（即均值）之间的偏离程度。统计中的方差（样本方差）是每个样本值与全体样本值的平均数之差的平方值的平均数。在许多实际问题中，研究方差即偏离程度有着重要意义。&lt;/p&gt;
&lt;p&gt;概率密度函数：&lt;br&gt;在数学中，连续型随机变量的概率密度函数（在不至于混淆时可以简称为密度函数）是一个描述这个随机变量的输出值，在某个确定的取值点附近的可能性的函数。而随机变量的取值落在某个区域之内的概率则为概率密度函数在这个区域上的积分。当概率密度函数存在的时候，累积分布函数是概率密度函数的积分。概率密度函数一般以小写标记&lt;br&gt;正态分布是重要的概率分布。它的概率密度函数是：&lt;br&gt;&lt;img src=&quot;http://oh6ybr0jg.bkt.clouddn.com/gailvmidu.jpg&quot; alt=&quot;此处输入图片的描述&quot;&gt;&lt;br&gt;随着参数μ和σ变化，概率分布也产生变化。&lt;br&gt;期望：μ&lt;br&gt;方差：σ^2&lt;br&gt;中位数：μ&lt;br&gt;众44o6fdeswq    DFGI-数：μ&lt;br&gt;偏度：0&lt;br&gt;峰度：3&lt;br&gt;\]&lt;br&gt;
    
    </summary>
    
      <category term="机器学习" scheme="http://yoursite.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="机器学习" scheme="http://yoursite.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>scikit-learn pca</title>
    <link href="http://yoursite.com/2018/03/03/scikit-learn%20pca/"/>
    <id>http://yoursite.com/2018/03/03/scikit-learn pca/</id>
    <published>2018-03-03T03:06:30.000Z</published>
    <updated>2018-12-21T08:14:17.397Z</updated>
    
    <content type="html"><![CDATA[<p>from sklearn import datasets</p>
<p>digits = datasets.load_digits()<br>x = digits.data<br>y = digits.target</p>
<p>from sklearn.model_selection import  train_test_split<br>x_train,x_test,y_train,y_test = train_test_split(x,y,random_state=666)</p>
<p>print(x_train.shape)</p>
<p>#(1347, 64)<br>from sklearn.neighbors import KNeighborsClassifier<br>import time<br>start = time.clock()<br>knn_clf = KNeighborsClassifier()</p>
<p>knn_clf.fit(x_train,y_train)<br>end = time.clock()</p>
<p>print(end-start)</p>
<p>#0.009107513739889835<br>score = knn_clf.score(x_test,y_test)</p>
<p>print(score)</p>
<p>#0.986666666667</p>
<p>from sklearn.decomposition import  PCA</p>
<p>pca = PCA(n_components=2)<br>pca.fit(x_train)<br>X_train_reduction = pca.transform(x_train)<br>X_test_reduction = pca.transform(x_test)</p>
<p>start2 = time.clock()<br>knn_clf = KNeighborsClassifier()<br>knn_clf.fit(X_train_reduction,y_train)<br>end2 = time.clock()</p>
<p>print(end2-start2)</p>
<p>#0.0019209365663966915<br>score = knn_clf.score(X_test_reduction,y_test)<br>print(score)</p>
<p>#0.606666666667</p>
<p>print(pca.explained<em>variance</em>)</p>
<p>pca = PCA(n_components=x_train.shape[1])</p>
<p>pca3 = PCA(0.95)<br>pca3.fit(x_train)<br>print(pca3.n<em>components</em>)</p>
<p>#28</p>
<p>start3 = time.clock()<br>knn_clf3 = KNeighborsClassifier()<br>X_train_reduction = pca3.transform(x_train)<br>X_test_reduction = pca3.transform(x_test)<br>knn_clf3.fit(X_train_reduction,y_train)<br>end3 = time.clock()</p>
<p>print(end3-start3)</p>
<p>#0.006395458395239972<br>score = knn_clf3.score(X_test_reduction,y_test)<br>print(score)</p>
<p>#0.98</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;from sklearn import datasets&lt;/p&gt;
&lt;p&gt;digits = datasets.load_digits()&lt;br&gt;x = digits.data&lt;br&gt;y = digits.target&lt;/p&gt;
&lt;p&gt;from sklearn.model_sel
    
    </summary>
    
    
      <category term="机器学习" scheme="http://yoursite.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>scikit-learn KNN</title>
    <link href="http://yoursite.com/2018/03/02/scikit-learn%20KNN/"/>
    <id>http://yoursite.com/2018/03/02/scikit-learn KNN/</id>
    <published>2018-03-02T02:06:30.000Z</published>
    <updated>2018-12-21T08:14:37.220Z</updated>
    
    <content type="html"><![CDATA[<p>地址：<br><a href="http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#sklearn.neighbors.KNeighborsClassifier" target="_blank" rel="external">http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#sklearn.neighbors.KNeighborsClassifier</a></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> KNeighborsClassifier</div><div class="line"></div><div class="line">X = [[<span class="number">0</span>], [<span class="number">1</span>], [<span class="number">2</span>], [<span class="number">3</span>]]</div><div class="line">y = [<span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">1</span>]</div><div class="line">neigh = KNeighborsClassifier(n_neighbors=<span class="number">3</span>)</div><div class="line">neigh.fit(X, y)</div><div class="line"></div><div class="line">print(neigh.predict([[<span class="number">1.1</span>]]))</div><div class="line"><span class="comment"># [0]</span></div><div class="line">print(neigh.predict_proba([[<span class="number">0.9</span>]]))</div><div class="line"><span class="comment">#[[ 0.66666667  0.33333333]]</span></div></pre></td></tr></table></figure>
<a id="more"></a>
<p>手写数字练习：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets</div><div class="line"></div><div class="line">digits = datasets.load_digits()</div><div class="line">x= digits.data</div><div class="line">y= digits.target</div><div class="line">print(x.shape)</div><div class="line"><span class="comment">#(1797, 64)</span></div><div class="line"></div><div class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span>  train_test_split</div><div class="line">x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=<span class="number">0.2</span>,random_state=<span class="number">666</span>)</div><div class="line"></div><div class="line"></div><div class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> KNeighborsClassifier</div><div class="line"></div><div class="line">knn_clf = KNeighborsClassifier(n_neighbors=<span class="number">3</span>)</div><div class="line">knn_clf.fit(x_train,y_train)</div><div class="line">score= knn_clf.score(x_test,y_test)</div><div class="line">print(score)</div><div class="line"><span class="comment">#0.988888888889</span></div></pre></td></tr></table></figure>
<p>查找最佳超参数<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line">beat_score=<span class="number">0</span></div><div class="line">break_k =<span class="number">-1</span></div><div class="line"><span class="keyword">for</span> k <span class="keyword">in</span> range(<span class="number">1</span>,<span class="number">11</span>):</div><div class="line">    knn_clf2 = KNeighborsClassifier(n_neighbors=k)</div><div class="line">    knn_clf2.fit(x_train,y_train)</div><div class="line">    score= knn_clf2.score(x_test,y_test)</div><div class="line">    <span class="keyword">if</span>(score &gt;beat_score):</div><div class="line">        break_k =k</div><div class="line">        beat_score = score</div><div class="line"></div><div class="line">print(<span class="string">"beat_score"</span>,beat_score)</div><div class="line">print(<span class="string">"break_k"</span>,break_k)</div></pre></td></tr></table></figure></p>
<p>beat_score 0.991666666667<br>break_k 4</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line">beat_score=<span class="number">0</span></div><div class="line">break_k =<span class="number">-1</span></div><div class="line">beat_method=<span class="string">''</span></div><div class="line"><span class="keyword">for</span> method <span class="keyword">in</span> [<span class="string">'uniform'</span>,<span class="string">'distance'</span>]:</div><div class="line">    <span class="keyword">for</span> k <span class="keyword">in</span> range(<span class="number">1</span>,<span class="number">11</span>):</div><div class="line">        knn_clf2 = KNeighborsClassifier(n_neighbors=k,weights=method)</div><div class="line">        knn_clf2.fit(x_train,y_train)</div><div class="line">        score= knn_clf2.score(x_test,y_test)</div><div class="line">        <span class="keyword">if</span>(score &gt;beat_score):</div><div class="line">            beat_method = method</div><div class="line">            break_k =k</div><div class="line">            beat_score = score</div><div class="line"></div><div class="line">print(<span class="string">"beat_score"</span>,beat_score)</div><div class="line">print(<span class="string">"break_k"</span>,break_k)</div></pre></td></tr></table></figure>
<p>网格搜素：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> time</div><div class="line">start = time.clock()</div><div class="line">param_grid=[</div><div class="line">    &#123;</div><div class="line">        <span class="string">'weights'</span>:[<span class="string">'uniform'</span>],</div><div class="line">        <span class="string">'n_neighbors'</span>:[i  <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>,<span class="number">11</span>)]</div><div class="line">    &#125;,</div><div class="line">    &#123;</div><div class="line">        <span class="string">'weights'</span>:[<span class="string">'distance'</span>],</div><div class="line">        <span class="string">'n_neighbors'</span>:[i  <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>,<span class="number">11</span>)],</div><div class="line">        <span class="string">'p'</span>:[i  <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>,<span class="number">6</span>)]</div><div class="line">    &#125;</div><div class="line">]</div><div class="line"></div><div class="line">knn_clf = KNeighborsClassifier()</div><div class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span>  GridSearchCV</div><div class="line">grid_search = GridSearchCV(knn_clf,param_grid)</div><div class="line">grid_search.fit(x_train,y_train)</div><div class="line">print(<span class="string">"grid_search.best_estimator_:"</span>,grid_search.best_estimator_)</div><div class="line">print(<span class="string">"grid_search.best_score_:"</span>,grid_search.best_score_)</div><div class="line">print(<span class="string">"grid_search.best_params_:"</span>,grid_search.best_params_)</div><div class="line"></div><div class="line">knn_clf = grid_search.best_estimator_</div><div class="line">knn_clf_score = knn_clf.score(x_test,y_test)</div><div class="line">print(knn_clf_score)</div><div class="line">end = time.clock()</div><div class="line">print(end-start)</div></pre></td></tr></table></figure></p>
<p>grid_search.best<em>estimator</em>: KNeighborsClassifier(algorithm=’auto’, leaf_size=30, metric=’minkowski’,<br>           metric_params=None, n_jobs=1, n_neighbors=3, p=3,<br>           weights=’distance’)<br>grid_search.best<em>score</em>: 0.985386221294<br>grid_search.best<em>params</em>: {‘n_neighbors’: 3, ‘p’: 3, ‘weights’: ‘distance’}<br>0.983333333333<br>296.18877317471</p>
<p>增加并行化处理：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">grid_search = GridSearchCV(knn_clf,param_grid,n_jobs=<span class="number">2</span>,verbose=<span class="number">2</span>)</div></pre></td></tr></table></figure></p>
<p>速度变为：156.67693082041933</p>
<p>最值归一化：<br>适用于分布有明显边界的情况，受outlier影响较大<br>均值方差归一化：<br>适用于分布没有明显边界的情况，有可能存在极端数值</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;地址：&lt;br&gt;&lt;a href=&quot;http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#sklearn.neighbors.KNeighborsClassifier&quot;&gt;http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#sklearn.neighbors.KNeighborsClassifier&lt;/a&gt;&lt;/p&gt;
&lt;figure class=&quot;highlight python&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;2&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;3&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;4&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;5&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;6&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;7&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;8&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;9&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;10&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;11&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;from&lt;/span&gt; sklearn.neighbors &lt;span class=&quot;keyword&quot;&gt;import&lt;/span&gt; KNeighborsClassifier&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;X = [[&lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;], [&lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;], [&lt;span class=&quot;number&quot;&gt;2&lt;/span&gt;], [&lt;span class=&quot;number&quot;&gt;3&lt;/span&gt;]]&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;y = [&lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;, &lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;, &lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;, &lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;]&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;neigh = KNeighborsClassifier(n_neighbors=&lt;span class=&quot;number&quot;&gt;3&lt;/span&gt;)&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;neigh.fit(X, y)&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;print(neigh.predict([[&lt;span class=&quot;number&quot;&gt;1.1&lt;/span&gt;]]))&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# [0]&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;print(neigh.predict_proba([[&lt;span class=&quot;number&quot;&gt;0.9&lt;/span&gt;]]))&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;#[[ 0.66666667  0.33333333]]&lt;/span&gt;&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
    
    </summary>
    
    
      <category term="机器学习" scheme="http://yoursite.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>scikit-learn regression</title>
    <link href="http://yoursite.com/2018/03/01/scikit-learn%20regression/"/>
    <id>http://yoursite.com/2018/03/01/scikit-learn regression/</id>
    <published>2018-03-01T03:06:30.000Z</published>
    <updated>2018-12-21T08:14:24.851Z</updated>
    
    <content type="html"><![CDATA[<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets</div><div class="line"></div><div class="line">boston = datasets.load_boston()</div><div class="line">x= boston.data</div><div class="line">y= boston.targe</div><div class="line"></div><div class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span>  train_test_split</div><div class="line">x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=<span class="number">0.2</span>,random_state=<span class="number">666</span>)</div><div class="line"></div><div class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> linear_model</div><div class="line">clf = linear_model.LinearRegression()</div><div class="line"></div><div class="line">clf.fit(x_train,y_train)</div><div class="line">y_predict = clf.predict(x_test)</div><div class="line"></div><div class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> mean_squared_error</div><div class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> mean_absolute_error</div><div class="line"></div><div class="line">MSE = mean_squared_error(y_test,y_predict)</div><div class="line">print(MSE)</div><div class="line">MAE = mean_absolute_error(y_test,y_predict)</div><div class="line">print(MAE)</div></pre></td></tr></table></figure>
]]></content>
    
    <summary type="html">
    
      &lt;figure class=&quot;highlight python&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;2&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;3&lt;/d
    
    </summary>
    
    
      <category term="机器学习" scheme="http://yoursite.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>机器学习-决策树算法实例</title>
    <link href="http://yoursite.com/2018/02/18/Mathematical%20decision%20tree/"/>
    <id>http://yoursite.com/2018/02/18/Mathematical decision tree/</id>
    <published>2018-02-18T01:30:00.000Z</published>
    <updated>2018-07-25T16:10:05.738Z</updated>
    
    <content type="html"><![CDATA[<h2 id="决策树："><a href="#决策树：" class="headerlink" title="决策树："></a>决策树：</h2><p>有监督学习方法<br>是一种预测模型<br>是在已知各种情况发生概率基础上，通过构建决策树来进行分析的一种方法</p>
<h3 id="树形结构"><a href="#树形结构" class="headerlink" title="树形结构"></a>树形结构</h3><p>从跟节点开始，预测待分类项对应的特征属性，按照值选择输出分支，直到叶子节点，将叶子节点的存放类别作为树的结果</p>
<p>决策树分为两类：<br>分类，回归<br>前者用于分类标签值，后者用于预测连续值<br>常用算法ID3，C4,5，CART</p>
<h3 id="数据标准化："><a href="#数据标准化：" class="headerlink" title="数据标准化："></a>数据标准化：</h3><p>StandardScaler (基于特征矩阵的列，将属性值转换至服从正态分布)<br>标准化是依照特征矩阵的列处理数据，其通过求z-score的方法，将样本的特征值转换到同一量纲下<br>常用与基于正态分布的算法，比如回归<br>数据归一化<br>MinMaxScaler （区间缩放，基于最大最小值，将数据转换到0,1区间上的）<br>提升模型收敛速度，提升模型精度<br>常见用于神经网络<br>Normalizer （基于矩阵的行，将样本向量转换为单位向量）<br>其目的在于样本向量在点乘运算或其他核函数计算相似性时，拥有统一的标准<br>常见用于文本分类和聚类、logistic回归中也会使用，有效防止过拟合</p>
<h3 id="特征选择："><a href="#特征选择：" class="headerlink" title="特征选择："></a>特征选择：</h3><p>从已有的特征中选择出影响目标值最大的特征属性</p>
<h2 id="常用方法：-分类：F统计量、卡方系数，互信息mutual-info-classif"><a href="#常用方法：-分类：F统计量、卡方系数，互信息mutual-info-classif" class="headerlink" title="常用方法：{ 分类：F统计量、卡方系数，互信息mutual_info_classif"></a>常用方法：{ 分类：F统计量、卡方系数，互信息mutual_info_classif</h2><pre><code>{ 连续：皮尔逊相关系数 F统计量 互信息mutual_info_classif
</code></pre><h2 id="SelectKBest（卡方系数）"><a href="#SelectKBest（卡方系数）" class="headerlink" title="SelectKBest（卡方系数）"></a>SelectKBest（卡方系数）</h2>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;决策树：&quot;&gt;&lt;a href=&quot;#决策树：&quot; class=&quot;headerlink&quot; title=&quot;决策树：&quot;&gt;&lt;/a&gt;决策树：&lt;/h2&gt;&lt;p&gt;有监督学习方法&lt;br&gt;是一种预测模型&lt;br&gt;是在已知各种情况发生概率基础上，通过构建决策树来进行分析的一种方法&lt;/p&gt;
&lt;h
    
    </summary>
    
      <category term="机器学习" scheme="http://yoursite.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="机器学习" scheme="http://yoursite.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>设计模式-结构模式</title>
    <link href="http://yoursite.com/2018/02/11/Design%20pattern%20structural/"/>
    <id>http://yoursite.com/2018/02/11/Design pattern structural/</id>
    <published>2018-02-11T01:30:00.000Z</published>
    <updated>2018-07-25T16:17:19.158Z</updated>
    
    <content type="html"><![CDATA[<h3 id="1-适配器"><a href="#1-适配器" class="headerlink" title="1.适配器"></a>1.适配器</h3><p>效果及优缺点：<br>对于类适配器：</p>
<ol>
<li>用一个具体的Adapter类对Adaptee和Taget进行匹配。结果是当我们想要匹配一个类以及所有它的子类时，类Adapter将不能胜任工作。</li>
<li>使得Adapter可以override（重定义） Adaptee的部分行为，因为Adapter是Adaptee的一个子类。<br>对于对象适配器：</li>
<li>允许一个Adapter与多个Adaptee，即Adaptee本身以及它的所有子类（如果有子类的话）同时工作。Adapter也可以一次给所有的Adaptee添加功能。</li>
<li>使得override（重定义）Adaptee的行为比较困难。如果一定要override Adaptee的方法，就只好先做一个Adaptee的子类以override Adaptee的方法，然后再把这个子类当作真正的Adaptee源进行适配。</li>
</ol>
<h3 id="2-桥接"><a href="#2-桥接" class="headerlink" title="2.桥接"></a>2.桥接</h3><p>继承是一种强耦合的结果，父类变，子类就必须要变。可以使用组合/继承来解耦合。将抽象和他的实现分离<br><img src="https://images.cnblogs.com/cnblogs_com/houleixx/Snap1.jpg" alt="此处输入图片的描述"></p>
<h3 id="3-组合"><a href="#3-组合" class="headerlink" title="3.组合"></a>3.组合</h3><p>将对象组合成属性结构以表示‘部分-整体’的层次结构。组合模式使得用户对单个对象和组合对象的使用具有一致性。</p>
<p>组合模式描述了如何使用递归的组合，使客户不用区分这些类</p>
<h3 id="4-装配器"><a href="#4-装配器" class="headerlink" title="4.装配器"></a>4.装配器</h3><h3 id="5-外观"><a href="#5-外观" class="headerlink" title="5.外观"></a>5.外观</h3><h3 id="6-享元模式"><a href="#6-享元模式" class="headerlink" title="6.享元模式"></a>6.享元模式</h3><h3 id="7-代理模式"><a href="#7-代理模式" class="headerlink" title="7.代理模式"></a>7.代理模式</h3><p>Copy-on-writedai代理：即写即复制“快照”虚拟代理的一种，把复制拖延到只有客户端需要时，才真正执行<br>保护代理：允许在访问对象时附加管理任务</p>
<p>1.什么是代理模式：例如我们找房子找中介<br>2.为什么要使用代理：我们不需要自己找房子</p>
]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;1-适配器&quot;&gt;&lt;a href=&quot;#1-适配器&quot; class=&quot;headerlink&quot; title=&quot;1.适配器&quot;&gt;&lt;/a&gt;1.适配器&lt;/h3&gt;&lt;p&gt;效果及优缺点：&lt;br&gt;对于类适配器：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;用一个具体的Adapter类对Adaptee和Tag
    
    </summary>
    
      <category term="设计模式" scheme="http://yoursite.com/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"/>
    
    
      <category term="设计模式" scheme="http://yoursite.com/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"/>
    
  </entry>
  
  <entry>
    <title>设计模式-行为模式</title>
    <link href="http://yoursite.com/2018/02/10/Design%20pattern%20behavior/"/>
    <id>http://yoursite.com/2018/02/10/Design pattern behavior/</id>
    <published>2018-02-10T01:30:00.000Z</published>
    <updated>2018-03-30T15:45:16.730Z</updated>
    
    <content type="html"><![CDATA[<h3 id="责任链模式"><a href="#责任链模式" class="headerlink" title="责任链模式"></a>责任链模式</h3><h4 id="命令模式"><a href="#命令模式" class="headerlink" title="命令模式"></a>命令模式</h4><p>命令Command<br>    ——声明执行操作的接口。<br>具体命令ConcreteCommand<br>    ——定义接收对象和动作之间的绑定关系。<br>    ——通过引起接收者的相应动作来实现执行。<br>客户Client<br>    ——产生一个ConcreteCommand对象，并设置接收者。<br>引发者Invoker<br>    ——要求命令执行请求。<br>接收者Receiver<br>    ——知道如何执行与请求相联系的操作。</p>
<a id="more"></a>
<h3 id="迭代器模式"><a href="#迭代器模式" class="headerlink" title="迭代器模式"></a>迭代器模式</h3><h3 id="模板方法模式"><a href="#模板方法模式" class="headerlink" title="模板方法模式"></a>模板方法模式</h3><p>准备一个抽象类，定义一个算法的大体框架<br>将部分逻辑以具体方法以及具体构造子的形式实现<br>剩余的逻辑通过声明一些抽象方法来描述<br>这些抽象方法要求子类实现，<br>不同的子类可以以不同的方式实现这些抽象方法，从而对剩余的逻辑有不同的实现。<br>子类不改变算法的结构而重定义算法</p>
<h3 id="观察者模式"><a href="#观察者模式" class="headerlink" title="观察者模式"></a>观察者模式</h3><p>同一应用对象不同展示形式，如一组数据映射为表格和柱状图。用户更改表格数据，柱状图要同步修改</p>
<p>关键对象：<br>抽象主题Subject<br>提供一个连接观察者对象和解除连接的接口。<br>知道它的观察者。可有任意数目的观察者对象观察一个主题。<br>可以增加和删除观察者对象，<br>具体主题ConcreteSubject：<br>通常用一个具体子类实现。<br>负责实现对观察者引用的聚集的管理力注。<br>将有关状态存入ConcreteObserver对象。<br>在具体主题内部状态改变时向它的观察者发送通知。</p>
<p>抽象观察者Observer ：<br>一般用一个抽象类或者一个接口实现，<br>为所有的具体观察者定义一个更新接口<br>更新接口包含的方法叫更新方法。<br>具体观察者ConcreteObserver<br>通常用一个具体子类实现，<br>保存一个指向ConcreteSubject对象的引用。<br>存储要与主题一致的状态。<br>实现抽象观察者角色所要求的更新接口，以便使本身的状态与主题的状态相协调。</p>
<h3 id="状态模式"><a href="#状态模式" class="headerlink" title="状态模式"></a>状态模式</h3><h3 id="策略模式"><a href="#策略模式" class="headerlink" title="策略模式"></a>策略模式</h3><h3 id="访问者模式"><a href="#访问者模式" class="headerlink" title="访问者模式"></a>访问者模式</h3><h3 id="解释器模式"><a href="#解释器模式" class="headerlink" title="解释器模式"></a>解释器模式</h3>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;责任链模式&quot;&gt;&lt;a href=&quot;#责任链模式&quot; class=&quot;headerlink&quot; title=&quot;责任链模式&quot;&gt;&lt;/a&gt;责任链模式&lt;/h3&gt;&lt;h4 id=&quot;命令模式&quot;&gt;&lt;a href=&quot;#命令模式&quot; class=&quot;headerlink&quot; title=&quot;命令模式&quot;&gt;&lt;/a&gt;命令模式&lt;/h4&gt;&lt;p&gt;命令Command&lt;br&gt;    ——声明执行操作的接口。&lt;br&gt;具体命令ConcreteCommand&lt;br&gt;    ——定义接收对象和动作之间的绑定关系。&lt;br&gt;    ——通过引起接收者的相应动作来实现执行。&lt;br&gt;客户Client&lt;br&gt;    ——产生一个ConcreteCommand对象，并设置接收者。&lt;br&gt;引发者Invoker&lt;br&gt;    ——要求命令执行请求。&lt;br&gt;接收者Receiver&lt;br&gt;    ——知道如何执行与请求相联系的操作。&lt;/p&gt;
    
    </summary>
    
      <category term="设计模式" scheme="http://yoursite.com/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"/>
    
    
      <category term="设计模式" scheme="http://yoursite.com/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"/>
    
  </entry>
  
  <entry>
    <title>2018学习计划</title>
    <link href="http://yoursite.com/2018/02/07/2018%E5%AD%A6%E4%B9%A0%E8%AE%A1%E5%88%92/"/>
    <id>http://yoursite.com/2018/02/07/2018学习计划/</id>
    <published>2018-02-07T00:00:00.000Z</published>
    <updated>2018-12-21T08:12:32.620Z</updated>
    
    <content type="html"><![CDATA[<h2 id="大数据及机器学习学习计划"><a href="#大数据及机器学习学习计划" class="headerlink" title="大数据及机器学习学习计划"></a>大数据及机器学习学习计划</h2><ol>
<li><p>编程基础：Python<br><a href="https://cn.udacity.com/course/programming-foundations-with-python--ud036" target="_blank" rel="external">https://cn.udacity.com/course/programming-foundations-with-python--ud036</a></p>
</li>
<li><p>计算机科学导论  72小时<br><a href="https://cn.udacity.com/course/intro-to-computer-science--cs101" target="_blank" rel="external">https://cn.udacity.com/course/intro-to-computer-science--cs101</a></p>
</li>
<li>推论统计学  48小时<br><a href="https://cn.udacity.com/course/intro-to-inferential-statistics--ud201" target="_blank" rel="external">https://cn.udacity.com/course/intro-to-inferential-statistics--ud201</a></li>
<li>描述统计学  48小时<br><a href="https://cn.udacity.com/course/intro-to-inferential-statistics--ud201" target="_blank" rel="external">https://cn.udacity.com/course/intro-to-inferential-statistics--ud201</a></li>
<li>机器学习  240小时<br><a href="https://cn.udacity.com/course/machine-learning--ud262" target="_blank" rel="external">https://cn.udacity.com/course/machine-learning--ud262</a></li>
<li>统计学入门<br><a href="https://cn.udacity.com/course/intro-to-statistics--st101" target="_blank" rel="external">https://cn.udacity.com/course/intro-to-statistics--st101</a></li>
<li>基础线性代数<br><a href="https://cn.udacity.com/course/linear-algebra-refresher-course--ud953" target="_blank" rel="external">https://cn.udacity.com/course/linear-algebra-refresher-course--ud953</a></li>
<li><p>机器学习<br><a href="https://cn.udacity.com/course/machine-learning-engineer-nanodegree--nd009" target="_blank" rel="external">https://cn.udacity.com/course/machine-learning-engineer-nanodegree--nd009</a></p>
</li>
<li><p>Apache Storm 进行实时分析  48小时<br><a href="https://cn.udacity.com/course/real-time-analytics-with-apache-storm--ud381" target="_blank" rel="external">https://cn.udacity.com/course/real-time-analytics-with-apache-storm--ud381</a></p>
</li>
<li><p>Bash脚本  40+小时</p>
</li>
</ol>
]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;大数据及机器学习学习计划&quot;&gt;&lt;a href=&quot;#大数据及机器学习学习计划&quot; class=&quot;headerlink&quot; title=&quot;大数据及机器学习学习计划&quot;&gt;&lt;/a&gt;大数据及机器学习学习计划&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;&lt;p&gt;编程基础：Python&lt;br&gt;&lt;a hre
    
    </summary>
    
      <category term="学习计划" scheme="http://yoursite.com/categories/%E5%AD%A6%E4%B9%A0%E8%AE%A1%E5%88%92/"/>
    
    
      <category term="学习" scheme="http://yoursite.com/tags/%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>机器学习-支持向量机</title>
    <link href="http://yoursite.com/2018/02/05/Mathematical%20Support%20Vector%20Machine/"/>
    <id>http://yoursite.com/2018/02/05/Mathematical Support Vector Machine/</id>
    <published>2018-02-05T01:30:00.000Z</published>
    <updated>2018-12-21T08:13:30.038Z</updated>
    
    <content type="html"><![CDATA[<h3 id="支持向量机（Support-Vector-Machine，SVM）的基本概念："><a href="#支持向量机（Support-Vector-Machine，SVM）的基本概念：" class="headerlink" title="支持向量机（Support Vector Machine，SVM）的基本概念："></a>支持向量机（Support Vector Machine，SVM）的基本概念：</h3><h5 id="点到超平面的距离"><a href="#点到超平面的距离" class="headerlink" title="点到超平面的距离"></a>点到超平面的距离</h5><p>在分类任务中，为了获取稳健的线性分类器，一个很自然的想法是，找出一条分割线使得两侧样本与该分割线的平均距离足够的远。在欧式空间中，定义一个点𝒙到直线（或者高维空间中的超平面）𝒘^𝑇 𝒙+𝑏=0的距离公式是：<br>            𝑟(𝑥)=  (|𝒘^𝑇 𝒙+𝑏|)/(||𝒘||)<br>在分类问题中，如果这样的分割线或者分割平面能够准确地将样本分开，对于样本{𝒙<em>𝑖,𝑦</em>𝑖}∈𝐷, 𝑦<em>𝑖=±1 而言，若𝑦</em>𝑖=1，则有𝒘^𝑇 𝒙<em>𝒊+𝑏≥1，反之若𝑦</em>𝑖=-1，则有𝒘^𝑇 𝒙_𝒊+𝑏≤−1.</p>
]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;支持向量机（Support-Vector-Machine，SVM）的基本概念：&quot;&gt;&lt;a href=&quot;#支持向量机（Support-Vector-Machine，SVM）的基本概念：&quot; class=&quot;headerlink&quot; title=&quot;支持向量机（Support 
    
    </summary>
    
      <category term="机器学习" scheme="http://yoursite.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="机器学习" scheme="http://yoursite.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>设计模式-工厂模式</title>
    <link href="http://yoursite.com/2018/01/27/Design%20pattern%20factory/"/>
    <id>http://yoursite.com/2018/01/27/Design pattern factory/</id>
    <published>2018-01-27T01:30:00.000Z</published>
    <updated>2018-02-08T16:00:47.673Z</updated>
    
    <content type="html"><![CDATA[<p>创建几个套皮肤，所有的UI控件 如按钮，滚动条，窗口 都要创建出来。现在需要红色主题，黑色主题，和蓝色主题3套皮肤。</p>
<p>接口类：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">Button</span> </span>&#123;</div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">display</span><span class="params">()</span></span>;</div><div class="line">&#125;</div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">ScrollBar</span> </span>&#123;</div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">display</span><span class="params">()</span></span>;</div><div class="line">&#125;</div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">Window</span> </span>&#123;</div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">display</span><span class="params">()</span></span>;</div><div class="line">&#125;</div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">SkinFactory</span> </span>&#123;</div><div class="line">    <span class="function"><span class="keyword">public</span> ScrollBar <span class="title">createScrollBar</span><span class="params">()</span></span>;</div><div class="line">    <span class="function"><span class="keyword">public</span> Button <span class="title">createButton</span><span class="params">()</span></span>;</div><div class="line">    <span class="function"><span class="keyword">public</span> Window <span class="title">createWindow</span><span class="params">()</span></span>;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<a id="more"></a>
<p>红色皮肤工厂<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">RedSkinFactory</span> <span class="keyword">implements</span> <span class="title">SkinFactory</span> </span>&#123;</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">public</span> ScrollBar <span class="title">createScrollBar</span><span class="params">()</span> </span>&#123;</div><div class="line">        <span class="keyword">return</span> <span class="keyword">new</span> RedScrollBar();</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">public</span> Button <span class="title">createButton</span><span class="params">()</span> </span>&#123;</div><div class="line">        <span class="keyword">return</span> <span class="keyword">new</span> RedButton();</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">public</span> Window <span class="title">createWindow</span><span class="params">()</span> </span>&#123;</div><div class="line">        <span class="keyword">return</span> <span class="keyword">new</span> RedWindow();</div><div class="line">    &#125;</div><div class="line">&#125;</div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">RedScrollBar</span> <span class="keyword">implements</span> <span class="title">ScrollBar</span> </span>&#123;</div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">display</span><span class="params">()</span> </span>&#123;</div><div class="line">        System.out.println(<span class="string">"创建红色滚动条。"</span>);</div><div class="line">    &#125;</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">RedButton</span> <span class="keyword">implements</span> <span class="title">Button</span> </span>&#123;</div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">display</span><span class="params">()</span> </span>&#123;</div><div class="line">        System.out.println(<span class="string">"创建红色按钮"</span>);</div><div class="line">    &#125;</div><div class="line">&#125;</div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">RedWindow</span> <span class="keyword">implements</span> <span class="title">Window</span> </span>&#123;</div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">display</span><span class="params">()</span> </span>&#123;</div><div class="line">        System.out.println(<span class="string">"创建红色窗口。"</span>);</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>实现类<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">SkinClient</span> </span>&#123;</div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</div><div class="line">        SkinFactory BlackSkinFactory = <span class="keyword">new</span> BlackSkinFactory();</div><div class="line">        BlackSkinFactory.createButton().display();</div><div class="line">        BlackSkinFactory.createScrollBar().display();</div><div class="line">        BlackSkinFactory.createWindow().display();</div><div class="line"></div><div class="line">        SkinFactory RedSkinFactory = <span class="keyword">new</span> RedSkinFactory();</div><div class="line">        RedSkinFactory.createButton().display();</div><div class="line">        RedSkinFactory.createScrollBar().display();</div><div class="line">        RedSkinFactory.createWindow().display();</div><div class="line"></div><div class="line">        SkinFactory BlueSkinFactory = <span class="keyword">new</span> BlueSkinFactory();</div><div class="line">        BlueSkinFactory.createButton().display();</div><div class="line">        BlueSkinFactory.createScrollBar().display();</div><div class="line">        BlueSkinFactory.createWindow().display();</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>sh输出结果<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">创建黑色按钮</div><div class="line">创建黑色滚动条。</div><div class="line">创建黑色窗口。</div><div class="line">创建红色按钮</div><div class="line">创建红色滚动条。</div><div class="line">创建红色窗口。</div><div class="line">创建蓝色按钮</div><div class="line">创建蓝色滚动条。</div><div class="line">创建蓝色窗口。</div></pre></td></tr></table></figure></p>
<p>其他颜色同上<br>代码结构截图：<br><img src="http://oh6ybr0jg.bkt.clouddn.com/daimajiegoutu-gongchang.png" alt="此处输入图片的描述"><br>结果截图：<br><img src="http://oh6ybr0jg.bkt.clouddn.com/jieguojietu-gongchang1.png" alt="此处输入图片的描述"></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;创建几个套皮肤，所有的UI控件 如按钮，滚动条，窗口 都要创建出来。现在需要红色主题，黑色主题，和蓝色主题3套皮肤。&lt;/p&gt;
&lt;p&gt;接口类：&lt;br&gt;&lt;figure class=&quot;highlight java&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;2&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;3&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;4&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;5&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;6&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;7&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;8&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;9&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;10&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;11&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;12&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;13&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;14&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;class&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;interface&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;Button&lt;/span&gt; &lt;/span&gt;&amp;#123;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    &lt;span class=&quot;function&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;display&lt;/span&gt;&lt;span class=&quot;params&quot;&gt;()&lt;/span&gt;&lt;/span&gt;;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&amp;#125;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;class&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;interface&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;ScrollBar&lt;/span&gt; &lt;/span&gt;&amp;#123;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    &lt;span class=&quot;function&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;display&lt;/span&gt;&lt;span class=&quot;params&quot;&gt;()&lt;/span&gt;&lt;/span&gt;;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&amp;#125;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;class&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;interface&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;Window&lt;/span&gt; &lt;/span&gt;&amp;#123;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    &lt;span class=&quot;function&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;display&lt;/span&gt;&lt;span class=&quot;params&quot;&gt;()&lt;/span&gt;&lt;/span&gt;;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&amp;#125;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;class&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;interface&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;SkinFactory&lt;/span&gt; &lt;/span&gt;&amp;#123;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    &lt;span class=&quot;function&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;public&lt;/span&gt; ScrollBar &lt;span class=&quot;title&quot;&gt;createScrollBar&lt;/span&gt;&lt;span class=&quot;params&quot;&gt;()&lt;/span&gt;&lt;/span&gt;;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    &lt;span class=&quot;function&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;public&lt;/span&gt; Button &lt;span class=&quot;title&quot;&gt;createButton&lt;/span&gt;&lt;span class=&quot;params&quot;&gt;()&lt;/span&gt;&lt;/span&gt;;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    &lt;span class=&quot;function&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;public&lt;/span&gt; Window &lt;span class=&quot;title&quot;&gt;createWindow&lt;/span&gt;&lt;span class=&quot;params&quot;&gt;()&lt;/span&gt;&lt;/span&gt;;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&amp;#125;&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="设计模式" scheme="http://yoursite.com/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"/>
    
    
      <category term="设计模式" scheme="http://yoursite.com/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"/>
    
  </entry>
  
  <entry>
    <title>设计模式目录</title>
    <link href="http://yoursite.com/2018/01/27/Design%20pattern%20catalog/"/>
    <id>http://yoursite.com/2018/01/27/Design pattern catalog/</id>
    <published>2018-01-27T01:30:00.000Z</published>
    <updated>2018-02-06T14:27:35.863Z</updated>
    
    <content type="html"><![CDATA[<h3 id="创建性模式："><a href="#创建性模式：" class="headerlink" title="创建性模式："></a>创建性模式：</h3><p>1.类的创建模式——使用继承关系，把类的创建延迟到子类<br>2.对象的创建模式——把对象的创建过程动态地委派给另一个对象<br>    封装要创建的具体类（类的实例）的信息<br>    隐藏这些类（类的实例）被创建和组合的过程</p>
<p>包含<br>抽象工厂、建造者、工厂方式、原型、单例</p>
<h3 id="结构性模式："><a href="#结构性模式：" class="headerlink" title="结构性模式："></a>结构性模式：</h3><p>考虑如何组合类和对象构成较大的结构。<br>1.结构性类模式：使用继承来组合接口或实现<br>2.结构性对象模式：对象合成实现新功能。<br><a id="more"></a><br>包含：<br>适配器、桥接、组合、装饰着、外观、轻量、代理</p>
<h3 id="行为模式："><a href="#行为模式：" class="headerlink" title="行为模式："></a>行为模式：</h3><p>主要解决算法和对象之间的责任分配问题。<br>对象或类的模式<br>它们之间的通信模式。<br>包含：<br>责任链、命令、解释器、迭代、中介者、备忘录、观察者、状态、策略、模板方法、观察者</p>
<p>工厂方法主要针对一个产品等级结构<br>抽象工厂模式需要面对多个产品等级结构</p>
]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;创建性模式：&quot;&gt;&lt;a href=&quot;#创建性模式：&quot; class=&quot;headerlink&quot; title=&quot;创建性模式：&quot;&gt;&lt;/a&gt;创建性模式：&lt;/h3&gt;&lt;p&gt;1.类的创建模式——使用继承关系，把类的创建延迟到子类&lt;br&gt;2.对象的创建模式——把对象的创建过程动态地委派给另一个对象&lt;br&gt;    封装要创建的具体类（类的实例）的信息&lt;br&gt;    隐藏这些类（类的实例）被创建和组合的过程&lt;/p&gt;
&lt;p&gt;包含&lt;br&gt;抽象工厂、建造者、工厂方式、原型、单例&lt;/p&gt;
&lt;h3 id=&quot;结构性模式：&quot;&gt;&lt;a href=&quot;#结构性模式：&quot; class=&quot;headerlink&quot; title=&quot;结构性模式：&quot;&gt;&lt;/a&gt;结构性模式：&lt;/h3&gt;&lt;p&gt;考虑如何组合类和对象构成较大的结构。&lt;br&gt;1.结构性类模式：使用继承来组合接口或实现&lt;br&gt;2.结构性对象模式：对象合成实现新功能。&lt;br&gt;
    
    </summary>
    
      <category term="设计模式" scheme="http://yoursite.com/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"/>
    
    
      <category term="设计模式" scheme="http://yoursite.com/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"/>
    
  </entry>
  
  <entry>
    <title>python numpy</title>
    <link href="http://yoursite.com/2018/01/10/python%20numpy/"/>
    <id>http://yoursite.com/2018/01/10/python numpy/</id>
    <published>2018-01-10T03:30:00.000Z</published>
    <updated>2018-03-16T16:49:05.804Z</updated>
    
    <content type="html"><![CDATA[<h3 id="jupyter-notebook"><a href="#jupyter-notebook" class="headerlink" title="jupyter notebook:"></a>jupyter notebook:</h3><p>1.arange<br>生成数组<br>np.arange(10)<br>array([0,1,2,3,4,5,6,7,8,9])</p>
<p>2.等差数列是指从第二项起，每一项与它的前一项的差等于同一个常数的一种数列，常用A、P表示<br>等差数列 linspace<br>np.linspace(1,10,5)<br>array([1. , 3.25 ,5.5,5.75,10])</p>
<p>np.linspace(1,10,5,endpoint=False)  相当于生成6个数只显示前五个<br>array([1. , 2.8 ,4.6,6.5,8.2])</p>
<p>3.等比数列是指从第二项起，每一项与它的前一项的比值等于同一个常数的一种数列<br>等比数列logspace<br>np.logspace(1,10,5)</p>
<p>4.shape<br><a id="more"></a><br>arr = np.array([  [1,2,3],<br>                  [2,3,4]<br>               ])</p>
<p>arr.shape<br>(2, 3)</p>
<p>5.zeros<br>help(np.zeros)<br>zeros(shape, dtype=float, order=’C’)<br> Examples<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line"></div><div class="line"><span class="meta">&gt;&gt;&gt; </span>np.zeros(<span class="number">5</span>)</div><div class="line">array([ <span class="number">0.</span>,  <span class="number">0.</span>,  <span class="number">0.</span>,  <span class="number">0.</span>,  <span class="number">0.</span>])</div><div class="line"></div><div class="line"><span class="meta">&gt;&gt;&gt; </span>np.zeros((<span class="number">5</span>,), dtype=np.int)</div><div class="line">array([<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>])</div><div class="line"></div><div class="line"><span class="meta">&gt;&gt;&gt; </span>np.zeros((<span class="number">2</span>, <span class="number">1</span>))</div><div class="line">array([[ <span class="number">0.</span>],</div><div class="line">       [ <span class="number">0.</span>]])</div><div class="line"></div><div class="line"><span class="meta">&gt;&gt;&gt; </span>s = (<span class="number">2</span>,<span class="number">2</span>)</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>np.zeros(s)</div><div class="line">array([[ <span class="number">0.</span>,  <span class="number">0.</span>],</div><div class="line">       [ <span class="number">0.</span>,  <span class="number">0.</span>]])</div><div class="line"></div><div class="line"><span class="meta">&gt;&gt;&gt; </span>np.zeros((<span class="number">2</span>,), dtype=[(<span class="string">'x'</span>, <span class="string">'i4'</span>), (<span class="string">'y'</span>, <span class="string">'i4'</span>)]) <span class="comment"># custom dtype</span></div><div class="line">array([(<span class="number">0</span>, <span class="number">0</span>), (<span class="number">0</span>, <span class="number">0</span>)],</div><div class="line">      dtype=[(<span class="string">'x'</span>, <span class="string">'&lt;i4'</span>), (<span class="string">'y'</span>, <span class="string">'&lt;i4'</span>)])</div></pre></td></tr></table></figure></p>
<p>6.ones<br>类似zeros,只不过填充的是1</p>
<p>7.empty<br>类似zeros,只不过填充的是随机值</p>
<p>8.reshape<br>把一维数组转置为多维数组<br>reshape 不会改变原来的ndarray，但是得到新的ndarray是原数组的视图<br>对于ndarray的一些方法操作，首先要区分是否会改变原来变量，以此来判断是视图还是副本</p>
]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;jupyter-notebook&quot;&gt;&lt;a href=&quot;#jupyter-notebook&quot; class=&quot;headerlink&quot; title=&quot;jupyter notebook:&quot;&gt;&lt;/a&gt;jupyter notebook:&lt;/h3&gt;&lt;p&gt;1.arange&lt;br&gt;生成数组&lt;br&gt;np.arange(10)&lt;br&gt;array([0,1,2,3,4,5,6,7,8,9])&lt;/p&gt;
&lt;p&gt;2.等差数列是指从第二项起，每一项与它的前一项的差等于同一个常数的一种数列，常用A、P表示&lt;br&gt;等差数列 linspace&lt;br&gt;np.linspace(1,10,5)&lt;br&gt;array([1. , 3.25 ,5.5,5.75,10])&lt;/p&gt;
&lt;p&gt;np.linspace(1,10,5,endpoint=False)  相当于生成6个数只显示前五个&lt;br&gt;array([1. , 2.8 ,4.6,6.5,8.2])&lt;/p&gt;
&lt;p&gt;3.等比数列是指从第二项起，每一项与它的前一项的比值等于同一个常数的一种数列&lt;br&gt;等比数列logspace&lt;br&gt;np.logspace(1,10,5)&lt;/p&gt;
&lt;p&gt;4.shape&lt;br&gt;
    
    </summary>
    
      <category term="python" scheme="http://yoursite.com/categories/python/"/>
    
    
      <category term="python" scheme="http://yoursite.com/tags/python/"/>
    
  </entry>
  
  <entry>
    <title>python—pandas</title>
    <link href="http://yoursite.com/2018/01/08/python%E2%80%94pandas/"/>
    <id>http://yoursite.com/2018/01/08/python—pandas/</id>
    <published>2018-01-08T01:30:00.000Z</published>
    <updated>2018-01-19T16:02:42.664Z</updated>
    
    <content type="html"><![CDATA[<p>from pandas import Series,DataFrame<br>import pandas as pd</p>
<h3 id="Series：一种类似于一维数组的对象，是由一组数据（各种NumPy数据类型）以及一组与之相关的数据标签（即索引）组成。-索引可重复"><a href="#Series：一种类似于一维数组的对象，是由一组数据（各种NumPy数据类型）以及一组与之相关的数据标签（即索引）组成。-索引可重复" class="headerlink" title="Series：一种类似于一维数组的对象，是由一组数据（各种NumPy数据类型）以及一组与之相关的数据标签（即索引）组成。  索引可重复"></a>Series：一种类似于一维数组的对象，是由一组数据（各种NumPy数据类型）以及一组与之相关的数据标签（即索引）组成。  索引可重复</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> pandas <span class="keyword">import</span> Series,DataFrame</div><div class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</div><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"></div><div class="line">arr = np.array([<span class="number">1</span>,<span class="number">3</span>,<span class="number">5</span>,np.NaN,<span class="number">10</span>])</div><div class="line">serises0=Series(arr)</div><div class="line">serises0</div></pre></td></tr></table></figure>
<p>0     1.0<br>1     3.0<br>2     5.0<br>3     NaN<br>4    10.0<br>dtype: float64<br><a id="more"></a><br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">serises0.dtype</div></pre></td></tr></table></figure></p>
<p>dtype(‘float64’)</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">serises0.index</div></pre></td></tr></table></figure>
<p>RangeIndex(start=0, stop=5, step=1)</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">serises0.values</div></pre></td></tr></table></figure>
<p>array([  1.,   3.,   5.,  nan,  10.])</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">serises1=Series(data=[<span class="number">91</span>,<span class="number">92</span>,<span class="number">93</span>],dtype=np.float64,index=[<span class="string">u'数学'</span>,<span class="string">u'语文'</span>,<span class="string">u'外语'</span>])</div><div class="line">serises1</div></pre></td></tr></table></figure>
<p>数学    91.0<br>语文    92.0<br>外语    93.0<br>dtype: float64</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">dict0=&#123;<span class="string">u'数学'</span>:<span class="number">91.0</span>,<span class="string">u'语文'</span>:<span class="number">92</span>,<span class="string">u'外语'</span>:<span class="number">93</span>&#125;</div><div class="line">dict0</div></pre></td></tr></table></figure>
<p>{u’\u5916\u8bed’: 93, u’\u6570\u5b66’: 91.0, u’\u8bed\u6587’: 92}</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">serises2=Series(dict0)</div><div class="line">serises2</div></pre></td></tr></table></figure>
<p>外语    93.0<br>数学    91.0<br>语文    92.0<br>dtype: float64</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">serises2[<span class="number">0</span>]</div></pre></td></tr></table></figure>
<p>93.0</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">serises2[<span class="string">u'外语'</span>]</div></pre></td></tr></table></figure>
<p>93.0</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">serises2[<span class="string">'外语'</span>:<span class="string">'语文'</span>]</div></pre></td></tr></table></figure>
<p>外语    93.0<br>数学    91.0<br>语文    92.0<br>dtype: float64</p>
<p>Series运算，自动对齐索引<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">serises2=Series(data=[<span class="number">11</span>,<span class="number">12</span>,<span class="number">13</span>],dtype=np.float64,index=[<span class="string">'p1'</span>,<span class="string">'p2'</span>,<span class="string">'p3'</span>])</div><div class="line">serises3=Series(data=[<span class="number">22</span>,<span class="number">23</span>,<span class="number">24</span>,<span class="number">25</span>],dtype=np.float64,index=[<span class="string">'p2'</span>,<span class="string">'p3'</span>,<span class="string">'p4'</span>,<span class="string">'p5'</span>])</div><div class="line">serises2 +serises3</div></pre></td></tr></table></figure></p>
<p>p1     NaN<br>p2    34.0<br>p3    36.0<br>p4     NaN<br>p5     NaN<br>dtype: float64</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">serises1.name=<span class="string">'name'</span></div><div class="line">serises1.index.name=<span class="string">'考试科目'</span></div><div class="line">serises1</div></pre></td></tr></table></figure>
<p>考试科目<br>数学    91.0<br>语文    92.0<br>外语    93.0<br>Name: name, dtype: float64</p>
<h3 id="DataFrame-：-表格形式的数据结构，包含一组有序的列，每列可以是不同的值类型，DataFrame既有行索引又有列索引，可以看做是由Series组成的字典"><a href="#DataFrame-：-表格形式的数据结构，包含一组有序的列，每列可以是不同的值类型，DataFrame既有行索引又有列索引，可以看做是由Series组成的字典" class="headerlink" title="DataFrame ： 表格形式的数据结构，包含一组有序的列，每列可以是不同的值类型，DataFrame既有行索引又有列索引，可以看做是由Series组成的字典"></a>DataFrame ： 表格形式的数据结构，包含一组有序的列，每列可以是不同的值类型，DataFrame既有行索引又有列索引，可以看做是由Series组成的字典</h3><p>通过二维数组创建<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">df01=DataFrame([[<span class="string">'Tom'</span>,<span class="string">'John'</span>],[<span class="number">88</span>,<span class="number">90</span>]])</div><div class="line">df01</div></pre></td></tr></table></figure></p>
<pre><code>0    1
</code></pre><p>0    Tom    John<br>1    88    90</p>
<p>通过字典创建<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">data=&#123;<span class="string">'Tom'</span>:[<span class="number">88</span>,<span class="number">55</span>],<span class="string">'John'</span>:[<span class="number">90</span>,<span class="number">22</span>]&#125;</div><div class="line">df02=DataFrame(data)</div><div class="line">df02</div></pre></td></tr></table></figure></p>
<p>   John    Tom<br>0    90    88<br>1    22    55</p>
<p>DataFrame 可以增加数据<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">df02.ix[<span class="string">'2'</span>]=np.NaN</div></pre></td></tr></table></figure></p>
<pre><code>John    Tom
</code></pre><p>0    90.0    88.0<br>1    22.0    55.0<br>2    NaN        NaN</p>
<p>数据删除<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">df02=df02.dropna()</div><div class="line">df02</div></pre></td></tr></table></figure></p>
<pre><code>John    Tom
</code></pre><p>0    90.0    88.0<br>1    22.0    55.0</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">arr1=np.random.randint(<span class="number">5</span>,<span class="number">10</span>,(<span class="number">4</span>,<span class="number">4</span>))</div><div class="line">df1=pd.DataFrame(arr1)</div><div class="line">df1</div><div class="line">df1.ix[:<span class="number">2</span>,<span class="number">1</span>]=np.NAN</div><div class="line">df1.ix[:<span class="number">1</span>,<span class="number">2</span>]=np.NAN</div><div class="line">df1</div></pre></td></tr></table></figure>
<pre><code>0    1    2    3
</code></pre><p>0    8    NaN    NaN    7<br>1    5    NaN    NaN    9<br>2    5    NaN    5.0    5<br>3    9    8.0    7.0    5</p>
<h3 id="loc-iloc"><a href="#loc-iloc" class="headerlink" title="loc iloc"></a>loc iloc</h3><p>iloc 对于下标进行操作<br>loc 对于索引值进行操作</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;from pandas import Series,DataFrame&lt;br&gt;import pandas as pd&lt;/p&gt;
&lt;h3 id=&quot;Series：一种类似于一维数组的对象，是由一组数据（各种NumPy数据类型）以及一组与之相关的数据标签（即索引）组成。-索引可重复&quot;&gt;&lt;a href=&quot;#Series：一种类似于一维数组的对象，是由一组数据（各种NumPy数据类型）以及一组与之相关的数据标签（即索引）组成。-索引可重复&quot; class=&quot;headerlink&quot; title=&quot;Series：一种类似于一维数组的对象，是由一组数据（各种NumPy数据类型）以及一组与之相关的数据标签（即索引）组成。  索引可重复&quot;&gt;&lt;/a&gt;Series：一种类似于一维数组的对象，是由一组数据（各种NumPy数据类型）以及一组与之相关的数据标签（即索引）组成。  索引可重复&lt;/h3&gt;&lt;figure class=&quot;highlight python&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;2&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;3&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;4&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;5&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;6&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;7&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;from&lt;/span&gt; pandas &lt;span class=&quot;keyword&quot;&gt;import&lt;/span&gt; Series,DataFrame&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;import&lt;/span&gt; pandas &lt;span class=&quot;keyword&quot;&gt;as&lt;/span&gt; pd&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;import&lt;/span&gt; numpy &lt;span class=&quot;keyword&quot;&gt;as&lt;/span&gt; np&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;arr = np.array([&lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;,&lt;span class=&quot;number&quot;&gt;3&lt;/span&gt;,&lt;span class=&quot;number&quot;&gt;5&lt;/span&gt;,np.NaN,&lt;span class=&quot;number&quot;&gt;10&lt;/span&gt;])&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;serises0=Series(arr)&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;serises0&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;0     1.0&lt;br&gt;1     3.0&lt;br&gt;2     5.0&lt;br&gt;3     NaN&lt;br&gt;4    10.0&lt;br&gt;dtype: float64&lt;br&gt;
    
    </summary>
    
      <category term="python" scheme="http://yoursite.com/categories/python/"/>
    
    
      <category term="python" scheme="http://yoursite.com/tags/python/"/>
    
  </entry>
  
  <entry>
    <title>spark 机器学习入门(二)</title>
    <link href="http://yoursite.com/2017/10/19/spark%20ml2/"/>
    <id>http://yoursite.com/2017/10/19/spark ml2/</id>
    <published>2017-10-19T06:30:00.000Z</published>
    <updated>2018-07-25T16:43:43.579Z</updated>
    
    <content type="html"><![CDATA[<p>Spark MLlib 核心组件<br>Ø DataFrame 包含不同的列，可存储文本、 图片、 标签、 特征向量、 预测值等<br>Ø Estimator 用于从训练数据算出机器学习模型，输入DataFrame输出Model<br>Ø Transformer 输入DataFrame输出DataFrame<br>• Model即为一种Transformer，用于从测试数据生成预测结果<br>• 特征转换Transformer转换一个或多个特征，并将转换后的特征列追加到输出DataFrame中<br>Ø Pipeline<br>• 将多个Transformer和Estimator链接起来形成一个机器学习workflow<br>• Pipeline也是一种Estimator，生成一个PipelineModel<br>Ø Parameter 所有的Transformer和Estimator共享该通用的API来指定参数<br>Ø PipelineModel 保证对测试数据使用与训练数据完全相同的数据转换</p>
<p>训练模型：</p>
<p>Tokenizer and HashingTF 是Transformers<br>LogisticRegression 是Estimator<br><img src="http://spark.apache.org/docs/latest/img/ml-Pipeline.png" alt="此处输入图片的描述"></p>
<p>预测结果<br>Pipeline 是 Estimator<br>fit()方法会产生一个PipelineModel<br><img src="http://spark.apache.org/docs/latest/img/ml-PipelineModel.png" alt="此处输入图片的描述"><br>transform()方法Pipelines and PipelineModels帮助确保训练数据和测试数据经过相同特征的处理步骤。</p>
<p>SparseMatrix<br>介绍推荐博主：<br><a href="http://blog.csdn.net/sinat_29508201/article/details/54089771" target="_blank" rel="external">http://blog.csdn.net/sinat_29508201/article/details/54089771</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Spark MLlib 核心组件&lt;br&gt;Ø DataFrame 包含不同的列，可存储文本、 图片、 标签、 特征向量、 预测值等&lt;br&gt;Ø Estimator 用于从训练数据算出机器学习模型，输入DataFrame输出Model&lt;br&gt;Ø Transformer 输入Dat
    
    </summary>
    
      <category term="spark" scheme="http://yoursite.com/categories/spark/"/>
    
    
      <category term="spark" scheme="http://yoursite.com/tags/spark/"/>
    
  </entry>
  
  <entry>
    <title>spark 机器学习入门(一)</title>
    <link href="http://yoursite.com/2017/10/18/spark%20ml1/"/>
    <id>http://yoursite.com/2017/10/18/spark ml1/</id>
    <published>2017-10-18T03:30:00.000Z</published>
    <updated>2017-10-22T11:03:05.867Z</updated>
    
    <content type="html"><![CDATA[<p>目前基于RDD的MLlib已经进入维护莫斯。大概在spark2.3基于RDD的MLlib API将要被废弃。未来是基于DataFrame的API</p>
<p>1.基本统计<br>计算两组数据之间的相关性</p>
<h3 id="皮尔森相关系数（Pearson-correlation-coefficient）"><a href="#皮尔森相关系数（Pearson-correlation-coefficient）" class="headerlink" title="皮尔森相关系数（Pearson correlation coefficient）"></a>皮尔森相关系数（Pearson correlation coefficient）</h3><p>也称皮尔森积矩相关系数(Pearson product-moment correlation coefficient) ，是一种线性相关系数。皮尔森相关系数是用来反映两个变量线性相关程度的统计量。相关系数用r表示，其中n为样本量，分别为两个变量的观测值和均值。r描述的是两个变量间线性相关强弱的程度。r的绝对值越大表明相关性越强</p>
<p><img src="http://segmentfault.com/img/cGNupC" alt="此处输入图片的描述"><br><img src="http://segmentfault.com/img/eOV3Oj" alt="此处输入图片的描述"><br><img src="http://segmentfault.com/img/lJqNL" alt="此处输入图片的描述"><br><a id="more"></a><br>按照高中数学水平来理解, 它很简单, 可以看做将两组数据首先做Z分数处理之后, 然后两组数据的乘积和除以样本数</p>
<p>Z分数一般代表正态分布中, 数据偏离中心点的距离.等于变量减掉平均数再除以标准差.(就是高考的标准分类似的处理)</p>
<p>标准差则等于变量减掉平均数的平方和,再除以样本数,最后再开方.</p>
<p>所以, 根据这个最朴素的理解,我们可以将公式依次精简为:</p>
<p><img src="http://segmentfault.com/img/bKDASK" alt="此处输入图片的描述"></p>
<p>spearman相关系数：是衡量分级定序变量之间的相关程度的统计量，对不服从正态分布的资料、原始资料等级资料、一侧开口资料、总体分布类型未知的资料不符合使用积矩相关系数来描述关联性。此时可采用秩相关（rank correlation），也称等级相关，来描述两个变量之间的关联程度与方向。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> org.apache.spark.ml.linalg.&#123;<span class="type">Matrix</span>, <span class="type">Vectors</span>&#125;</div><div class="line"><span class="keyword">import</span> org.apache.spark.ml.stat.<span class="type">Correlation</span></div><div class="line"><span class="keyword">import</span> org.apache.spark.sql.<span class="type">SparkSession</span></div><div class="line"><span class="keyword">import</span> org.apache.spark.sql.<span class="type">Row</span></div><div class="line"></div><div class="line"><span class="class"><span class="keyword">object</span> <span class="title">ml_1</span> </span>&#123;</div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</div><div class="line">    <span class="keyword">val</span> spark = <span class="type">SparkSession</span></div><div class="line">      .builder</div><div class="line">      .master(<span class="string">"local"</span>)</div><div class="line">      .getOrCreate()</div><div class="line">    <span class="keyword">import</span> spark.implicits._</div><div class="line"></div><div class="line">    <span class="comment">// $example on$</span></div><div class="line">    <span class="keyword">val</span> data = <span class="type">Seq</span>(</div><div class="line">      <span class="type">Vectors</span>.sparse(<span class="number">4</span>, <span class="type">Seq</span>((<span class="number">0</span>, <span class="number">1.0</span>), (<span class="number">3</span>, <span class="number">-2.0</span>))),</div><div class="line">      <span class="type">Vectors</span>.dense(<span class="number">4.0</span>, <span class="number">5.0</span>, <span class="number">0.0</span>, <span class="number">3.0</span>),</div><div class="line">      <span class="type">Vectors</span>.dense(<span class="number">6.0</span>, <span class="number">7.0</span>, <span class="number">0.0</span>, <span class="number">8.0</span>),</div><div class="line">      <span class="type">Vectors</span>.sparse(<span class="number">4</span>, <span class="type">Seq</span>((<span class="number">0</span>, <span class="number">9.0</span>), (<span class="number">3</span>, <span class="number">1.0</span>)))</div><div class="line">    )</div><div class="line"></div><div class="line">    <span class="keyword">val</span> df = data.map(<span class="type">Tuple1</span>.apply).toDF(<span class="string">"features"</span>)</div><div class="line">    <span class="keyword">val</span> <span class="type">Row</span>(coeff1: <span class="type">Matrix</span>) = <span class="type">Correlation</span>.corr(df, <span class="string">"features"</span>).head</div><div class="line">    println(<span class="string">"Pearson correlation matrix:\n"</span> + coeff1.toString)</div><div class="line">    </div><div class="line">    <span class="keyword">val</span> <span class="type">Row</span>(coeff2: <span class="type">Matrix</span>) = <span class="type">Correlation</span>.corr(df, <span class="string">"features"</span>, <span class="string">"spearman"</span>).head</div><div class="line">    println(<span class="string">"Spearman correlation matrix:\n"</span> + coeff2.toString)</div><div class="line">    <span class="comment">// $example off$</span></div><div class="line"></div><div class="line">    spark.stop()</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>1.0为第一列和第一列计算<br>0.055641488407465814为第一列和第二列计算<br>0.4004714203168137 为第三列和第四列计算</p>
<p>计算结果:<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"><span class="type">Pearson</span> correlation matrix:</div><div class="line"><span class="number">1.0</span>                   <span class="number">0.055641488407465814</span>  <span class="type">NaN</span>  <span class="number">0.4004714203168137</span> </div><div class="line"><span class="number">0.055641488407465814</span>  <span class="number">1.0</span>                   <span class="type">NaN</span>  <span class="number">0.9135958615342522</span>  </div><div class="line"><span class="type">NaN</span>                   <span class="type">NaN</span>                   <span class="number">1.0</span>  <span class="type">NaN</span>                 </div><div class="line"><span class="number">0.4004714203168137</span>    <span class="number">0.9135958615342522</span>    <span class="type">NaN</span>  <span class="number">1.0</span>                 </div><div class="line"><span class="type">Spearman</span> correlation matrix:</div><div class="line"><span class="number">1.0</span>                  <span class="number">0.10540925533894532</span>  <span class="type">NaN</span>  <span class="number">0.40000000000000174</span>  </div><div class="line"><span class="number">0.10540925533894532</span>  <span class="number">1.0</span>                  <span class="type">NaN</span>  <span class="number">0.9486832980505141</span>   </div><div class="line"><span class="type">NaN</span>                  <span class="type">NaN</span>                  <span class="number">1.0</span>  <span class="type">NaN</span>                  </div><div class="line"><span class="number">0.40000000000000174</span>  <span class="number">0.9486832980505141</span>   <span class="type">NaN</span>  <span class="number">1.0</span></div></pre></td></tr></table></figure></p>
<h4 id="卡方检验"><a href="#卡方检验" class="headerlink" title="卡方检验"></a><strong>卡方检验</strong></h4><p>卡方检验是用途非常广的一种假设检验方法，它在分类资料统计推断中的应用，包括：两个率或两个构成比比较的卡方检验；多个率或多个构成比比较的卡方检验以及分类资料的相关分析等。<br>卡方检验就是统计样本的实际观测值与理论推断值之间的偏离程度，实际观测值与理论推断值之间的偏离程度就决定卡方值的大小，卡方值越大，越不符合；卡方值越小，偏差越小，越趋于符合，若两个值完全相等时，卡方值就为0，表明理论值完全符合。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> org.apache.spark.ml.linalg.<span class="type">Vector</span></div><div class="line"><span class="keyword">import</span> org.apache.spark.ml.linalg.<span class="type">Vectors</span></div><div class="line"><span class="keyword">import</span> org.apache.spark.ml.stat.<span class="type">ChiSquareTest</span></div><div class="line"><span class="keyword">import</span> org.apache.spark.sql.<span class="type">SparkSession</span></div><div class="line"></div><div class="line"><span class="comment">/**</span></div><div class="line">  * Created by Administrator on 2017/10/18.</div><div class="line">  */</div><div class="line"><span class="class"><span class="keyword">object</span> <span class="title">ChiSquareTest</span> </span>&#123;</div><div class="line"></div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</div><div class="line">    <span class="keyword">val</span> spark = <span class="type">SparkSession</span></div><div class="line">      .builder</div><div class="line">      .master(<span class="string">"local"</span>)</div><div class="line">      .getOrCreate()</div><div class="line">    <span class="keyword">import</span> spark.implicits._</div><div class="line"></div><div class="line">    <span class="keyword">val</span> data = <span class="type">Seq</span>(</div><div class="line">      (<span class="number">0.0</span>, <span class="type">Vectors</span>.dense(<span class="number">0.5</span>, <span class="number">10.0</span>)),</div><div class="line">      (<span class="number">0.0</span>, <span class="type">Vectors</span>.dense(<span class="number">1.5</span>, <span class="number">20.0</span>)),</div><div class="line">      (<span class="number">1.0</span>, <span class="type">Vectors</span>.dense(<span class="number">1.5</span>, <span class="number">30.0</span>)),</div><div class="line">      (<span class="number">0.0</span>, <span class="type">Vectors</span>.dense(<span class="number">3.5</span>, <span class="number">30.0</span>)),</div><div class="line">      (<span class="number">0.0</span>, <span class="type">Vectors</span>.dense(<span class="number">3.5</span>, <span class="number">40.0</span>)),</div><div class="line">      (<span class="number">1.0</span>, <span class="type">Vectors</span>.dense(<span class="number">3.5</span>, <span class="number">40.0</span>))</div><div class="line">    )</div><div class="line"></div><div class="line">    <span class="keyword">val</span> df = data.toDF(<span class="string">"label"</span>, <span class="string">"features"</span>)</div><div class="line">    <span class="keyword">val</span> chi = <span class="type">ChiSquareTest</span>.test(df, <span class="string">"features"</span>, <span class="string">"label"</span>).head</div><div class="line">    println(<span class="string">"pValues = "</span> + chi.getAs[<span class="type">Vector</span>](<span class="number">0</span>))</div><div class="line">    println(<span class="string">"degreesOfFreedom = "</span> + chi.getSeq[<span class="type">Int</span>](<span class="number">1</span>).mkString(<span class="string">"["</span>, <span class="string">","</span>, <span class="string">"]"</span>))</div><div class="line">    println(<span class="string">"statistics = "</span> + chi.getAs[<span class="type">Vector</span>](<span class="number">2</span>))</div><div class="line"></div><div class="line">    spark.stop()</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>结果：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">pValues = [<span class="number">0.6872892787909721</span>,<span class="number">0.6822703303362126</span>]</div><div class="line">degreesOfFreedom = [<span class="number">2</span>,<span class="number">3</span>]</div><div class="line">statistics = [<span class="number">0.75</span>,<span class="number">1.5</span>]</div></pre></td></tr></table></figure></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;目前基于RDD的MLlib已经进入维护莫斯。大概在spark2.3基于RDD的MLlib API将要被废弃。未来是基于DataFrame的API&lt;/p&gt;
&lt;p&gt;1.基本统计&lt;br&gt;计算两组数据之间的相关性&lt;/p&gt;
&lt;h3 id=&quot;皮尔森相关系数（Pearson-correlation-coefficient）&quot;&gt;&lt;a href=&quot;#皮尔森相关系数（Pearson-correlation-coefficient）&quot; class=&quot;headerlink&quot; title=&quot;皮尔森相关系数（Pearson correlation coefficient）&quot;&gt;&lt;/a&gt;皮尔森相关系数（Pearson correlation coefficient）&lt;/h3&gt;&lt;p&gt;也称皮尔森积矩相关系数(Pearson product-moment correlation coefficient) ，是一种线性相关系数。皮尔森相关系数是用来反映两个变量线性相关程度的统计量。相关系数用r表示，其中n为样本量，分别为两个变量的观测值和均值。r描述的是两个变量间线性相关强弱的程度。r的绝对值越大表明相关性越强&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://segmentfault.com/img/cGNupC&quot; alt=&quot;此处输入图片的描述&quot;&gt;&lt;br&gt;&lt;img src=&quot;http://segmentfault.com/img/eOV3Oj&quot; alt=&quot;此处输入图片的描述&quot;&gt;&lt;br&gt;&lt;img src=&quot;http://segmentfault.com/img/lJqNL&quot; alt=&quot;此处输入图片的描述&quot;&gt;&lt;br&gt;
    
    </summary>
    
      <category term="spark" scheme="http://yoursite.com/categories/spark/"/>
    
    
      <category term="spark" scheme="http://yoursite.com/tags/spark/"/>
    
  </entry>
  
</feed>
